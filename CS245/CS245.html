<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>CS245 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso-light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="../katex/katex.min.js" type="text/javascript"></script>
  <link rel="stylesheet" href="../katex/katex.min.css" />
  <script type="text/javascript">
  window.onload = function() {
    document.getElementsByClassName("status-banner")[0].style.display = "block";
    setTimeout(function() {
      renderMathElements(document.getElementsByClassName("math"));
      document.getElementsByClassName("status-banner")[0].style.display = "none";
    }, 50); // delay to allow status banner to show
  }

  function renderMathElements(mathElements) {
    var mathOptions = {
      macros: {
        "\\set": "\\left\\{ #1 \\right\\}",
        "\\tup": "\\left\\langle #1 \\right\\rangle",
        "\\abs": "\\left\\lvert #1 \\right\\rvert",
        "\\floor": "\\left\\lfloor #1 \\right\\rfloor",
        "\\ceil": "\\left\\lceil#1 \\right\\rceil",
        "\\mb": "\\mathbb{#1}",
        "\\rem": "\\operatorname{rem}",
        "\\ord": "\\operatorname{ord}",
        "\\sign": "\\operatorname{sign}",
        "\\imag": "\\bm{i}",
        "\\dee": "\\mathop{}\\!\\mathrm{d}",
        "\\lH": "\\overset{\\text{l'H}}{=}",
        "\\evalat": "\\left.\\left(#1\\right)\\right|",
        "\\sech": "\\operatorname{sech}",
        "\\spn": "\\operatorname{Span}",
        "\\proj": "\\operatorname{proj}",
        "\\prp": "\\operatorname{perp}",
        "\\refl": "\\operatorname{refl}",
        "\\magn": "\\left\\lVert #1 \\right\\rVert",
        "\\rank": "\\operatorname{rank}",
        "\\sys": "\\left[ #1 \\mid #2\\space \\right]",
        "\\range": "\\operatorname{Range}",
        "\\adj": "\\operatorname{adj}",
        "\\cof": "\\operatorname{cof}",
        "\\coord": "{\\left\\lbrack #1 \\right\\rbrack}_{#2}",
        "\\diag": "\\operatorname{diag}",
        "\\formlp": "\\operatorname{Form}(\\mathcal{L}^P)",
        "\\argmin": "\operatorname{argmin}}",
        "\\argmax": "\operatorname{argmax}}",
        "\\sgn": "\operatorname{sgn}}",

        // not yet available in KaTeX
        "\\operatorname": "\\mathop{\\text{#1}}\\nolimits", //wip: spacing is slightly off
        "\\not": "\\rlap{\\kern{7.5mu}/}", //wip: slash angle is slightly off
        "\\bm": "\\mathbf", //wip: should be italic, but isn't
      },
      throwOnError: false,
    };
    for (var i=0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      katex.render(texText.data, mathElements[i], mathOptions);
    }
  }
  </script>
</head>
<body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/resume.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="https://www.linkedin.com/in/uberi/" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:me@anthonyz.ca" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="https://twitter.com/anthony926535" class="contact">twitter</a></li>
    <span class="divider"></span>
    <li><a href="https://keybase.io/uberi" class="info">public key</a></li>
  </ul>
<h1 id="cs-245">CS 245</h1>
<p>Logic and computation.</p>
<pre><code>Instructor: Daniela Maftuleac
Email: daniela.maftuleac@uwaterloo.ca
Office Hours: Tuesday 2-3pm, Wednesday 12-1pm Math Tutorial Center
Website: https://www.student.cs.uwaterloo.ca/~cs245/</code></pre>
<p>Assignments are due at 1pm at the dropboxes on MC 4th floor, due on Thursdays, posted on Tuesdays, returned in tutorials. Remark requests must be done within a week after the marks are posted.</p>
<h2 id="logic">Logic</h2>
<p>Logic is the science of correct reasoning. It is concerned with determining whether things are true or false.</p>
<p>In <strong>symbolic logic</strong>, we use symbols to represent truth values and manipulate logical statements using certain logical rules.</p>
<p>This course deals with propositional logic, predicate logic, and program verification.</p>
<p>Prove that <span class="math inline">3 \mid (4^n + 5)</span> for all <span class="math inline">n \in \mb{N}</span>:</p>
<blockquote>
<p>Clearly, this is true for <span class="math inline">n = 0</span>, since <span class="math inline">3 \mid (1 + 5)</span>.<br />
Assume for some <span class="math inline">k \ge 0</span> that <span class="math inline">3 \mid (4^k + 5)</span>.<br />
So <span class="math inline">\exists p \in \mb{Z}, 3p = 4^k + 5</span> and <span class="math inline">4(3p) = 4(4^k + 5)</span>, so <span class="math inline">12p - 15 = 3(4p - 5) = 4^{k + 1} + 5</span>.<br />
Let <span class="math inline">q = 4p - 5</span>. Since <span class="math inline">q \in \mb{Z}</span>, <span class="math inline">\exists q \in \mb{Z}, 3q = 4^{k + 1} + 5</span>.<br />
So <span class="math inline">3 \mid 4^{k + 1} + 5</span>, and by induction, <span class="math inline">3 \mid 4^n + 5</span> for all <span class="math inline">n \in \mb{N}</span>.</p>
</blockquote>
<p>The idea is that with strong induction, we can use any of the previous cases to prove the inductive hypothesis.</p>
<h1 id="section">7/5/14</h1>
<h2 id="propositional-logic">Propositional Logic</h2>
<p>The language of propositions is propositional logic.</p>
<p>A proposition is a declarative statement that is either true or false. It may depend on the context, like how the proposition <span class="math inline">x \ge 5</span> depends on the contextual variable <span class="math inline">x</span>.</p>
<p>We always assume that for any proposition with its context (the situation the proposition applies in), either the proposition is true, or it is false, and it cannot be both. If a statement is false, then its negation is true.</p>
<p>Propositions must be declarative. They must make sense when we ask, &quot;is it true that PROPOSITION?&quot;. It must be assignable to either true or false.</p>
<p><strong>Simple/atomic propositions</strong> are the building blocks of <strong>compound propositions</strong>. For example, &quot;It is currently raining in Waterloo&quot; and &quot;It is currently 12 degrees Celsius in Waterloo&quot; are simple propositions, and &quot;It is either raining or 12 degrees in Waterloo&quot; is a compound proposition.</p>
<p>Atomic ropositions are the smallest possible statements that are still propositions. They cannot be divided into smaller propositions.</p>
<h3 id="expression-syntax">Expression Syntax</h3>
<p>The propositional language is known as <span class="math inline">\mathcal{L}_P</span> (Language of Propositions). This language contains <strong>atoms</strong>, which are lowercase Latin characters such as <span class="math inline">p</span>, <span class="math inline">q</span>, and <span class="math inline">r</span>, optionally with subscripts. These all belong to the set <span class="math inline">\operatorname{Atom}(\mathcal{L}_P)</span>, so <span class="math inline">p \in \operatorname{Atom}(\mathcal{L}_P)</span>.</p>
<p>There are also <strong>punctuation</strong> symbols, the round parentheses &quot;(&quot; and &quot;)&quot;, which change the precendence of subexpressions.</p>
<p>There are also <strong>connectives</strong>, which are <span class="math inline">\neg, \wedge, \vee, \rightarrow, \leftrightarrow</span>.</p>
<p>An <strong>expression</strong> is a finite sequence of symbols. The length of an expression is the number of symbols it contains. Expressions may not necessarily be valid, like <span class="math inline">( \vee \neg \vee (</span>.</p>
<p>The empty expression (containing no symbols) is denoted <span class="math inline">\emptyset</span>.</p>
<h3 id="expression-operations">Expression Operations</h3>
<p>Let <span class="math inline">U, V, W</span> be expressions. Then <span class="math inline">U</span> and <span class="math inline">V</span> are equal (<span class="math inline">U = V</span>) if and only if they contain the same sequence of symbols.</p>
<p>Then <span class="math inline">UV</span> is the concatenation of <span class="math inline">U</span> and <span class="math inline">V</span> - the expression containing the entire sequence in <span class="math inline">U</span>, followed by the entire sequence in <span class="math inline">V</span>.</p>
<p>If <span class="math inline">U = W_1 V W_2</span>, then <span class="math inline">V</span> is a <strong>segment</strong> of <span class="math inline">U</span> - it is a sequence of symbols that <span class="math inline">U</span> also contains. All sequences contain the empty expression.</p>
<p>If <span class="math inline">V</span> is a segment of <span class="math inline">U</span> and <span class="math inline">V \ne U</span>, then <span class="math inline">V</span> is a <strong>proper segment</strong> of <span class="math inline">U</span>.</p>
<p>If <span class="math inline">U = VW</span>, then <span class="math inline">V</span> is an <strong>initial segment</strong> and <span class="math inline">W</span> is a <strong>terminal segment</strong>.</p>
<h3 id="expression-validity">Expression Validity</h3>
<p>The binary (two-parameter) connectives are <span class="math inline">\wedge, \vee, \rightarrow, \leftrightarrow</span>. In the following, <span class="math inline">\odot</span> will represent any arbitrary one of these binary connectives. The only connective that is not binary is the unary <span class="math inline">\neg</span> connective.</p>
<p>The set of <strong>formulas</strong> is the set of all valid/well-formed expressions, and is denoted <span class="math inline">\formlp</span>. Given <span class="math inline">A, B \in \formlp</span>, we can define <span class="math inline">\formlp</span> as follows:</p>
<ul>
<li><span class="math inline">\operatorname{Atom}(\mathcal{L}_P) \subseteq \formlp</span> - all atoms are formulas.</li>
<li><span class="math inline">\neg A \in \formlp</span> - the negation of any formula is also a formula (the set of formulas are closed under negation).</li>
<li><span class="math inline">A \odot B \in \formlp</span> - binary connectives applied to two formulas are also formulas (the set of formulas is closed under all the binary connectives).</li>
</ul>
<p>Formulas are often represented using Roman capital letters.</p>
<p>Theorem 2.2.3 states the obvious consequences of the definition: all formulas of <span class="math inline">\mathcal{L}_P</span> are atoms, or of the form <span class="math inline">\neg A, A \wedge B, A \vee B, A \rightarrow B, A \leftrightarrow B</span>.</p>
<p>Let <span class="math inline">R(n)</span> be a property (true if the property holds for <span class="math inline">n</span>, false otherwise). Theorem 2.2.4 states that if <span class="math inline">\forall p \in \operatorname{Atom}(\mathcal{L}_P), R(p)</span> and <span class="math inline">\forall A \in \formlp, R(A) \implies R(\neg A)</span> and <span class="math inline">\forall A, B \in \formlp, R(A) \wedge R(B) \implies R(A \odot B)</span>, then <span class="math inline">\forall A \in \formlp, R(A)</span>.</p>
<p>In other words, if a property holds for all the forms of formulas, then it holds for all formulas.</p>
<p>The <strong>type</strong> of a formula is determined by its top-level operator. For example, <span class="math inline">\neg A</span> is a negation, <span class="math inline">A \wedge B</span> is conjunction, <span class="math inline">A \vee b</span> is a disjunction, <span class="math inline">A \rightarrow B</span> is an implication, <span class="math inline">A \leftrightarrow B</span> is an equivalence. According to theorem 2.3.3, all formulas must be one of these forms.</p>
<p>We want to be able to look at any expression and determine whether it is well formed. For example, <span class="math inline">\neg()</span> is not a well formed formula (WFF) because it is not obtainable through the rules that define an element in the set of formulas.</p>
<p>Is <span class="math inline">(\neg a) \wedge (b \vee c)</span> well formed?</p>
<blockquote>
<p>We can first notice that this is of the form <span class="math inline">P \wedge Q</span>, where <span class="math inline">P = \neg a</span> and <span class="math inline">Q = b \vee c</span>. By the rules, we know that the whole thing is well formed if and only if <span class="math inline">P</span> and <span class="math inline">Q</span> are both well formed.<br />
Now we check if <span class="math inline">P</span> is well formed. Clearly, it is of the form <span class="math inline">\neg R</span>, where <span class="math inline">R = a</span>, and <span class="math inline">a</span> is an atom (which is, by definition, well formed), so by the rules, <span class="math inline">\neg a</span> is well formed.<br />
Now we check if <span class="math inline">Q</span> is well formed. Clearly, it is of the form <span class="math inline">S \vee T</span>, where <span class="math inline">S = b</span> and <span class="math inline">T = c</span>. By the rules, <span class="math inline">Q</span> is well formed if and only if <span class="math inline">S</span> and <span class="math inline">T</span> are. Since they are atoms, they are both well formed by definition.<br />
Since <span class="math inline">P</span> and <span class="math inline">Q</span> are well formed, <span class="math inline">P \wedge Q</span> is well formed and so is <span class="math inline">(\neg a) \wedge (b \vee c)</span>.</p>
</blockquote>
<h1 id="section-1">12/5/14</h1>
<h2 id="parse-trees">Parse Trees</h2>
<p>The other way of testing for well-formedness is by constructing a parse tree out of the symbols in the formula. The top-level operator or atom is the root node of the tree, and the operands are its children. This is repeated until all the symbols have been added to the tree. Parentheses simply change the arrangement of the nodes and are not included in the parse tree.</p>
<p>For example, the expression <span class="math inline">(((\neg p) \wedge q) \rightarrow (p \wedge (q \vee (\neg r))))</span> has the following parse tree:</p>
<pre><code>      \implies
       /   \
      /     \
  \wedge   \wedge
   /  \     /  \
\neg   q   p  \vee
  |           /  \
  p          q  \neg
                  |
                  r</code></pre>
<p>Every parse tree is unique. The rules for a valid formula can be applied to a parse tree to test for well-formedness:</p>
<ul>
<li>Tree nodes must be either atoms or connectives.</li>
<li>If a node is an atom, it cannot have any children - if a node has children, it must be a connective.</li>
<li>If a node is the unary connective (<span class="math inline">\neg</span>), then it must have exactly one child.</li>
<li>If the node is a binary connective, then it must have exactly two children.</li>
<li>If a tree is empty, then it is not a well formed formula.</li>
</ul>
<p>An algorithm for testing if an expression <span class="math inline">U</span> is a well formed formula is given below</p>
<ol type="1">
<li>If <span class="math inline">U</span> is empty, produce False.</li>
<li>If <span class="math inline">U \in \operatorname{Atom}(\mathcal{L}_P)</span>, then produce True.</li>
<li>If the expression does not begin with a <span class="math inline">(</span> symbol, produce False.</li>
<li>If the second symbol is <span class="math inline">\neg</span>, then let <span class="math inline">V</span> be an expression such that <span class="math inline">U = (\neg V)</span>. Apply this algorithm again with <span class="math inline">V</span> as the expression, and if it is false, produce False.</li>
<li>Otherwise (the second symbol is not <span class="math inline">\neg</span>), apply this algorithm again with all the symbols starting from and including the second symbol, except doing nothing in step 7. If it results in False, return False. Otherwise, let <span class="math inline">V</span> be the well formed formula from the second symbol to wherever the algorithm run ended. If the next symbol after this is not a binary connective, produce False. Do the formula thing again to get a well formed formula <span class="math inline">W</span>, or produce False.</li>
<li>If the symbol after the place <span class="math inline">W</span> ended is not a <span class="math inline">)</span> symbol, produce False.</li>
<li>If the expression does not end after the <span class="math inline">)</span> symbol, produce False.</li>
<li>Produce True.</li>
</ol>
<p>This algorithm gets applied a finite number of times, proportional to the depth of the tree.</p>
<p>The <strong>height</strong> of a parse tree is the length of the longest path from the root to a leaf.</p>
<h3 id="precedence">Precedence</h3>
<p>We now introduce a system of precedence. The logical connectives listed by priority, from highest to lowest, are <span class="math inline">\neg</span>, <span class="math inline">\wedge</span>, <span class="math inline">\vee</span>, <span class="math inline">\rightarrow</span>, and <span class="math inline">\leftrightarrow</span>.</p>
<p>Precedence is the idea that some connectives get higher priority than others. For example, <span class="math inline">p \vee q \wedge r</span> could potentially mean either <span class="math inline">((p \vee q) \wedge r)</span>, or <span class="math inline">(p \vee (q \wedge r))</span>. But since <span class="math inline">\wedge</span> has a higher precedence than <span class="math inline">\vee</span>, we define <span class="math inline">p \vee q \wedge r</span> to mean <span class="math inline">(p \vee (q \wedge r))</span>.</p>
<p>When there are multiple ambiguities, we start with the ones with highest precedence. For example, <span class="math inline">\neg p \wedge q \vee r</span> is resolved to <span class="math inline">(\neg p) \wedge q \vee r</span>, then <span class="math inline">(((\neg p) \wedge q) \vee r)</span>.</p>
<p>With this in place, we can now eliminate many of the superfluous parentheses to clean up our formulas.</p>
<p><strong>Course of values induction</strong> is a type of strong induction where the inductive hypothesis used to prove the inductive conclusion is the conjunction of all the previous cases.</p>
<p>In other words, we do course of values induction by proving a property holds for <span class="math inline">M(1)</span>, and then by proving that <span class="math inline">M(1) \wedge \ldots \wedge M(k) \implies M(k + 1)</span> for any <span class="math inline">k \ge 1</span>. By the principal of strong induction, <span class="math inline">M(n)</span> therefore holds for all <span class="math inline">n \ge 1</span>.</p>
<p>Sometimes we want to use induction on the height of the parse tree. This is often useful for proving things about propositional formulas, due to the recursive nature of formulas.</p>
<p>If a formula <span class="math inline">C</span> contains the segment <span class="math inline">(\neg A)</span>, where <span class="math inline">A</span> is another formula, then <span class="math inline">A</span> is the <strong>scope</strong> of the <span class="math inline">\neg</span> within <span class="math inline">C</span>. The scope is the area where the <span class="math inline">\neg</span> applies.</p>
<p>For binary connectives, if <span class="math inline">C</span> contains <span class="math inline">(A \odot B)</span> where <span class="math inline">\odot</span> is a binary connective, then <span class="math inline">A</span> and <span class="math inline">B</span> are the left and right scopes, respectively, of the binary connective within <span class="math inline">C</span>.</p>
<p>A scope is unique to the operator. Two operators cannot have the exact same scope, though the scopes themselves can be equal.</p>
<h1 id="section-2">14/5/14</h1>
<h2 id="semantics">Semantics</h2>
<p>The semantics of a language describe how we interpret should valid formulas in that language. Semantics assigns meanings to formulas.</p>
<p>Let <span class="math inline">A</span> and <span class="math inline">B</span> be formulas, representing the propositions <span class="math inline">\mathcal{A}</span> and <span class="math inline">\mathcal{B}</span>, respectively. Then <span class="math inline">\neg A</span> represents &quot;Not <span class="math inline">\mathcal{A}</span>&quot;, <span class="math inline">A \wedge B</span> represents &quot;<span class="math inline">\mathcal{A}</span> and <span class="math inline">\mathcal{B}</span>&quot;.</p>
<p>Semantics is formally given as functions that map each formula to a value in <span class="math inline">\set{0, 1}</span> (false and true). This function can be represented using a <strong>truth table</strong>.</p>
<p>The value of a formula <span class="math inline">A</span> given a truth valuation <span class="math inline">t</span> is represented <span class="math inline">A^t</span>, with <span class="math inline">A^t \in \set{0, 1}</span>. If we used conventional function notation, we might write <span class="math inline">t(A) \in \set{0, 1}</span>.</p>
<p><strong>Truth valuations</strong> are functions that are used to assign truth values to propositional variables. The domain is the set of propositional variables in a formula, and the range is <span class="math inline">\set{0, 1}</span>. If <span class="math inline">t</span> is a truth valuation, then <span class="math inline">A^t \in \set{0, 1}</span>, where <span class="math inline">A</span> is a propositional variable.</p>
<p><span class="math inline">t \models A</span> is the same as <span class="math inline">A^t = 1</span>, while <span class="math inline">t \not\models A</span> is the same as <span class="math inline">A^t = 0</span>.</p>
<p>We can completely represent the truth valuation for a formula by listing out all possible values of the domain and the resulting value in the range. For <span class="math inline">n</span> variables, there are <span class="math inline">2^n</span> possible values.</p>
<p>We can define the truth valuation function <span class="math inline">t</span> in terms of formulas <span class="math inline">A</span> and <span class="math inline">B</span> recursively:</p>
<ol type="1">
<li><span class="math inline">A \in \operatorname{Atom}(\mathcal{L}_P) \implies A^t \in \set{0, 1}</span>.</li>
<li><span class="math inline">(\neg A) = \begin{cases} 1 &amp;\text{if } A^t = 0 \\ 0 &amp;\text{otherwise} \end{cases}</span>.</li>
<li><span class="math inline">(A \wedge B) = \begin{cases} 1 &amp;\text{if } A^t = B^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}</span>.</li>
<li><span class="math inline">(A \vee B) = \begin{cases} 1 &amp;\text{if } A^t = 1 \text{ or } B^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}</span>.</li>
<li><span class="math inline">(A \rightarrow B) = \begin{cases} 1 &amp;\text{if } A^t = 0 \text{ or } B^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}</span>.</li>
<li><span class="math inline">(A \leftrightarrow B) = \begin{cases} 1 &amp;\text{if } A^t = B^t \\ 0 &amp;\text{otherwise} \end{cases}</span>.</li>
</ol>
<p>Given a set of formulas <span class="math inline">\Sigma</span>, <span class="math inline">\Sigma^t = \begin{cases} 1 &amp;\text{if } \forall A \in \Sigma, A^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}</span>. In other words, a set of formulas is true in a given truth valuation if and only if all of the formulas in the set are true.</p>
<p><span class="math inline">\Sigma</span> is <strong>satisfiable</strong> if and only if there exists a truth valuation <span class="math inline">t</span> such that <span class="math inline">\Sigma^t = 1</span>. It this <span class="math inline">t</span> exists, then <span class="math inline">t</span> <strong>satisfies</strong> <span class="math inline">\Sigma</span>. Therefore, <span class="math inline">\emptyset</span> is satisfiable by any truth valuation.</p>
<p>A truth valuation can also be called a <strong>model</strong>.</p>
<p>A <strong>tautology</strong> is a formula which is always true, so for any truth valuation <span class="math inline">t</span>, <span class="math inline">A^t = 1</span>.</p>
<p>A <strong>contradiction</strong> is a formula which is always false, so for any truth valuation <span class="math inline">t</span>, <span class="math inline">A^t = 0</span>.</p>
<p>A <strong>semantically consistent</strong> formula is one that is not a contradiction, so there exists a truth valuation <span class="math inline">t</span> such that <span class="math inline">A^t = 1</span>.</p>
<p>Satisfiability is a property of a set of formulas where there exists a truth valuation that makes every formula in the set true.</p>
<p>The negation of a tautology is always a contradiction, and only the negation of a tautology is a contradiction. Likewise, the negation of a contradiction is a tautology, and only the negation of a contradiction is a tautology.</p>
<p>Rather than writing out the entire truth table, we can simplify formulas using the following identities:</p>
<ul>
<li><span class="math inline">\neg 0 = 1, \neg 1 = 0</span></li>
<li><span class="math inline">A \wedge 1 = 1 \wedge A = A</span></li>
<li><span class="math inline">A \wedge 0 = 0 \wedge A = 0</span></li>
<li><span class="math inline">A \vee 1 = 1 \vee A = 1</span></li>
<li><span class="math inline">A \vee 0 = 0 \vee A = A</span></li>
<li><span class="math inline">A \rightarrow 1 = 1</span></li>
<li><span class="math inline">0 \rightarrow A = 1</span></li>
<li><span class="math inline">1 \rightarrow A = A</span></li>
<li><span class="math inline">A \rightarrow 0 = \neg A</span></li>
</ul>
<p>Show that <span class="math inline">A = ((p \wedge q \rightarrow r) \wedge (p \rightarrow q)) \rightarrow (p \rightarrow r)</span> is a tautology:</p>
<blockquote>
<p>Assume <span class="math inline">p^t = 0</span>. Then <span class="math inline">A^t = (1 \rightarrow (p \rightarrow r))^t = 1</span>.<br />
Assume <span class="math inline">p^t = 1</span>. Then <span class="math inline">A^t = (((q \rightarrow r) \wedge q) \rightarrow r)^t</span>.<br />
Assume <span class="math inline">q^t = 0</span>. Then <span class="math inline">A^t = 1</span>. Assume <span class="math inline">q^t = 1</span>. Then <span class="math inline">A^t = (r \rightarrow r)^t = 1</span>.<br />
So <span class="math inline">A</span> is a tautology.</p>
</blockquote>
<p>Let <span class="math inline">\mathcal{A}</span> and <span class="math inline">\mathcal{A}_1, \ldots, \mathcal{A}_n</span> be propositions.</p>
<p>Deductive logic studies whether <span class="math inline">\mathcal{A}</span> can be deduced from <span class="math inline">\mathcal{A}_1, \ldots, \mathcal{A}_n</span>.</p>
<p>Let <span class="math inline">\Sigma \subseteq \formlp, A \in \formlp</span>.</p>
<p><span class="math inline">A</span> is a <strong>tautological consequence/semantic entailment</strong> of <span class="math inline">\Sigma</span> (written <span class="math inline">\Sigma \models A</span>) if and only if for all truth valuation <span class="math inline">t</span>, <span class="math inline">\Sigma^t = 1 \implies A^t = 1</span>. Also, <span class="math inline">\neg (\Sigma \models A) = \Sigma \not\models A</span>. We can also write out the elements of <span class="math inline">\Sigma</span> directly, like <span class="math inline">P_1, \ldots, P_n \models A</span>, which is the same as <span class="math inline">\set{P_1, \ldots, P_n} \models A</span>.</p>
<p>In other words, if <span class="math inline">\Sigma \models A</span>, then the truth of <span class="math inline">\Sigma</span> implies the truth of <span class="math inline">A</span>.</p>
<p>As a result, if <span class="math inline">\emptyset \models A</span>, then <span class="math inline">A</span> is a tautology. This is because <span class="math inline">\emptyset^t = 1</span> for any truth valuation <span class="math inline">t</span>, so <span class="math inline">A^t = 1</span> as well.</p>
<p>As a result of our semantic definitions of our operations, conjunction and disjunction is commutative and associative. So <span class="math inline">A \wedge B = B \wedge A, A \vee B = B \vee A, (A \wedge B) \wedge C = A \wedge (B \wedge C), (A \vee B) \vee C = A \vee (B \vee C)</span>.</p>
<p>Also, <span class="math inline">A_1, \ldots, A_n \models A \iff \emptyset \models A_1 \wedge \ldots \wedge A_n \rightarrow A \iff \emptyset \models A_1 \implies (A_2 \implies (\ldots (A_n \implies A) \ldots))</span>.</p>
<h1 id="section-3">21/5/14</h1>
<p>Note that <span class="math inline">\Sigma \implies A</span> is not a formula, because it cannot be created using the formula rules. It is an operator that accepts formulas as both operands.</p>
<p>It is true that <span class="math inline">\Sigma \not\models A</span> if there exists a truth valuation <span class="math inline">t</span> such that <span class="math inline">\Sigma^t = 1</span> and <span class="math inline">A^t = 0</span>.</p>
<p>If <span class="math inline">A \models B</span> and <span class="math inline">B \models A</span>, then <span class="math inline">A \equiv B</span>. Also, if <span class="math inline">A \equiv B</span> and <span class="math inline">C \equiv D</span>, then <span class="math inline">\neg A \equiv \neg B</span> and <span class="math inline">A \odot C \equiv B \odot D</span> where <span class="math inline">\odot</span> is a binary connective.</p>
<p>Also, we define <span class="math inline">\emptyset^t = 1</span> for any truth valuation <span class="math inline">t</span>.</p>
<p>If <span class="math inline">B \equiv C</span>, then <span class="math inline">A \equiv A&#39;</span> where <span class="math inline">A&#39;</span> is <span class="math inline">A</span> with any number of occurrences of <span class="math inline">B</span> replaced by <span class="math inline">C</span>. This is known as <strong>replaceability</strong>.</p>
<p>The <strong>dual</strong> of <span class="math inline">A</span>, which is a formula that uses only the connectives <span class="math inline">\neg, \wedge, \vee</span> is <span class="math inline">A&#39;</span>, which is <span class="math inline">A</span> with every <span class="math inline">\wedge</span> replaced by <span class="math inline">\vee</span>, every <span class="math inline">\vee</span> with <span class="math inline">\wedge</span>, and every atom <span class="math inline">A</span> with <span class="math inline">\neg A</span>. It is always true that <span class="math inline">A = \neg A&#39;</span>. This is basically application of De Morgan's laws to formulas.</p>
<p>We know that <span class="math inline">A \rightarrow B \equiv \neg A \vee B</span>. Because of this, <span class="math inline">\rightarrow</span> is <strong>definable</strong> in terms of <span class="math inline">\neg, \vee</span>, or <strong>reducible to</strong> <span class="math inline">\neg, \vee</span>.</p>
<p><span class="math inline">\neg</span> is a unary connective - it accepts one operand. <span class="math inline">\vee</span> is a binary connective - it accepts two operands. It is also possible to have ternary connectives and even connectives of arity 4 and above (arity is the number of operands).</p>
<p>Let <span class="math inline">f</span> be an <span class="math inline">n</span>-ary connective - a connective accepting <span class="math inline">n</span> operands. Then <span class="math inline">f A_1 \ldots A_n</span> is a formula where <span class="math inline">A_1, \ldots, A_n</span> are connected by the connective <span class="math inline">f</span>.</p>
<p>An <span class="math inline">n</span>-ary connective has <span class="math inline">2^n</span> possible input cases to consider. For <span class="math inline">k</span> possible inputs, there are <span class="math inline">2^k</span> possible output cases. So there are <span class="math inline">2^{2^n}</span> possible <span class="math inline">n</span>-ary connectives.</p>
<p>A set of connectives is <strong>adequate</strong> if and only if any <span class="math inline">n</span>-ary connective can be defined in terms of these connectives.</p>
<p>For example, <span class="math inline">\set{\wedge, \vee, \neg}</span> is an adequate set because the truth table for any <span class="math inline">n</span>-ary operator can be represented by a formula using just these connectives. This can be proven:</p>
<blockquote>
<p>Let <span class="math inline">f</span> be an <span class="math inline">n</span>-ary connective. Clearly, there are <span class="math inline">2^n</span> possible truth valuations <span class="math inline">t_1, \ldots, t_{2^n}</span> for <span class="math inline">A_1, \ldots, A_n</span>. Let <span class="math inline">t</span> be one of these truth valuations.<br />
Let <span class="math inline">T(t) = T_1(t) \wedge \ldots \wedge T_n</span>(t) where <span class="math inline">T_i(t) = \begin{cases} A_i &amp;\text{if } A_i^t = 1 \\ \neg A_i &amp;\text{if } A_i^t = 0 \end{cases}</span>. For example, if <span class="math inline">A_1^t = 1, A_2^t = 0, A_3^t = 1</span>, then <span class="math inline">T = A_1 (\neg A_2) A_3</span>.<br />
Clearly, <span class="math inline">T(t_i)^{t_j}</span> is true if and only if <span class="math inline">t_i = t_j</span>. In other words, <span class="math inline">T(t)</span> results in a formula that is true in only the truth valuation <span class="math inline">t</span> and no others. Let <span class="math inline">V = T(t_1) \vee \ldots \vee T(t_{2^n})</span>, where there is a <span class="math inline">T(i)</span> term if and only if <span class="math inline">(f A_1, \ldots, A_n)^t = 1</span>.<br />
Clearly, this is a formula that is true when <span class="math inline">f A_1, \ldots, A_n</span> is true, and false otherwise. Therefore, <span class="math inline">f A_1, \ldots, A_n = V</span>.<br />
So any <span class="math inline">f</span> can be defined in terms of <span class="math inline">\set{\wedge, \vee, \neg}</span>, which makes it adequate.</p>
</blockquote>
<p>We usually prove sets are adequate by defining the connectives in a set that is already known to be adequate in terms of the connectives of this set. If a connective <span class="math inline">f</span> is definable in terms of a set of connectives <span class="math inline">A</span>, and every connective in that set is definable in terms of another set <span class="math inline">B</span>, then <span class="math inline">f</span> is definable in terms of <span class="math inline">B</span>.</p>
<p>This is because we could define <span class="math inline">f</span> first in terms of <span class="math inline">A</span>, and then define that in terms of <span class="math inline">B</span>.</p>
<p>For example, <span class="math inline">\set{\wedge, \neg}</span> is adequate because <span class="math inline">\wedge</span> and <span class="math inline">\neg</span> are already in the set, and <span class="math inline">A \vee B \equiv \neg((\neg A) \wedge (\neg B))</span>, so <span class="math inline">\vee</span> is definable in terms of <span class="math inline">\set{\wedge, \neg}</span>.</p>
<h1 id="section-4">26/5/14</h1>
<p>The Schroder connective is defined as <span class="math inline">A \downarrow B</span> where <span class="math inline">A \downarrow B \equiv \neg (A \wedge B)</span> - the NOR operation. This connective is interesting because it can make an adequate set by itself - <span class="math inline">\set{\downarrow}</span> is an adequate set.</p>
<p><span class="math inline">\set{\neg, \rightarrow}</span> is an adequate set.</p>
<h2 id="proof-calculus">Proof Calculus</h2>
<p>We want a calculus for reasoning about propositional logic. This will allow us to simplify proofs of validity.</p>
<p>In this course we will be looking at the Hilbert and natural deduction systems for formal proof calculus.</p>
<p>Let <span class="math inline">\Sigma = \set{\alpha_1, \ldots, \alpha_n}</span>. This is a set of premises.</p>
<p><span class="math inline">\Sigma \models d</span> is the same as <span class="math inline">\forall t, \Sigma^t = 1 \implies d^t = 1</span>.</p>
<p><span class="math inline">\Sigma \vdash \alpha</span> means that <span class="math inline">\alpha</span> is provable or deducible from <span class="math inline">\Sigma</span>.</p>
<h2 id="hilbert-system">Hilbert System</h2>
<p>The <strong>Hilbert System</strong> is a deductive system over the set of propositional logic formulas.</p>
<p><span class="math inline">\Sigma \vdash_H \alpha</span> means that <span class="math inline">\alpha</span> is provable or deducible in the Hilbert system. <span class="math inline">\vdash_H A</span> means <span class="math inline">\emptyset \vdash_H A</span>.</p>
<p><span class="math inline">\Sigma</span> is a set of formulas known as premises, and from them we can deduce <span class="math inline">\delta</span> using axioms and inference rules.</p>
<p>Axioms are basically just tautologies. In this course we will only be using axioms over <span class="math inline">\set{\neg, \rightarrow}</span> since this set is small and results in fewer axioms:</p>
<ol type="1">
<li><span class="math inline">\phi \rightarrow (\psi \rightarrow \phi)</span> - basically, this is just a special case of</li>
<li><span class="math inline">(\phi \rightarrow (\psi \rightarrow \xi)) \rightarrow ((\phi \rightarrow \psi) \rightarrow (\phi \rightarrow \xi))</span> - basically, <span class="math inline">\rightarrow</span> is distributive</li>
<li><span class="math inline">(\neg \phi \rightarrow \neg \psi) \rightarrow (\psi \rightarrow \phi)</span> - basically, the contrapositive of a formula implies the formula</li>
</ol>
<p>Here, <span class="math inline">\phi, \psi, \xi</span> are any formulas.</p>
<p><strong>Inference rules</strong> are manipulations we can perform on formulas to obtain new formulas. In this system we have only Modus Ponens (MP): <span class="math inline">\set{\phi, \phi \rightarrow \psi} \rightarrow_H \psi</span>.</p>
<p>A <strong>proof</strong> is a set of formulas that includes axioms, premises, and conclusions. We start with the axioms that we know are true, so we use inference rules over the axioms and previously obtained formulas, listing out each new formula obtained, until we get the desired result.</p>
<p>For example, prove that <span class="math inline">\vdash_H A \rightarrow A</span>:</p>
<ol type="1">
<li><span class="math inline">A \rightarrow ((A \rightarrow A) \rightarrow A)</span> (Axiom 1 where <span class="math inline">\psi = A \rightarrow A</span>)</li>
<li><span class="math inline">(A \rightarrow ((A \rightarrow A) \rightarrow A)) \rightarrow ((A \rightarrow (A \rightarrow A)) \rightarrow (A \rightarrow A))</span> (Axiom 2 where <span class="math inline">\psi = A \rightarrow A</span>)</li>
<li><span class="math inline">(A \rightarrow (A \rightarrow A)) \rightarrow (A \rightarrow A)</span> (Modus Ponens on 1 and 2)</li>
<li><span class="math inline">A \rightarrow A</span> (Modus Ponens on 1 and 3)</li>
</ol>
<p>Prove that <span class="math inline">\set{A \rightarrow B, B \rightarrow C} \vdash_H A \rightarrow C</span>:</p>
<ol type="1">
<li><span class="math inline">A \rightarrow B</span> (Premise 1)</li>
<li><span class="math inline">B \rightarrow C</span> (Premise 2)</li>
<li><span class="math inline">((B \rightarrow C) \rightarrow (A \rightarrow (B \rightarrow C)))</span> (Axiom 1 where <span class="math inline">\phi = B \rightarrow C</span>)</li>
<li><span class="math inline">A \rightarrow (B \rightarrow C)</span> (Modus Ponens on 1 and 3)</li>
<li><span class="math inline">(A \rightarrow (B \rightarrow C)) \rightarrow ((A \rightarrow B) \rightarrow (A \rightarrow C))</span> (Axiom 2)</li>
<li><span class="math inline">(A \rightarrow B) \rightarrow (A \rightarrow C)</span> (Modus Ponens on 4 and 5)</li>
<li><span class="math inline">A \rightarrow C</span> (Modus Ponens on 1 and 6)</li>
</ol>
<p>The <strong>deduction theorem</strong> says that <span class="math inline">\Sigma \vdash_H A \rightarrow B</span> if and only if <span class="math inline">\Sigma \cup A \vdash_H B</span>. So <span class="math inline">\set{\alpha_1, \ldots, \alpha_n} \vdash_H \alpha</span> is the same as <span class="math inline">\emptyset \vdash_H (\alpha_1 \rightarrow (\ldots (alpha_n \rightarrow \alpha) \ldots))</span>.</p>
<p>In other words, to prove an implication, we just have to assume the antecedent and use it to prove the consequent.</p>
<h1 id="section-5">28/5/14</h1>
<p>Prove that <span class="math inline">\neg \neg A \vdash_H A</span>:</p>
<ol type="1">
<li><span class="math inline">\neg \neg A</span> (Premise 1)</li>
<li><span class="math inline">\neg \neg A \rightarrow (\neg \neg \neg \neg A \rightarrow \neg \neg A)</span> (Axiom 1 where <span class="math inline">\psi = \neg \neg \neg \neg A</span>)</li>
<li><span class="math inline">\neg \neg \neg \neg A \rightarrow \neg \neg A</span> (Modus Ponens on 1 and 2)</li>
<li><span class="math inline">(\neg (\neg \neg \neg A) \rightarrow \neg A) \rightarrow (\neg A \rightarrow \phi)</span> (Axiom 3 where <span class="math inline">\phi = \neg \neg \neg A</span>)</li>
<li><span class="math inline">\neg A \rightarrow \neg \neg \neg A</span> (Modus Ponens on 3 and 4)</li>
<li><span class="math inline">(\neg A \rightarrow \neg \neg \neg A) \rightarrow (\neg \neg A \rightarrow A)</span> (Axiom 3 where <span class="math inline">\psi = \neg \neg A</span>)</li>
<li><span class="math inline">\neg \neg A \rightarrow A</span> (Modus Ponens on 5 and 6)</li>
<li><span class="math inline">A</span> (Modus Ponens on 1 and 7)</li>
</ol>
<p><span class="math inline">\Sigma \models \alpha</span> is a semantic construct. This is associated with soundness.</p>
<p><span class="math inline">\Sigma \vdash \alpha</span> is a syntactical construct. This is associated with completeness.</p>
<p>Formulas must be semantically entailed before it can be syntactically entailed. We need it to be semantically sound before proving it is complete.</p>
<p>Here are some rules of thumb to more easily construct proofs.</p>
<ul>
<li>Axiom 3 is often helpful in adding or remove negations, by putting the formula with the negation on one of the sides and the formula without on the other.</li>
<li>Axiom 1 is useful for getting the converse and setting up modus ponens to simplify.</li>
<li>Axiom 2 is just... just use it as a last resort.</li>
<li>General pattern is premise/axiom, modus ponens, premise/axiom, etc.</li>
<li>Remember the proofs for some more sane manipulation rules like <span class="math inline">\neg \neg A = A</span> and use those instead of these crazy axioms.</li>
</ul>
<h2 id="natural-deduction">Natural Deduction</h2>
<p>In natural deduction, we infer a <strong>conclusion</strong> from the <strong>premises</strong> using various <strong>proof rules</strong>.</p>
<p>Natural deduction was born out of people noticing that the Hilbert system is terribly complicated even for the simplest of proofs.</p>
<p>Let <span class="math inline">\Sigma = \set{\alpha_1, \ldots, \alpha_n}</span> be the set of all the premises.</p>
<p>For convenience, we define that <span class="math inline">\alpha_1, \ldots, \alpha_n</span> is equivalent to <span class="math inline">\set{\alpha_1, \ldots, \alpha_n}</span>.</p>
<p>We also define that <span class="math inline">\Sigma, \alpha</span> is equivalent to <span class="math inline">\Sigma \cup \set{\alpha}</span>, and given a set <span class="math inline">S</span>, then <span class="math inline">\Sigma, S</span> is equivalent to <span class="math inline">\Sigma \cup S</span>.</p>
<p><span class="math inline">\Sigma \vdash \alpha</span> is not a formula, but is a proposition.</p>
<blockquote>
<p>If the train arrives late and there are no taxis at the station, then John is late for his meeting.<br />
John is not late for his meeting.<br />
The train did arrive late.<br />
Therefore, there were taxis at the station.</p>
</blockquote>
<p>The above can be written as follows:</p>
<blockquote>
<p>Let <span class="math inline">l</span> represent the train being late. Let <span class="math inline">m</span> represent being late to the meeting. Let <span class="math inline">t</span> represent there being taxis.<br />
Then <span class="math inline">l \wedge \neg t \rightarrow m</span>, <span class="math inline">\neg m</span>, <span class="math inline">l</span>, so <span class="math inline">t</span>.</p>
</blockquote>
<p>The rules of deduction in ND are:</p>
<table>
<colgroup>
<col style="width: 9%" />
<col style="width: 27%" />
<col style="width: 34%" />
<col style="width: 25%" />
<col style="width: 3%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Symbol</th>
<th style="text-align: left;">Rule</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Rule Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Reflexivity</td>
<td style="text-align: left;"><span class="math inline">\operatorname{Ref}</span></td>
<td style="text-align: left;"><span class="math inline">A \vdash A</span></td>
<td style="text-align: left;">Anything can be deduced from itself.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="even">
<td style="text-align: left;">Addition of Premises</td>
<td style="text-align: left;"><span class="math inline">+</span> with <span class="math inline">\Sigma_1 \vdash \alpha</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma_1 \vdash \alpha</span> implies <span class="math inline">\Sigma_1 \cup \Sigma_2 \vdash \alpha</span></td>
<td style="text-align: left;">Premises can be freely added to valid arguments.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Reflexive premises</td>
<td style="text-align: left;"><span class="math inline">\epsilon</span></td>
<td style="text-align: left;"><span class="math inline">\alpha \in \Sigma</span> implies <span class="math inline">\Sigma \vdash \alpha</span></td>
<td style="text-align: left;">Anything can be deduced if it is itself deducible.</td>
<td style="text-align: left;">Derived</td>
</tr>
<tr class="even">
<td style="text-align: left;">Negation-introduction</td>
<td style="text-align: left;"><span class="math inline">\neg+</span> with <span class="math inline">\Sigma, \alpha \vdash \psi</span> and <span class="math inline">\Sigma, \alpha \vdash \neg \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma, \alpha \vdash \psi</span> and <span class="math inline">\Sigma, \alpha \vdash \neg \psi</span> implies <span class="math inline">\Sigma \vdash \neg \alpha</span></td>
<td style="text-align: left;">If <span class="math inline">\alpha</span> results in a contradiction, then <span class="math inline">\neg \alpha</span> must be true.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Negation-elimination</td>
<td style="text-align: left;"><span class="math inline">\neg-</span> with <span class="math inline">\Sigma, \neg \alpha \vdash \psi</span> and <span class="math inline">\Sigma, \neg \alpha \vdash \neg \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma, \neg \alpha \vdash \psi</span> and <span class="math inline">\Sigma, \neg \alpha \vdash \neg \psi</span> implies <span class="math inline">\Sigma \vdash \alpha</span></td>
<td style="text-align: left;">If <span class="math inline">\neg \alpha</span> results in a contradiction, then <span class="math inline">\alpha</span> must be true.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="even">
<td style="text-align: left;">Conjunction-introduction</td>
<td style="text-align: left;"><span class="math inline">\wedge+</span> with <span class="math inline">\Sigma \vdash \alpha</span> and <span class="math inline">\Sigma \vdash \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha</span> and <span class="math inline">\Sigma \vdash \psi</span> implies <span class="math inline">\Sigma \vdash \alpha \wedge \psi</span></td>
<td style="text-align: left;">If something implies two things individually, then it implies both together.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Conjunction-elimination</td>
<td style="text-align: left;"><span class="math inline">\wedge-</span> with <span class="math inline">\Sigma \vdash \alpha \wedge \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha \wedge \psi</span> implies <span class="math inline">\Sigma \vdash \alpha</span> and <span class="math inline">\Sigma \vdash \psi</span></td>
<td style="text-align: left;">If two things both follow from the premises, each one follows individually.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="even">
<td style="text-align: left;">Implication-introduction</td>
<td style="text-align: left;"><span class="math inline">\rightarrow+</span> with <span class="math inline">\Sigma, \alpha \vdash \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma, \alpha \vdash \psi</span> implies <span class="math inline">\Sigma \vdash \alpha \rightarrow \psi</span></td>
<td style="text-align: left;">If <span class="math inline">\psi</span> can be deduced from <span class="math inline">\alpha</span>, then <span class="math inline">\alpha \rightarrow \psi</span>.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Implication-elimination</td>
<td style="text-align: left;"><span class="math inline">\rightarrow-</span> with <span class="math inline">\Sigma \vdash \alpha \rightarrow \psi</span> and <span class="math inline">\Sigma \vdash \alpha</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha \rightarrow \psi</span> and <span class="math inline">\Sigma \vdash \alpha</span> implies <span class="math inline">\Sigma \vdash \psi</span></td>
<td style="text-align: left;">If something implies something else and that thing is true, then so is the other.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="even">
<td style="text-align: left;">Disjunction-introduction</td>
<td style="text-align: left;"><span class="math inline">\vee+</span> with <span class="math inline">\Sigma \vdash \alpha</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha</span> implies <span class="math inline">\Sigma \vdash \alpha \vee \psi</span> and <span class="math inline">\Sigma \vdash \psi \vee \alpha</span></td>
<td style="text-align: left;">Something deducible implies that it or something else is deducible.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Disjunction-elimination</td>
<td style="text-align: left;"><span class="math inline">\vee-</span> with <span class="math inline">\Sigma, \alpha_1 \vdash \psi</span> and <span class="math inline">\Sigma, \alpha_2 \vdash \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma, \alpha_1 \vdash \psi</span> and <span class="math inline">\Sigma, \alpha_2 \vdash \psi</span> implies <span class="math inline">\Sigma, \alpha_1 \vee \alpha_2 \vdash \psi</span></td>
<td style="text-align: left;">If two things individually imply another, then either implies it.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="even">
<td style="text-align: left;">Double-implication-introduction</td>
<td style="text-align: left;"><span class="math inline">\leftrightarrow+</span> with <span class="math inline">\Sigma, \alpha \vdash \psi</span> and <span class="math inline">\Sigma, \psi \vdash \alpha</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma, \alpha \vdash \psi</span> and <span class="math inline">\Sigma, \psi \vdash \alpha</span> implies <span class="math inline">\Sigma \vdash \alpha \leftrightarrow \psi</span></td>
<td style="text-align: left;">If one thing implies another and the other implies it, they are equivalent.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Double-implication-elimination 1</td>
<td style="text-align: left;"><span class="math inline">\leftrightarrow-</span> with <span class="math inline">\Sigma \vdash \alpha \leftrightarrow \alpha</span> and <span class="math inline">\Sigma \vdash \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha \leftrightarrow \psi</span> and <span class="math inline">\Sigma \vdash \alpha</span> implies <span class="math inline">\Sigma \vdash \psi</span></td>
<td style="text-align: left;">If two things are equivalent and the first is deducible, so is the second.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="even">
<td style="text-align: left;">Double-implication-elimination 2</td>
<td style="text-align: left;"><span class="math inline">\leftrightarrow-</span> with <span class="math inline">\Sigma \vdash \alpha \leftrightarrow \psi</span> and <span class="math inline">\Sigma \vdash \alpha</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha \leftrightarrow \psi</span> and <span class="math inline">\Sigma \vdash \psi</span> implies <span class="math inline">\Sigma \vdash \alpha</span></td>
<td style="text-align: left;">If two things are equivalent and the second is deducible, so is the first.</td>
<td style="text-align: left;">Built-in</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Transitivity of deducibility</td>
<td style="text-align: left;"><span class="math inline">\operatorname{Tr}</span> with <span class="math inline">\Sigma_1 \vdash \Sigma_2</span> and <span class="math inline">\Sigma_2 \vdash \Sigma_3</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma_1 \vdash \Sigma_2</span> and <span class="math inline">\Sigma_2 \vdash \Sigma_3</span> implies <span class="math inline">\Sigma_1 \vdash \Sigma_3</span></td>
<td style="text-align: left;">If one thing implies a second, which implies a third, then the first implies the last.</td>
<td style="text-align: left;">Derived</td>
</tr>
</tbody>
</table>
<p>;wip: add all the other rules here, such as de morgan</p>
<p>Prove the <span class="math inline">\epsilon</span> rule from the basic rules <span class="math inline">\operatorname{Ref}, +</span>:</p>
<blockquote>
<p>Let <span class="math inline">A = \Sigma \setminus \set{\alpha}</span>.<br />
Clearly, <span class="math inline">\alpha \implies \alpha</span> by <span class="math inline">\operatorname{Ref}</span> (step 1).<br />
So <span class="math inline">\set{\alpha} \cup A \vdash \alpha</span> by <span class="math inline">+</span> with step 1 (step 2).<br />
Since <span class="math inline">\set{\alpha} \cup A = \Sigma</span>, <span class="math inline">\Sigma \vdash \alpha</span> (step 3, conclusion).</p>
</blockquote>
<p>Prove that <span class="math inline">\neg \neg p \vdash p</span>:</p>
<ol type="1">
<li><span class="math inline">\neg \neg p, \neg p \vdash \neg \neg p</span> (<span class="math inline">\epsilon</span>).</li>
<li><span class="math inline">\neg \neg p, \neg p \vdash \neg p</span> (<span class="math inline">\epsilon</span>).</li>
<li><span class="math inline">\neg \neg p \vdash p</span> (<span class="math inline">\neg-</span>).</li>
</ol>
<p>Note that implication-introduction and implication-elimination is very similar to the deduction theorem.</p>
<p>Prove that <span class="math inline">A \rightarrow B, B \rightarrow C \vdash A \rightarrow C</span>:</p>
<ol type="1">
<li><span class="math inline">A \rightarrow B, B \rightarrow C, A \vdash A \rightarrow B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, B \rightarrow C, A \vdash A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, B \rightarrow C, A \vdash B</span> (<span class="math inline">\rightarrow-</span> with step 1 and 2)</li>
<li><span class="math inline">A \rightarrow B, B \rightarrow C, A \vdash B \rightarrow C</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, B \rightarrow C, A \vdash C</span> (<span class="math inline">\rightarrow-</span> with step 3 and 4)</li>
<li><span class="math inline">A \rightarrow B, B \rightarrow C \vdash A \rightarrow C</span> (<span class="math inline">\rightarrow+</span> with step 5)</li>
</ol>
<h1 id="section-6">2/6/14</h1>
<p>If a system is sound and complete, then arguments can be proved if and only if they are valid.</p>
<p>We can write <span class="math inline">A, B \vdash C</span> as <span class="math inline">\frac{A \qquad B}{C}</span>. This is known as <strong>inference notation</strong>.</p>
<h3 id="formal-proofs">Formal Proofs</h3>
<p>A <strong>formal proof</strong> for <span class="math inline">\Sigma_k \vdash \alpha_k</span> is simply a sequence of the natural deduction rules - <span class="math inline">\Sigma_1 \vdash \alpha_1, \ldots, \Sigma_k \vdash \alpha_k</span>. If this is the case, then <span class="math inline">\alpha_n</span> is <strong>formally deducible</strong> from <span class="math inline">\Sigma_n</span> - it can be proven from those premises.</p>
<p>Note that <span class="math inline">\Sigma \vdash \alpha</span> is very different from <span class="math inline">\Sigma \models \alpha</span> - the former deals purely with syntax, while the latter deals with semantics - what the symbols actually mean.</p>
<p>Negation-introduction (<span class="math inline">\neg+</span>) is also called <strong>contradiction</strong> or <strong>reductio ad absurdum</strong>. It is usually the rule we use when we want to prove by contradiction, and is very similar to negation-elimination (<span class="math inline">\neg-</span>).</p>
<p>Prove that <span class="math inline">p \vdash \neg \neg p</span>:</p>
<ol type="1">
<li><span class="math inline">p, \neg p \vdash p</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">p, \neg p \vdash \neg p</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">p \vdash \neg \neg p</span> (reductio ad absurdum with step 1 and 2)</li>
</ol>
<p>In formal proofs, we usually start off by stating premises (also called assumptions), and then adding rules and modifying results until we arrive at the conclusion of the proof. The conclusion of the proof is the thing we are trying to prove.</p>
<p>The proof format we have been using so far is in something known as <strong>line/sequent/turnstile notation</strong>. The <span class="math inline">\vdash</span> symbol is a sequent or turnstile, with all premises before it and all conclusions after.</p>
<p>In <strong>box notation</strong>, we write assumptions, and then we draw a box that contains it, the box acts like a &quot;scope&quot; in which the assumptions hold and we can directly write the deduced thing. Inside the box we can directly write the resulting formulas without writing the <span class="math inline">\alpha_1, \ldots, \alpha_n \vdash</span> before it. Scopes can nest, and this saves a lot of rewriting of premises.</p>
<p>Alternatively, we might indent the values instead of drawing a box around them. For example, the previous proof that <span class="math inline">A \rightarrow B, B \rightarrow C \vdash A \rightarrow C</span>:</p>
<ol type="1">
<li><span class="math inline">A \rightarrow B, B \rightarrow C</span> (assumption)</li>
<li>The following is indented or drawn in a box:
<ol type="1">
<li><span class="math inline">A \rightarrow B, B \rightarrow C, A</span> (assumption)</li>
<li><span class="math inline">A \rightarrow B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">B</span> (<span class="math inline">\rightarrow-</span> with step 2.2 and 2.3)</li>
<li><span class="math inline">B \rightarrow C</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">C</span> (<span class="math inline">\rightarrow-</span> with step 2.4 and 2.5)</li>
</ol></li>
<li><span class="math inline">A \rightarrow C</span> (<span class="math inline">\rightarrow+</span> with step 2.6):</li>
</ol>
<p>When we begin a box or indentation, we insert an assumption. When we close a box, we remove the assumption. This ability to insert and remove asumptions keeps our proofs clean and organized.</p>
<p>Boxes or indentations can nest, and have lexical scope - when we have a box inside a box, we can use any statements above it, even if it is in a parent box. Outside of a box, we cannot use any of the resulting formulas directly - they are always attached to their assumptions. For example, in the above example we could not state <span class="math inline">C</span> in step 3, but we could use <span class="math inline">A \rightarrow B, B \rightarrow C, A \vdash C</span> in the <span class="math inline">\rightarrow+</span> rule.</p>
<p>A box is often closed when we arrive at a conclusion using a rule such as <span class="math inline">\neg-</span>, <span class="math inline">\rightarrow+</span>, or <span class="math inline">\vee-</span>. Usages of <span class="math inline">\neg-</span> and <span class="math inline">\rightarrow+</span> are usually found right after a box closes. <span class="math inline">\vee-</span> is usually found after two boxes.</p>
<p>All boxes must be closed by the end of the argument. Otherwise, there are extra premises and the proof is not yet complete.</p>
<p>Elimination rules turn two statements into one. Introduction rules introduce new statements, or turn one statement into two.</p>
<h1 id="section-7">4/6/14</h1>
<h2 id="soundnesscompleteness">Soundness/Completeness</h2>
<p><strong>Soundness</strong> is a property of a deductive system where it is impossible to prove any invalid arguments.</p>
<p><strong>Completeness</strong> is a property of a deductive system where it is always possible to prove valid arguments.</p>
<p>The <strong>soundness theorem</strong> states that if something is provable, then it is valid - <span class="math inline">\Sigma \vdash \alpha</span> implies that <span class="math inline">\Sigma \models \alpha</span>.</p>
<p>In practice, we prove soundness by using the contrapositive: by proving that <span class="math inline">\Sigma \not\models \alpha</span> implies <span class="math inline">\Sigma \not\vdash \alpha</span>.</p>
<p>If <span class="math inline">A \vdash B</span> and <span class="math inline">B \vdash C</span>, then <span class="math inline">A \vdash C</span>.</p>
<p>In other words, if <span class="math inline">\Sigma&#39; = \set{A_1, \ldots, A_n}</span> and <span class="math inline">\Sigma \vdash A_1, \ldots, \Sigma \vdash A_n</span> and <span class="math inline">\Sigma&#39; \vdash \alpha</span>, then <span class="math inline">\Sigma \vdash \alpha</span></p>
<p>Proof:</p>
<ol type="1">
<li><span class="math inline">A_1, \ldots, A_n \vdash \alpha</span> (Premise)</li>
<li><span class="math inline">A_1, \ldots, A_{n - 1} \vdash A_n \rightarrow \alpha</span> (<span class="math inline">\rightarrow+</span>)</li>
<li><span class="math inline">\vdash A_1 \rightarrow (\ldots (A_n \rightarrow \alpha) \ldots)</span></li>
<li><span class="math inline">\Sigma \vdash A_1 \rightarrow (\ldots (A_n \rightarrow \alpha) \ldots)</span></li>
<li><span class="math inline">\Sigma \vdash A_1</span> (premise)</li>
<li><span class="math inline">\Sigma \vdash A_2 \rightarrow (\ldots (A_n \rightarrow \alpha) \ldots)</span></li>
<li><span class="math inline">\Sigma \vdash \alpha</span></li>
</ol>
<p>The proof rules of Natural Deduction are purely syntactic - they only shuffle symbols around without considering what they mean. Now we connect it with the actual semantics.</p>
<p>Soundness of natural deduction means that formal proofs demonstrate tautological consequences - <span class="math inline">\Sigma \vdash \alpha</span> implies that <span class="math inline">\Sigma \models \alpha</span>. In other words, every proof should be a valid argument.</p>
<p>Completeness of natural deduction means that tautological consequences are provable using natural deduction - <span class="math inline">\Sigma \models \alpha</span> implies that <span class="math inline">\Sigma \vdash \alpha</span>. In other words, every valid argument should have a proof.</p>
<p>Basically, anything provable by truth tables can also be proven using the ND rules.</p>
<p>Since ND is sound and complete, <span class="math inline">\Sigma \models \alpha</span> if and only if <span class="math inline">\Sigma \vdash \alpha</span>.</p>
<p>Also, <span class="math inline">\rightarrow</span> does not have an associative property, so <span class="math inline">(A \rightarrow B) \rightarrow C</span> is not the same as <span class="math inline">A \rightarrow (B \rightarrow C)</span>.</p>
<h1 id="section-8">9/6/14</h1>
<h3 id="natural-deduction-1">Natural Deduction</h3>
<p>Soundness and completeness is rather intuitive. For example, it is obvious that if <span class="math inline">p</span> and <span class="math inline">q</span> are true, then <span class="math inline">p</span> is also true, so <span class="math inline">p \wedge q \models p</span>. In ND, this is represented using the <span class="math inline">\wedge-</span> rule, which states <span class="math inline">p \wedge q \vdash p</span>.</p>
<p>When we want to prove that two formulas are tautologically equivalent, we can either use a truth table, or write a formal proof.</p>
<p>A <strong>sound</strong> formula is one where its proof, <span class="math inline">\Sigma \vdash \alpha</span>, implies <span class="math inline">\Sigma \models \alpha</span>.</p>
<p>We can prove the soundness theorem for ND using strong induction over the length of the proof:</p>
<blockquote>
<p>Let <span class="math inline">n</span> be the length of the proof in steps.<br />
Clearly, if <span class="math inline">n = 1</span>, then the proof must have the form <span class="math inline">\Sigma, \alpha \vdash \alpha</span> (<span class="math inline">\epsilon</span>), since this is the only rule that can prove something in one step.<br />
Clearly, <span class="math inline">\Sigma, \phi \models \phi</span> because anything is a tautological consequence of itself.<br />
Assume for some <span class="math inline">k \ge 1</span> that all proofs of length <span class="math inline">k</span> or less are sound - the inductive hypothesis.<br />
Then a proof of length <span class="math inline">k + 1</span> has the steps <span class="math inline">\alpha_1, \ldots, \alpha_k, \phi</span>, with rules associated with each step.<br />
Clearly, <span class="math inline">\alpha_1, \ldots, \alpha_k</span> is sound, by the inductive hypothesis.<br />
We want to prove that <span class="math inline">\alpha_1, \ldots, \alpha_k, \phi</span> is also sound.<br />
Clearly, <span class="math inline">\phi</span> is the result of applying the ND rules. So each rule is a possible case and we need to check each rule to verify that the proof of length <span class="math inline">k + 1</span> is sound.<br />
Assume the last rule is <span class="math inline">\wedge+</span>. Then <span class="math inline">\phi</span> is of the form <span class="math inline">\alpha_i \wedge \alpha_j</span> where <span class="math inline">i &lt; k, j &lt; k</span>.<br />
Then there must be sound proofs of <span class="math inline">\alpha_i</span> and <span class="math inline">\alpha_j</span>, by the inductive hypothesis.<br />
So <span class="math inline">\Sigma_i \models \alpha_i</span> and <span class="math inline">\Sigma_j \models \alpha_j</span>.<br />
By a truth table, <span class="math inline">\Sigma \models \alpha_i \wedge \alpha_j</span>, so <span class="math inline">\phi</span> is sound.<br />
We can use this technique to verify this for every ND rule.<br />
Therefore, <span class="math inline">\Sigma \vdash \phi</span> is always sound - it always implies <span class="math inline">\Sigma \models \phi</span>.</p>
</blockquote>
<p><strong>Syntactical consistency</strong> is a property of sets of formulas <span class="math inline">\Sigma \subseteq \formlp</span> where there does not exist <span class="math inline">\alpha \in \Sigma</span> such that <span class="math inline">\Sigma \vdash \alpha</span> and <span class="math inline">\Sigma \vdash \neg \alpha</span> at the same time - that it not possible to derive a contradiction from the premises.</p>
<p>This is not to be confused with semantic consistency, which applies only to formulas.</p>
<p>A set of formulas <span class="math inline">\Sigma \subseteq \formlp</span> is <strong>maximally consistent</strong> if and only if <span class="math inline">\Sigma</span> is consistent and any <span class="math inline">\alpha \in \formlp \setminus \Sigma</span>, <span class="math inline">\Sigma \cup \set{\alpha}</span> is inconsistent. In other words, it is the largest possible set of consistent formulas.</p>
<p>There are multiple possible maximally consistent sets.</p>
<p>If <span class="math inline">\Sigma</span> is maximally consistent:</p>
<ul>
<li><span class="math inline">p \in \Sigma</span> if and only if <span class="math inline">\Sigma \vdash \alpha</span>.</li>
<li><span class="math inline">\alpha \wedge \phi \in \Sigma</span> if and only if <span class="math inline">\Sigma \vdash \alpha</span> and <span class="math inline">\Sigma \vdash \phi</span>.</li>
<li><span class="math inline">\alpha \vee \phi \in \Sigma</span> if and only if <span class="math inline">\Sigma \vdash \alpha</span> or <span class="math inline">\Sigma \vdash \phi</span>.</li>
<li><span class="math inline">\alpha \rightarrow \phi \in \Sigma</span> if and only if <span class="math inline">\Sigma \vdash \alpha \implies \Sigma \vdash \phi</span>.</li>
<li><span class="math inline">\alpha \leftrightarrow \phi \in \Sigma</span> if and only if <span class="math inline">\Sigma \vdash \alpha \iff \Sigma \vdash \phi</span>.</li>
</ul>
<p>We can prove the completeness theorem for ND by proving the contrapositive:</p>
<blockquote>
<p>We want to prove <span class="math inline">\Sigma \not\vdash \phi \implies \Sigma \not\models \phi</span>.<br />
Assume <span class="math inline">\Sigma \not\vdash \phi</span>.<br />
Then <span class="math inline">\Sigma \cup \set{\neg \alpha}</span> is syntactically consistent, because there is no way that <span class="math inline">\Sigma \vdash \alpha</span> or <span class="math inline">\Sigma \vdash \neg \phi</span> for any <span class="math inline">\phi \in \Sigma</span>.<br />
So there exists a truth valuation <span class="math inline">t</span> such that <span class="math inline">\Sigma^t = 1 \wedge (\neg \phi)^t = 1</span>.<br />
So <span class="math inline">\Sigma \not\models \phi</span>.</p>
</blockquote>
<p>The <strong>Lindenbaum Lemma</strong> says that any consistent set of formulas can be extended into a maximally consistent set.</p>
<h1 id="section-9">11/6/14</h1>
<p>Soundness theorem: <span class="math inline">\Sigma \vdash \alpha \implies \Sigma \models \alpha</span>.</p>
<p>Completeness theorem: <span class="math inline">\Sigma \models \alpha \implies \Sigma \vdash \alpha</span>, and its contrapositive <span class="math inline">\Sigma \not\vdash \alpha \implies \Sigma \not\models \alpha</span>.</p>
<p>Soundness: <span class="math inline">\Sigma</span> is satisfiable implies <span class="math inline">\Sigma</span> is sound.</p>
<p>Completeness: <span class="math inline">\Sigma</span> is sound implies <span class="math inline">\Sigma</span> is satisfiable.</p>
<p>Logical connectives:</p>
<ul>
<li><span class="math inline">\neg p</span> - not <span class="math inline">p</span>, <span class="math inline">p</span> does not hold, it is not the case that <span class="math inline">p</span>, <span class="math inline">p</span> is false</li>
<li><span class="math inline">p \wedge q</span> - <span class="math inline">p</span> and <span class="math inline">q</span>, <span class="math inline">p</span> but <span class="math inline">q</span>, not only <span class="math inline">p</span> but <span class="math inline">q</span>, <span class="math inline">p</span> while <span class="math inline">q</span>, <span class="math inline">p</span> despite <span class="math inline">q</span>, <span class="math inline">p</span> yet <span class="math inline">q</span>, <span class="math inline">p</span> although <span class="math inline">q</span></li>
<li><span class="math inline">p \vee q</span> - <span class="math inline">p</span> or <span class="math inline">q</span>, <span class="math inline">p</span> or <span class="math inline">q</span> or both, <span class="math inline">p</span> and/or q, <span class="math inline">p</span> unless <span class="math inline">q</span></li>
<li><span class="math inline">p \rightarrow q</span> - if <span class="math inline">p</span> then <span class="math inline">q</span>, <span class="math inline">q</span> if <span class="math inline">p</span>, <span class="math inline">p</span> only if <span class="math inline">q</span>, <span class="math inline">q</span> when <span class="math inline">p</span>, <span class="math inline">p</span> is sufficient for <span class="math inline">q</span>, <span class="math inline">q</span> is necessary for <span class="math inline">p</span>, <span class="math inline">p</span> implies <span class="math inline">q</span></li>
<li><span class="math inline">p \leftrightarrow q</span> - <span class="math inline">p</span> if and only if <span class="math inline">q</span> (<span class="math inline">p</span> iff <span class="math inline">q</span>), <span class="math inline">p</span> is necessary and sufficient for <span class="math inline">q</span>, <span class="math inline">p</span> exactly if <span class="math inline">q</span>, <span class="math inline">p</span> is equivalent to <span class="math inline">q</span></li>
</ul>
<p>Tips and tricks for proofs:</p>
<ul>
<li>Natural deduction:
<ul>
<li>If you want to prove an implication <span class="math inline">A \rightarrow B</span>, then assume <span class="math inline">A</span> and show B, and use <span class="math inline">\rightarrow+</span>.</li>
<li>If you have something to prove with a different connective, then look at the corresponding introduction rule for that connective and try to show those premises.</li>
<li>As a rule of thumb, when you have something you want to show and can't see how to get it, use proof by contradiction: assume the negation of what you want to show, derive a contradiction, and then use <span class="math inline">\neg-</span> to remove the negation on what you wanted to show.</li>
<li>The turnstile and box notations both have their own advantages.</li>
</ul></li>
<li>Hilbert deduction:
<ul>
<li>Think about the problem in high-level steps. For example, if you have proven <span class="math inline">\neg \neg p</span> then a high-level step would be to conclude that <span class="math inline">p</span>, and figure out how to express this high level step in lower level terms later.</li>
<li>The deduction theorem is one of the most powerful high-level steps for rewriting something you want to show in an easier form.</li>
</ul></li>
</ul>
<p>Prove <span class="math inline">\neg A \vee \neg B \vdash \neg (A \wedge B)</span>:</p>
<ol type="1">
<li><span class="math inline">\neg A, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg \neg (A \wedge B)</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg A, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg (A \wedge B)</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg A, \neg \neg (A \wedge B) \vdash A \wedge B</span> (<span class="math inline">\neg-</span> with 1, 2)</li>
<li><span class="math inline">\neg A, \neg \neg (A \wedge B) \vdash A</span> (<span class="math inline">\wedge-</span> with 3)</li>
<li><span class="math inline">\neg A, \neg \neg (A \wedge B) \vdash \neg A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg A \vdash \neg (A \wedge B)</span> (<span class="math inline">\neg-</span> 4, 5)</li>
<li><span class="math inline">\neg B, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg \neg (A \wedge B)</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg B, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg (A \wedge B)</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg B, \neg \neg (A \wedge B) \vdash A \wedge B</span> (<span class="math inline">\neg-</span> with 7, 8)</li>
<li><span class="math inline">\neg B, \neg \neg (A \wedge B) \vdash B</span> (<span class="math inline">\wedge-</span> with 9)</li>
<li><span class="math inline">\neg B, \neg \neg (A \wedge B) \vdash \neg B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg B \vdash \neg (A \wedge B)</span> (<span class="math inline">\neg-</span> with 10, 11)</li>
<li><span class="math inline">\neg A \vee \neg B \vdash \neg (A \wedge B)</span> (<span class="math inline">\vee+</span> with 6, 12)</li>
</ol>
<p>Prove <span class="math inline">\neg (A \wedge B) \vdash \neg A \vee \neg B</span>:</p>
<ol type="1">
<li><span class="math inline">\neg (A \wedge B), \neg \neg A, \neg A \vdash \neg \neg A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg (A \wedge B), \neg \neg A, \neg A \vdash \neg A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg (A \wedge B), \neg \neg A \vdash A</span> (<span class="math inline">\neg-</span> with 1, 2)</li>
<li><span class="math inline">\neg (A \wedge B), \neg \neg B, \neg B \vdash \neg \neg B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg (A \wedge B), \neg \neg B, \neg B \vdash \neg B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">\neg (A \wedge B), \neg \neg B \vdash B</span> (<span class="math inline">\neg-</span> with 4, 5) ;wip</li>
</ol>
<p>Prove <span class="math inline">A \rightarrow B \vdash \neg B \rightarrow \neg A</span>:</p>
<ol type="1">
<li><span class="math inline">A \rightarrow B, \neg B, \neg \neg A, \neg A \vdash \neg \neg A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, \neg B, \neg \neg A, \neg A \vdash \neg A</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, \neg B, \neg \neg A \vdash A</span> (<span class="math inline">\neg-</span> with 1, 2)</li>
<li><span class="math inline">A \rightarrow B, \neg B, \neg \neg A \vdash A \rightarrow B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, \neg B, \neg \neg A \vdash B</span> (<span class="math inline">\rightarrow-</span> with 3, 4)</li>
<li><span class="math inline">A \rightarrow B, \neg B, \neg \neg A \vdash \neg B</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">A \rightarrow B, \neg B \vdash \neg A</span> (<span class="math inline">\neg-</span> with 5, 6)</li>
<li><span class="math inline">A \rightarrow B \vdash \neg B \rightarrow \neg A</span> (<span class="math inline">\rightarrow+</span> with 7)</li>
</ol>
<h1 id="section-10">16/6/14</h1>
<h2 id="predicate-logic">Predicate Logic</h2>
<p>Predicate logic is also known as <strong>first order logic</strong>.</p>
<p>Predicate logic is like propositional logic, but extended with quantifiers, variables, predicates, functions, constants, and more.</p>
<p>An ordered pair is an object that contains two objects <span class="math inline">a</span> and <span class="math inline">b</span>, represented by <span class="math inline">\tup{a, b}</span>, which, unlike sets, preserves the order of <span class="math inline">a</span> and <span class="math inline">b</span> (which one goes first). Two ordered pairs <span class="math inline">\tup{a, b}</span> and <span class="math inline">\tup{c, d}</span> are equal if and only if <span class="math inline">a = c</span> and <span class="math inline">b = d</span>.</p>
<p>This can be extended into the <strong>tuple</strong> object - an <span class="math inline">n</span>-tuple is an object that stores objects <span class="math inline">a_1, \ldots, a_n</span>, preserving order, and is represented <span class="math inline">\tup{a_1, \ldots, a_n}</span>. Again, <span class="math inline">\tup{a_1, \ldots, a_n} = \tup{b_1, \ldots, b_n}</span> if and only if <span class="math inline">a_i = b_i, 1 \le i \le n</span>.</p>
<h3 id="relations">Relations</h3>
<p>An <span class="math inline">n</span>-ary relation of <span class="math inline">S</span> is <span class="math inline">R = \set{\tup{x_1, \ldots, x_n} \middle| x_1, \ldots, x_n \in S, f(x_1, \ldots, x_n)}</span> for some boolean function <span class="math inline">f(x_1, \ldots, x_n)</span>.</p>
<p>For example, <span class="math inline">\le</span> is a binary relation over <span class="math inline">\mb{N}</span> where <span class="math inline">R = \set{\tup{a, b} \middle| a, b \in \mb{N}, a \le n}</span>. It is the set of all pairs of values where the first value is less than or equal to the second.</p>
<p>A ternary relation over <span class="math inline">\mb{N}</span> might be <span class="math inline">R = \set{\tup{x, y, z} \middle| x + y &lt; z, x, y, z \in \mb{N}}</span>.</p>
<p>It is always true that any <span class="math inline">n</span>-ary relation <span class="math inline">R</span> over <span class="math inline">S</span> is a subset of <span class="math inline">S^n</span>.</p>
<p>Equality is a special binary relation <span class="math inline">R = \set{\tup{x, y} \middle| x, y \in S, x = y} = \set{\tup{x, x} \middle| x \in S}</span>.</p>
<p>The Boolean value <span class="math inline">\tup{x, y} \in R</span> for a binary relation can also be written <span class="math inline">x R y</span>.</p>
<p><span class="math inline">R</span> is <strong>reflexive</strong> over <span class="math inline">S</span> if and only if <span class="math inline">\forall x \in S, x R x</span>.</p>
<p><span class="math inline">R</span> is <strong>symmetric</strong> over <span class="math inline">S</span> if and only if <span class="math inline">\forall x, y \in S, x R y \implies y R x</span>.</p>
<p><span class="math inline">R</span> is <strong>transitive</strong> over <span class="math inline">S</span> if and only if <span class="math inline">\forall x, y, z \in S, x R y \wedge y R z \implies x R z</span>.</p>
<p>If <span class="math inline">R</span> is all three, then <span class="math inline">R</span> is an equivalence relation. Examples of equivalence relations include <span class="math inline">=</span> and <span class="math inline">\equiv \pmod{36}</span>.</p>
<p>The <span class="math inline">R</span>-equivalence class of <span class="math inline">x</span> is <span class="math inline">\overline x = \set{y \in S \middle| x R y}</span>. It is the set of all elements of <span class="math inline">S</span> that satisfy <span class="math inline">x R y</span> and is therefore a subset of <span class="math inline">S</span>.</p>
<h3 id="functions">Functions</h3>
<p>A <strong>function/mapping</strong> <span class="math inline">f</span> is a set of ordered pairs where <span class="math inline">\tup{x, y} \in f \wedge \tup{x, z} \implies y = z</span>. In other words, it is a set of tuples with no duplicates.</p>
<p>The <strong>domain</strong> of <span class="math inline">f</span> is <span class="math inline">\operatorname{dom}(f) = \set{x \middle| \tup{x, y} \in f}</span>.</p>
<p>The <strong>range</strong> of <span class="math inline">f</span> is <span class="math inline">\operatorname{ran}(f) = \set{y \middle| \tup{x, y} \in f}</span>.</p>
<p>If <span class="math inline">\exists y, \tup{x, y} \in f</span>, then <span class="math inline">f(x) = y</span>. If <span class="math inline">\operatorname{dom}(f) = S</span> and <span class="math inline">\operatorname{ran}(f) \subseteq T</span> for some sets <span class="math inline">S</span> and <span class="math inline">T</span>, then <span class="math inline">f: S \to T</span> (<span class="math inline">f</span> is a function from <span class="math inline">S</span> to <span class="math inline">T</span>). Similarly, we can define <span class="math inline">n</span>-ary functions like <span class="math inline">g: S_1, S_2, S_3 \to T</span>.</p>
<p>If <span class="math inline">R</span> is an <span class="math inline">n</span>-ary relation and <span class="math inline">S&#39; \subseteq S</span>, then the <strong>restriction</strong> of <span class="math inline">R</span> to <span class="math inline">S&#39;</span> is <span class="math inline">R \cap S&#39;^n</span>. Basically, it is a restriction of the possible input and output values that are allowed. If <span class="math inline">R</span> is a function, this is written <span class="math inline">R \mid S&#39;: S&#39; \to T</span> - the restriction restricts the allowed x-values.</p>
<p><span class="math inline">f</span> is <strong>onto/surjective</strong> if <span class="math inline">\operatorname{ran}(f) = T</span> - if the image is the same as the codomain. In other words, the output of the function is all the possible output values in <span class="math inline">T</span>, or every possible output value has a corresponding input value.</p>
<p>Basically, every unique <span class="math inline">y \in T</span> has a (not necessarily unique) <span class="math inline">x \in S</span> such that <span class="math inline">f(x) = y</span>.</p>
<p><span class="math inline">f</span> is <strong>one-to-one/injective</strong> if <span class="math inline">f(x) = f(y) \implies x = y</span> - if every output value has a unique input value. In other words, every possible input value has a unique output value.</p>
<p>Basically, if <span class="math inline">x_1, x_2 \in S</span> and <span class="math inline">x_1 \ne x_2</span>, then <span class="math inline">f(x_1) \ne f(x_2)</span>.</p>
<p>If <span class="math inline">f</span> is both, then <span class="math inline">f</span> is a bijection and is <strong>bijective</strong> - every output value has one and only one input value, and every input value has one and only one output value. A bijection maps every element of <span class="math inline">S</span> to a unique element of <span class="math inline">T</span> and vice versa.</p>
<h1 id="section-11">18/6/14</h1>
<p>Two sets <span class="math inline">S, T</span> are <strong>equipotent</strong> if and only if there exists a bijection from <span class="math inline">S</span> to <span class="math inline">T</span>. This is denoted <span class="math inline">S \sim T</span>.</p>
<p>If and only if <span class="math inline">S \sim T</span>, then <span class="math inline">\abs{S} = \abs{T}</span>. A set <span class="math inline">S</span> is <strong>countably infinite</strong> if <span class="math inline">\abs{S} = \abs{\mb{N}}</span> - if we can construct a bijection between it and the set of all natural numbers. <span class="math inline">S</span> is <strong>countable</strong> if it is finite, or countably infinite - if <span class="math inline">\abs{S} \le \abs{\mb{N}}</span>.</p>
<p>We can prove a set is countably infinite by showing that there is a bijection between it and <span class="math inline">\mb{N}</span>, and we prove a set is countable by either proving it is finite or showing the bijection exists.</p>
<p>We can prove a set <span class="math inline">S</span> is not countable by proving that the bijection cannot exist.</p>
<p>Prove that the set of integers is countable:</p>
<blockquote>
<p>Clearly, there are more integers than natural numbers. However, they are both infinite, and infinite sets work in funny ways.<br />
Even though there is a bijection between a subset of <span class="math inline">\mb{Z}</span> and <span class="math inline">\mb{N}</span>, it is actually still possible to define a bijective <span class="math inline">f: \mb{Z} \to \mb{N}</span>.<br />
Let <span class="math inline">f(z) = \begin{cases} 1 - 2z &amp;\text{if } x \le 0 \\ 2z &amp;\text{if }x &gt; 0 \end{cases}</span>.<br />
This is a bijection because we can find the inverse, <span class="math inline">f^{-1}(n) = \begin{cases} \frac{1 - n}{2} &amp;\text{if } 2 \mid n \\ \frac n 2 &amp;\text{if } 2 \nmid n \end{cases}</span>.<br />
So the set of integers is countable.</p>
</blockquote>
<p>A countable set is one where we can enumerate or count the elements - we can assign a natural number to each element in the set.</p>
<p>Any subset of a countable set is countable. The union of countably many countable sets is also countable:</p>
<blockquote>
<p>Let <span class="math inline">S_1 \cup \ldots \cup S_n \cup \ldots</span> be a union of countably many countable sets.<br />
Let <span class="math inline">S_i = \set{a_{i, 1}, \ldots, a_{i, m}, \ldots}</span>.<br />
Then <span class="math inline">S_1 \cup \ldots \cup S_n \cup \ldots = \set{a_{1, 1}, a_{1, 2}, a_{2, 1}, a_{1, 3}, a_{2, 2}, a_{3, 1}, a_{1, 4}, a_{2, 3}, a_{3, 2}, a_{4, 1}, \ldots}</span> - ordered increasing by <span class="math inline">n + m</span> and then by <span class="math inline">n</span>.<br />
Let <span class="math inline">f: S_1 \cup \ldots \cup S_n \cup \ldots \to \mb{N}</span> be defined as <span class="math inline">f(a_{n, m}) = \frac 1 2 (n + m - 1)(n + m - 2) + n = \frac 1 2 (n + m - 1)(n + m - 2) + n = n^2 + m^2 + 2nm - 3n - 3m + 2</span>.<br />
This is called the diagonalization argument. It can also be used to prove that rational numbers are countable (by making <span class="math inline">n, m</span> the numerator and denominator) and similar things.</p>
</blockquote>
<p>The Cartesian product of a finite amount of countable sets is also a countable set. Also, the set of finite sets all containing only elements in a particular countable set is countable.</p>
<p>Predicate/first order logic is an extension of propositional logic that adds constructs to help deal with individuals/objects in a set. While propositional logic makes us list out all the objects we are using, predicate logic gives additional tools to deal things like some objects, all objects, or more.</p>
<p>For example, &quot;Every student is younger than some instructor&quot; could be represented in propositional logic by writing <span class="math inline">(s_1 &lt; i_1 \vee \ldots \vee s_1 &lt; i_n) \wedge \ldots \wedge (s_m &lt; i_1 \vee \ldots \vee s_m &lt; i_n)</span> where <span class="math inline">s_1, \ldots, s_m</span> are the student ages and <span class="math inline">i_1, \ldots, i_n</span> are the instructor ages.</p>
<p>Predicate logic makes it much easier to express this: <span class="math inline">\forall s \in S, \exists i \in I, s &lt; i</span>, where <span class="math inline">S</span> is the set of all students and <span class="math inline">I</span> is the set of all instructors.</p>
<h3 id="syntax">Syntax</h3>
<p>The language of predicate logic is called <span class="math inline">\mathcal{L}</span>.</p>
<p>Formulas in predicate logic is made up of several components:</p>
<ul>
<li>Domain of objects - sets containing any number of objects.</li>
<li>Variables - particular objects, but not necessarily a specific one.
<ul>
<li>Lowercase to distinguish them from predicates.</li>
<li>This is different from constants because they don't represent a specific object, just a placeholder for an object.</li>
<li>These are often found following a quantifier - in <span class="math inline">\exists x, x = x</span>, <span class="math inline">x</span> is a variable, not a constant.</li>
<li><span class="math inline">VS</span> is the set of variables and <span class="math inline">VS(A)</span> is the set of variables in a formula <span class="math inline">A</span>.</li>
</ul></li>
<li>Designated objects/constants - specific objects such as a particular number or a matrix.
<ul>
<li><span class="math inline">CS</span> is the set of constants and <span class="math inline">CS(A)</span> is the set of constants in a formula <span class="math inline">A</span>.</li>
</ul></li>
<li>Functions such as <span class="math inline">+</span>, <span class="math inline">-</span>, <span class="math inline">f</span>, and <span class="math inline">g</span> - taking terms and outputting terms.
<ul>
<li><span class="math inline">FS</span> is the set of functions and <span class="math inline">FS(A)</span> is the set of functions in a formula <span class="math inline">A</span>.</li>
</ul></li>
<li>Predicates/relations such as <span class="math inline">=</span> and <span class="math inline">&gt;</span> - taking terms and outputting Boolean values.
<ul>
<li><span class="math inline">PS</span> is the set of predicates and <span class="math inline">PS(A)</span> is the set of predicates in a formula <span class="math inline">A</span>.</li>
</ul></li>
<li>Quantifiers such as <span class="math inline">\forall</span> and <span class="math inline">\exists</span>.
<ul>
<li>They have the form <span class="math inline">\forall x. P(\ldots)</span> or <span class="math inline">\exists x. P(\ldots)</span>.</li>
</ul></li>
<li>Propositional connectives.</li>
</ul>
<h1 id="section-12">23/6/14</h1>
<p>Write &quot;Every child is younger than its mother&quot; using predicate logic:</p>
<blockquote>
<p>Let <span class="math inline">C(x)</span> represent <span class="math inline">x</span> being a child. Let <span class="math inline">M(x)</span> represent the mother of <span class="math inline">x</span>. Let <span class="math inline">Y(x, y)</span> represent <span class="math inline">x</span> being younger than <span class="math inline">y</span>.<br />
Then <span class="math inline">\forall x. C(x) \rightarrow Y(x, M(x))</span>.</p>
</blockquote>
<p><span class="math inline">\forall x. \forall y. \operatorname{plus}(x, y) = \operatorname{plus}(y, x)</span> - addition is commutative.</p>
<p><span class="math inline">\forall x. \neg \operatorname{equal}(0, \operatorname{succ}(x))</span> - 0 is not the successor of any non-negative integer.</p>
<p>Well formed formulas in <span class="math inline">\mathcal{L}</span> can be defined as follows:</p>
<ul>
<li><span class="math inline">\operatorname{Term}(\mathcal{L})</span> is the set of all constants and variables (terms), and functions over terms.
<ul>
<li>For example, <span class="math inline">f(g(a, b), c) \in \operatorname{Term}(\mathcal{L})</span>.</li>
<li>We basically need to pass the right number of parameters to every function.</li>
</ul></li>
<li><span class="math inline">\operatorname{Atom}(\mathcal{L})</span> is the set of all predicates over terms - the set of all <span class="math inline">P(t_1, \ldots, t_n), t_1, \ldots, t_n \in \operatorname{Term}(\mathcal{L})</span> where <span class="math inline">P</span> is an <span class="math inline">n</span>-ary predicate.
<ul>
<li>For example, <span class="math inline">\operatorname{equal}(\operatorname{plus}(x, 2), \operatorname(\operatorname{plus}(x, 1), 1))</span>.</li>
</ul></li>
<li><span class="math inline">\operatorname{Form}(\mathcal{L}) = \operatorname{Atom}(\mathcal{L}) \cup \set{(\neg \phi), (\phi \wedge \psi), (\phi \vee \psi), (\phi \rightarrow \psi), (\phi \leftrightarrow \psi)} \cup \set{\forall x. \phi, \exists x, \phi}</span> where <span class="math inline">\phi, \psi \in \operatorname{Form}(\mathcal{L})</span> - the set of all atoms combined with the set of operations over other formulas.
<ul>
<li>For example, <span class="math inline">\neg \operatorname{equal}(1, 2) \in \operatorname{Form}(\mathcal{L})</span>.</li>
<li>For example, <span class="math inline">\forall x, \operatorname{equal}(x, x) \in \operatorname{Form}(\mathcal{L})</span>.</li>
</ul></li>
</ul>
<p>This means that terms are not formulas, though atoms are.</p>
<p>We can also draw parse trees for formulas. Here, the leaves are terms and the other nodes are either connectives or predicates or quantifiers.</p>
<h1 id="section-13">25/6/14</h1>
<p>A <strong>free</strong> variable is a variable that has a value we can assign to it. A variable that is not free is <strong>bound/quantified</strong>, and occurs when we use quantifiers.</p>
<p>For example, <span class="math inline">\forall y, y = x</span> has the free variable <span class="math inline">x</span> and the bound variable <span class="math inline">y</span>. <span class="math inline">x</span> is free because we can give it whatever value we want, which we cannot do for <span class="math inline">y</span> since it does not have one particular value.</p>
<p>In a parse tree, if a variable node <span class="math inline">x</span> has a quantifier like <span class="math inline">\exists x</span> above it in the parse tree, it is bound. Otherwise, it is free.</p>
<p>If <span class="math inline">A \in \operatorname{Form}(\mathcal{L})</span>, <span class="math inline">FV(A)</span> is the set of free variables in <span class="math inline">A</span>. It is defined using the following rules:</p>
<ul>
<li>If <span class="math inline">A = P(t_1, \ldots, t_n)</span>, then <span class="math inline">FV(A)</span> is the set of all variables occurring in <span class="math inline">t_1, \ldots, t_n</span>.</li>
<li>If <span class="math inline">A = (\neg B)</span>, then <span class="math inline">FV(A) = FV(B)</span>.</li>
<li>If <span class="math inline">A = (B \odot C)</span> where <span class="math inline">\odot</span> is a binary connective, then <span class="math inline">FV(A) = FV(B) \cup FV(C)</span>.</li>
<li>If <span class="math inline">A = (\forall x. B)</span> or <span class="math inline">A = (\exists x. B)</span>, then <span class="math inline">FV(A) = FV(B) \setminus \set{x}</span>.</li>
</ul>
<p>For quantifier formulas like <span class="math inline">\forall x. A(x)</span> and <span class="math inline">(\exists x. A(x)) \wedge P(x)</span>, <span class="math inline">A(x)</span> is the <strong>scope</strong> of <span class="math inline">x</span> in the formula.</p>
<p>A variable can occur in multiple places and represent different things. For example, <span class="math inline">(\exists x. A(x)) \wedge P(x)</span> has a bound <span class="math inline">x</span> on the left side of <span class="math inline">\wedge</span>, and a free variable <span class="math inline">x</span> on the right side. These two refer to different objects.</p>
<p>A predicate logic formula <span class="math inline">A</span> is <strong>closed</strong> and is a <strong>sentence</strong> if and only if there are no free variables - <span class="math inline">FV(A) = \emptyset</span>.</p>
<p>Given a formula <span class="math inline">A</span>, <span class="math inline">A[x/t]</span> is the same formula, but with all free occurrences of <span class="math inline">x</span> <strong>substituted</strong> with the term <span class="math inline">t</span>. Note that bound occurrences of <span class="math inline">x</span> are not replaced.</p>
<p>If <span class="math inline">y</span> is a variable in <span class="math inline">t</span> and there are no occurrences of <span class="math inline">x</span> in the scope of <span class="math inline">\exists y</span> or <span class="math inline">\forall y</span> in a formula <span class="math inline">A</span>, then <span class="math inline">t</span> is <strong>free for</strong> <span class="math inline">x</span> in <span class="math inline">A</span>. Basically, <span class="math inline">t</span> is free for <span class="math inline">x</span> in <span class="math inline">A</span> if substituting <span class="math inline">t</span> for any occurrence of <span class="math inline">x</span> does not cause any free variables to become bound.</p>
<p>For example, if <span class="math inline">t = y + 1</span> and <span class="math inline">A = \forall y, P(x)</span>, then <span class="math inline">A[x/t]</span> would cause the <span class="math inline">y</span> in <span class="math inline">y + 1</span> we substituted in to become bound, so <span class="math inline">t</span> is not free for <span class="math inline">x</span> in <span class="math inline">A</span>. If <span class="math inline">t</span> is not free for <span class="math inline">x</span>, then we can make it free for <span class="math inline">x</span> by renaming the variable - <span class="math inline">t = y + 1</span> becomes <span class="math inline">t = z + 1</span>.</p>
<p>Formally, a substitution <span class="math inline">A[x/t]</span> can be defined recursively:</p>
<ul>
<li>If <span class="math inline">A</span> is a term, then <span class="math inline">A[x/t]</span> is <span class="math inline">A</span> with each occurrence of <span class="math inline">x</span> replaced with <span class="math inline">t</span>.</li>
<li>If <span class="math inline">A = P(t_1, \ldots, t_n)</span>, then <span class="math inline">A[x/t] = P(t_1[x/t], \ldots, t_n[x/t])</span>.</li>
<li>If <span class="math inline">A = \neg B</span>, then <span class="math inline">A[x/t] = \neg B[x/t]</span>.</li>
<li>If <span class="math inline">A = B \odot C</span> where <span class="math inline">\odot</span> is a binary connective, then <span class="math inline">A[x/t] = B[x/t] \odot C[x/t]</span>.</li>
<li>If <span class="math inline">A = \forall y. B</span>, then <span class="math inline">A[x/t] = A</span> if <span class="math inline">x = y</span>, and <span class="math inline">A[x/t] = \forall y. B[x/t]</span> otherwise (<span class="math inline">t</span> must be free for <span class="math inline">x</span> or renamed otherwise).</li>
<li>If <span class="math inline">A = \exists y. B</span>, then <span class="math inline">A[x/t] = A</span> if <span class="math inline">x = y</span>, and <span class="math inline">A[x/t] = \exists y. B[x/t]</span> otherwise (<span class="math inline">t</span> must be free for <span class="math inline">x</span> or renamed otherwise).</li>
</ul>
<h3 id="interpretations-and-assignments">Interpretations and Assignments</h3>
<p>In propositional logic, there were truth valuations that fixed atom values. In predicate logic, there are more elements to consider, such as quantifiers and functions.</p>
<p>Predicate logic formulas are used to express Boolean values. We can obtain these Boolean values using interpretations. All formulas are either true or false for all posible conditions.</p>
<p>An <strong>interpretation/model</strong> of a formula <span class="math inline">A</span> is a tuple of the form <span class="math inline">I = \tup{U, (\ldots)^I}</span>, where <span class="math inline">U</span> is the domain/universe of discourse and <span class="math inline">(\ldots)^I</span> is a function that maps constants to the domain, functions to functions over the domain, and predicates to relations in the domain.</p>
<p>Basically, an interpretation is a universe of discourse combined with a mapping from elements of the formula to elements in the universe of discourse.</p>
<p>If <span class="math inline">c \in CS(A)</span>, then <span class="math inline">c^I \in U</span>. If <span class="math inline">f \in FS(A)</span>, then <span class="math inline">f^I: D^n \to D</span> where <span class="math inline">n</span> is the arity of <span class="math inline">f</span>. If <span class="math inline">P \in PS(A)</span>, then <span class="math inline">P^I \subseteq D^n</span> where <span class="math inline">n</span> is the arity of <span class="math inline">P</span>.</p>
<p>Find an interpretation of <span class="math inline">\exists c. P(f(g(a), g(b)), g(c))</span>:</p>
<blockquote>
<p>Let <span class="math inline">I = \tup{\mb{N}, \begin{cases} 3 &amp;\text{if } a \\ 4 &amp;\text{if } b \\ x + y &amp;\text{if } f(x, y) \\ x^2 &amp;\text{if } g(x) \\ = &amp;\text{if } P \end{cases}}</span>.<br />
So <span class="math inline">(\forall c. P(f(g(a), g(b)), g(c)))^I</span> becomes <span class="math inline">\exists c. 3^2 + 4^2 = c^2</span>.<br />
The word form of the interpretation is: &quot;Let <span class="math inline">\mb{N}</span> be the universe of discourse. Let <span class="math inline">a</span> be 3 and <span class="math inline">b</span> be 4. Let <span class="math inline">f</span> be addition and <span class="math inline">g</span> be squaring, and <span class="math inline">P</span> be equality.&quot;.</p>
</blockquote>
<p>Interpretations are definitely more concrete than the original formulas, but if there are quantifiers, we still cannot directly state whether the formula is true or false under a given interpretation.</p>
<p>A <strong>valuation/assignment</strong> of an interpretation of a formula <span class="math inline">A^I</span> is a function <span class="math inline">\theta: VS(A) \to U</span> where <span class="math inline">U</span> is the universe of discourse for the interpretation. Basically, it is a bunch of substitutions for each variable. Valuations work only on terms.</p>
<p>If <span class="math inline">t \in CS</span>, then <span class="math inline">t^{I, \theta} = t^I</span>. If <span class="math inline">x \in VS</span>, then <span class="math inline">x^{I, \theta} = \theta(x)</span>. If <span class="math inline">f \in FS</span>, then <span class="math inline">f(t_1, \ldots, t_n)^{I, \theta} = f^I(t_1^{I, \theta}, \ldots, t_n^{I, \theta})</span>.</p>
<p>For example, using the previous interpretation <span class="math inline">I</span>, <span class="math inline">(\exists c. P(f(g(a), g(b)), g(c)))^I</span> is <span class="math inline">\exists c. 3^2 + 4^2 = c^2</span>. So under the assignment <span class="math inline">\theta(c) = 5</span>, <span class="math inline">(\exists c. P(f(g(a), g(b)), g(c)))^{I, \theta}</span> is <span class="math inline">3^2 + 4^2 = 5^2</span>, which is true.</p>
<p>Interpretations and valuations also work on terms. In this case, an interpretation and assignment result in an element of the universe of discourse for the interpretation.</p>
<p>If <span class="math inline">A(x)</span> has no free occurrences of <span class="math inline">y</span>, and <span class="math inline">A(y)</span> has no free occurrences of <span class="math inline">x</span>, then <span class="math inline">A(x)</span> and <span class="math inline">A(y)</span> basically mean the same thing. We can make them the same using a simple substitution <span class="math inline">A(x)[x/y] = A(y)</span>.</p>
<p>So for a closed formula, we can change the variables around as we wish: <span class="math inline">\exists x. P(x)</span> is the same as <span class="math inline">\exists y. P(y)</span>.</p>
<h1 id="section-14">2/7/14</h1>
<p>In predicate logic, a <strong>model</strong> is an interpretation together with an assignment. A model is a tuple <span class="math inline">\tup{I, \theta}</span>.</p>
<p>If <span class="math inline">M = (I, \theta)</span>, then <span class="math inline">I, \theta \models A</span> is the same as <span class="math inline">M \models A</span>. In the same way, <span class="math inline">A^{I, \theta}</span> is the same as <span class="math inline">A^M</span>.</p>
<p>The <strong>satisfaction relation</strong> <span class="math inline">\models</span> is a relation between an interpretation, an assignment, and a predicate logic formula. If true, it means that the formula under the interpretation and assignment is true. This is similar to the <span class="math inline">\models</span> operator over truth valuations and formulas in propositional logic.</p>
<p>Given an interpretation <span class="math inline">I</span>, an assignment <span class="math inline">\theta</span>, a model <span class="math inline">M = (I, \theta)</span>, and a first order logic formula <span class="math inline">A</span>:</p>
<ul>
<li>If <span class="math inline">A = P(t_1, \ldots, t_n)</span>, then <span class="math inline">M \models A</span> if and only if <span class="math inline">\tup{t_1^M, \ldots, t_n^M} \in P^I</span> (the terms satisfy the relation),</li>
<li>If <span class="math inline">A = \neg B</span>, then <span class="math inline">M \models A</span> if and only if <span class="math inline">M \models B</span> is false.</li>
<li>If <span class="math inline">A = B \wedge C</span>, then <span class="math inline">M \models A</span> if and only if <span class="math inline">M \models B</span> and <span class="math inline">M \models C</span>.</li>
<li>If <span class="math inline">A = B \vee C</span>, then <span class="math inline">M \models A</span> if and only if <span class="math inline">M \models B</span> or <span class="math inline">M \models C</span>.</li>
<li>If <span class="math inline">A = B \rightarrow C</span>, then <span class="math inline">M \models A</span> if and only if <span class="math inline">M \models B</span> implies <span class="math inline">M \models C</span>.</li>
<li>If <span class="math inline">A = B \leftrightarrow C</span>, then <span class="math inline">M \models A</span> if and only if <span class="math inline">M \models B</span> is equivalent to <span class="math inline">M \models C</span>.</li>
<li>If <span class="math inline">A = \forall x. B</span>, then <span class="math inline">M \models A</span> if and only if for every <span class="math inline">v \in U</span>, <span class="math inline">M&#39; \models B</span> where <span class="math inline">M&#39; = (I, \theta&#39;)</span> where <span class="math inline">\theta&#39;</span> is <span class="math inline">\theta</span> except it maps <span class="math inline">x</span> to <span class="math inline">v</span>.</li>
<li>If <span class="math inline">A = \exists x. B</span>, then <span class="math inline">M \models A</span> if and only if there exists a <span class="math inline">v \in U</span> such that <span class="math inline">M&#39; \models B</span> where <span class="math inline">M&#39; = (I, \theta&#39;)</span> where <span class="math inline">\theta&#39;</span> is <span class="math inline">\theta</span> except it maps <span class="math inline">x</span> to <span class="math inline">v</span>.</li>
</ul>
<p>We can also define a sub-language of <span class="math inline">\mathcal{L}</span> that has a subset of the elements of the full language. For example, <span class="math inline">\mathcal{A} = \tup{0, \operatorname{add1}, =}</span> is a sub-language that only has three elements in it. We can use it to represent any equality of natural numbers using an interpretation like <span class="math inline">\tup{\mb{N}, \begin{cases} x + 1 &amp;\text{if } \operatorname{add1}(x) \end{cases}}</span>.</p>
<p>We could say that the universal quantifier is conceptually similar to conjunction in propositional logic, because <span class="math inline">\forall x. P(x)</span> means <span class="math inline">P(x_1) \wedge P(x_2) \wedge \ldots</span>. We could also say that the existential quantifier is conceptally similar to disjunction in propositional logic, because <span class="math inline">\exists x. P(x)</span> means <span class="math inline">P(x_1) \vee P(x_2) \vee \ldots</span>.</p>
<h1 id="section-15">7/7/14</h1>
<p>The relevance lemma states that given a formula <span class="math inline">A</span>, interpretation <span class="math inline">I</span>, and valuations <span class="math inline">\theta_1, \theta_2</span>, if <span class="math inline">\theta_1(x) = \theta_2(x)</span> for all <span class="math inline">x \in VS(A)</span>, then <span class="math inline">I, \theta_1 \models A \iff I, \theta_2 \models A</span>.</p>
<p><span class="math inline">\Sigma \in \operatorname{Form}(\mathcal{L})</span> is <strong>satisfiable</strong> if and only if there exists an interpretation <span class="math inline">I</span> and valuation <span class="math inline">\theta</span> such that <span class="math inline">I, \theta \models A</span> for all <span class="math inline">A \in \Sigma</span>.</p>
<p><span class="math inline">A \in \operatorname{Form}(\mathcal{L})</span> is <strong>valid</strong> if and only if for any interpretation <span class="math inline">I</span> and valuation <span class="math inline">\theta</span>, <span class="math inline">I, \theta \models A</span>.</p>
<p>We prove something is satisfiable by giving <span class="math inline">I, \theta</span> and prove something is valid by using contradiction over the existance of <span class="math inline">I, \theta</span> that doesn't satisfy it.</p>
<p><span class="math inline">A</span> is a <strong>logical consequence</strong> of <span class="math inline">\Sigma</span> and <span class="math inline">\Sigma \models A</span> if and only if for every <span class="math inline">I, \theta</span>, <span class="math inline">I, \theta \models \Sigma</span> (satisfies every element of <span class="math inline">\Sigma</span>) implies <span class="math inline">I, \theta \models A</span>.</p>
<p>So <span class="math inline">\emptyset \models A</span>, also written as <span class="math inline">\models A</span>, means that <span class="math inline">A</span> is valid.</p>
<p>The replacability theorem states that given formulas <span class="math inline">A, B, C</span>, if <span class="math inline">B \equiv C</span> then <span class="math inline">A[B/C] \equiv A</span>. In other words, if two things are equal then we can replace those things in other things and they will not change semantically.</p>
<p>The duality theorem states that <span class="math inline">\neg A \equiv A&#39;</span> where <span class="math inline">A&#39;</span> is <span class="math inline">A</span> with <span class="math inline">\wedge</span> replaced with <span class="math inline">\vee</span>, <span class="math inline">\vee</span> with <span class="math inline">\wedge</span>, <span class="math inline">\exists</span> with <span class="math inline">\forall</span>, <span class="math inline">\forall</span> for <span class="math inline">\exists</span>, and all atoms <span class="math inline">P</span> with <span class="math inline">\neg P</span>.</p>
<h2 id="deductive-systems">Deductive Systems</h2>
<p>Natural deduction in first order logic is similar to that in propositional logic, but with additional rules for quantifiers.</p>
<table>
<colgroup>
<col style="width: 13%" />
<col style="width: 27%" />
<col style="width: 32%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Symbol</th>
<th style="text-align: left;">Rule</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Universal-introduction</td>
<td style="text-align: left;"><span class="math inline">\forall+</span> with <span class="math inline">\Sigma \vdash \alpha[x/t]</span> and <span class="math inline">t</span> is a constant not in <span class="math inline">\Sigma</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha[x/t]</span> for all <span class="math inline">t</span> not in <span class="math inline">\Sigma</span> implies <span class="math inline">\Sigma \vdash \forall x. \alpha</span></td>
<td style="text-align: left;">If <span class="math inline">\alpha</span> is true for an arbitrary <span class="math inline">x</span>, then it is true all <span class="math inline">x</span>.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Universal-elimination (specification)</td>
<td style="text-align: left;"><span class="math inline">\forall-</span> with <span class="math inline">\Sigma \vdash \forall x. \alpha</span> and <span class="math inline">t</span> is a constant</td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \forall x. \alpha</span> implies <span class="math inline">\Sigma \vdash \alpha[x/t]</span></td>
<td style="text-align: left;">If <span class="math inline">\alpha</span> is true for all <span class="math inline">x</span>, then it is true for a particular <span class="math inline">x</span> as well.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Existential-introduction</td>
<td style="text-align: left;"><span class="math inline">\exists+</span> with <span class="math inline">\Sigma \vdash \alpha[x/t]</span> and <span class="math inline">t</span> is a constant</td>
<td style="text-align: left;"><span class="math inline">\Sigma \vdash \alpha[x/t]</span> for all <span class="math inline">t</span> implies <span class="math inline">\Sigma \vdash \exists x. \alpha</span></td>
<td style="text-align: left;">If <span class="math inline">\alpha</span> is true for an arbitrary <span class="math inline">x</span>, then it is true some <span class="math inline">x</span>.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Existential-elimination</td>
<td style="text-align: left;"><span class="math inline">\exists-</span> with <span class="math inline">\Sigma, \alpha(u) \vdash \psi</span></td>
<td style="text-align: left;"><span class="math inline">\Sigma, \alpha(u) \vdash \psi</span> implies <span class="math inline">\Sigma, \exists x. p(x) \vdash \psi</span></td>
<td style="text-align: left;">If <span class="math inline">\alpha</span> implies something, there exists an <span class="math inline">\alpha</span> that implies something.</td>
</tr>
</tbody>
</table>
<p>Show that <span class="math inline">\forall x. \forall y. P(x, y) \vdash \forall y. \forall x. P(x, y)</span>:</p>
<ol type="1">
<li><span class="math inline">\forall x. \forall y. P(x, y) \vdash \forall x. \forall y. P(x, y)</span> (Ref)</li>
<li><span class="math inline">\forall x. \forall y. P(x, y) \vdash \forall y. P(u, y)</span> (<span class="math inline">\forall-</span> with 1 and <span class="math inline">u</span> is arbitrary)</li>
<li><span class="math inline">\forall x. \forall y. P(x, y) \vdash P(u, v)</span> (<span class="math inline">\forall-</span> with 2 and <span class="math inline">v</span> is arbitrary)</li>
<li><span class="math inline">P(u, v) \vdash P(u, v)</span> (Ref with arbitrary <span class="math inline">u</span> and <span class="math inline">v</span>)</li>
<li><span class="math inline">P(u, v) \vdash \forall y. P(u, y)</span> (<span class="math inline">\forall+</span> with 4 and <span class="math inline">v</span> is arbitrary)</li>
<li><span class="math inline">P(u, v) \vdash \forall x. \forall y. P(x, y)</span> (<span class="math inline">\forall+</span> with 5 and <span class="math inline">u</span> is arbitary)</li>
<li><span class="math inline">\forall x. \forall y. P(x, y) \vdash \forall x. \forall y. P(x, y)</span> (<span class="math inline">\operatorname{Tr}</span> with 3 and 6)</li>
</ol>
<h1 id="section-16">9/7/14</h1>
<p>Show that <span class="math inline">\exists x. P(x) \vdash \exists y. P(y)</span>:</p>
<ol type="1">
<li><span class="math inline">P(u) \vdash P(u)</span> (Ref)</li>
<li><span class="math inline">P(u) \vdash \exists y. P(y)</span> (<span class="math inline">\exists+</span> with 1 and <span class="math inline">u</span> is arbitrary)</li>
<li><span class="math inline">\exists x. P(x) \vdash \exists y. P(y)</span> (<span class="math inline">\exists-</span> with 2 and <span class="math inline">u</span> is arbitrary)</li>
</ol>
<h1 id="section-17">14/7/14</h1>
<h2 id="peano-arithmetic">Peano Arithmetic</h2>
<p>The Peano axioms formally define natural numbers. Peano arithmetic is a sublanguage of <span class="math inline">\mathcal{L}</span></p>
<p>The <strong>equality relation</strong> <span class="math inline">\approx</span> is a binary relation over a domain <span class="math inline">D</span>, defined as <span class="math inline">\set{\tup{x, x} \middle| x \in D}</span>.</p>
<p>We define two axioms for the equality relation:</p>
<ul>
<li><span class="math inline">\forall x. x \approx x</span> - everything is equal to itself.</li>
<li><span class="math inline">\forall x. \forall y. (x \approx y) \rightarrow (\alpha[z/x] \approx \alpha[z/x])</span> where <span class="math inline">\alpha \in \operatorname{Form}(\mathcal{L}), z \in VS(a)</span> - equal objects have equal properties.</li>
</ul>
<p>This implies that equality is symmetric (<span class="math inline">\forall x. \forall y. x \approx y \rightarrow y \approx x</span>) and transitive (<span class="math inline">\forall w. \forall x. \forall y. x \approx y \rightarrow (y \approx w \rightarrow x \approx w)</span>).</p>
<p>Proof of symmetry:</p>
<p>Proof:</p>
<ol type="1">
<li><span class="math inline">\vdash \forall x. x \approx x</span> (Axiom 1)</li>
<li><span class="math inline">\vdash a \approx a</span> (<span class="math inline">\forall-</span> with 1)</li>
<li><span class="math inline">\vdash \forall x. \forall y. x \approx y \rightarrow (x \approx a \rightarrow y \approx a)</span> (Axiom 2 with <span class="math inline">z \approx a</span> as <span class="math inline">\alpha</span>)</li>
<li><span class="math inline">\vdash a \approx b \rightarrow (a \approx a \rightarrow b \approx a)</span> (<span class="math inline">\forall-</span> with 3)</li>
<li><span class="math inline">a \approx b \vdash a \approx a</span> (<span class="math inline">\epsilon</span>)</li>
<li><span class="math inline">a \approx b \vdash a \approx a \rightarrow b \approx a</span> (<span class="math inline">\rightarrow-</span> with 4 and 5)</li>
<li><span class="math inline">a \approx b \vdash b \approx a</span> (<span class="math inline">\rightarrow-</span> with 6)</li>
<li><span class="math inline">\vdash a \approx b \rightarrow b \approx a</span> (<span class="math inline">\rightarrow+</span> with 7)</li>
<li><span class="math inline">\vdash \forall x. \forall y. x \approx y \rightarrow y \approx x</span> (<span class="math inline">\forall+</span> with 8)</li>
</ol>
<p>The symmetry rule is known as <span class="math inline">\operatorname{symmetric}</span>.</p>
<p>Proof of transitivity:</p>
<ol type="1">
<li><span class="math inline">\vdash b \approx a \rightarrow (b \approx c \rightarrow a \approx c)</span> (Axiom 2)</li>
<li><span class="math inline">a \approx b \vdash b \approx a \rightarrow (b \approx c \rightarrow a \approx c)</span> (<span class="math inline">+</span>)</li>
<li><span class="math inline">\vdash a \approx b \rightarrow b \approx a</span> (<span class="math inline">\operatorname{symmetric}</span>)</li>
<li><span class="math inline">a \approx b \vdash b \approx a</span> (<span class="math inline">\rightarrow-</span> with 3)</li>
<li><span class="math inline">a \approx b \vdash b \approx c \rightarrow a \rightarrow c</span> (<span class="math inline">\rightarrow-</span> with 1 and 4)</li>
<li><span class="math inline">\vdash a \approx b \rightarrow (b \approx c \rightarrow a \approx c)</span> (<span class="math inline">\rightarrow+</span> with 5)</li>
<li><span class="math inline">\forall w. \forall x. \forall y. x \approx y \rightarrow (y \rightarrow w \rightarrow x \approx w)</span> (<span class="math inline">\forall+</span> with 6)</li>
</ol>
<p>The idea of natural numbers were created in order to allow counting or ordering objects, where 0 represents a lack of objects and every successive number is one more object than the previous.</p>
<p>If <span class="math inline">S: \mb{N} \to \mb{N}</span> is a unary function that, given a natural number, gives the next natural number, every natural number can be represented as a term. For example, 0 is represented with <span class="math inline">0</span>, and 3 is represented with <span class="math inline">S(S(S(0)))</span>.</p>
<p>The signature of Peano arithmetic is <span class="math inline">\sigma = \tup{0, S, +, \cdot, \approx, \not\approx}</span>. These have the following axioms:</p>
<ol type="1">
<li><span class="math inline">\forall x. S(x) \not\approx 0</span> - no successor of a natural number is 0.</li>
<li><span class="math inline">\forall x. \forall y. S(x) \approx S(y) \rightarrow x \approx y</span> - two numbers with equal successors are equal.</li>
<li><span class="math inline">\forall x. x + 0 \approx x</span> - 0 is the additive identity</li>
<li><span class="math inline">\forall x. \forall y. s + S(y) \approx S(x + y)</span> - succession is linear</li>
<li><span class="math inline">\forall x. x \cdot 0 \approx 0</span> - 0 is the multiplicative identity</li>
<li><span class="math inline">\forall x. \forall y. s \cdot S(y) \approx x \cdot y + x</span> - succession is ditributive</li>
<li><span class="math inline">\alpha[x/0] \rightarrow ((\forall x. \alpha \rightarrow \alpha[x/S(x)]) \rightarrow \forall x. \alpha)</span> - simple induction</li>
</ol>
<p>Axiom 7 states that if something is true for 0, and each value implies its successor, then it is true for all values.</p>
<p>Also, <span class="math inline">\forall y. 0 + y \approx y</span> and <span class="math inline">\forall y. x + y \approx y + x \vdash \forall y. S(x) + y \approx S(x + y)</span>.</p>
<p>Also, <span class="math inline">\forall x. \forall y. x + y \approx y + x</span> and <span class="math inline">\forall x. \forall y. \forall z. (x + y) + z \approx x + (y + z)</span>.</p>
<p>Prove that every non-zero number has a predecessor - <span class="math inline">\forall x. x \not\approx 0 \rightarrow \exists y. S(y) \approx x</span>:</p>
<p>;wip</p>
<p>Prove that addition is commutative - <span class="math inline">\forall x. \forall y. x + y \approx y + x</span> using induction:</p>
<ol type="1">
<li><span class="math inline">\vdash \forall y. 0 + y \approx y</span> (derived from Axiom 3)</li>
<li><span class="math inline">\forall x. \forall y. x + y \approx y + x \vdash \forall x. \forall y. x + y \approx y + x \rightarrow S(x + y) \approx S(y + x)</span> (Axiom 2 for equality)</li>
<li><span class="math inline">\vdash \forall x. \forall y. x + y \approx y + x</span> (Axiom 7 with 1 and 2 where <span class="math inline">\alpha = x + y \approx y + x</span>)</li>
</ol>
<h2 id="program-verification">Program Verification</h2>
<p>A program is <strong>correct</strong> if it satisfies its specifications. We can show correctness by inspection, testing, and formal verification.</p>
<p>Testing and inspection can show that there are bugs, but cannot show that there are no bugs. For that we need formal verification, which can prove that a program is correct for all possible inputs.</p>
<p>In the real world, formal verification is used for safety and mission critical systems such as brakes and nuclear power plants. It is also helpful for documentation purposes.</p>
<p>The formal verification workflow starts by converting an informal description of the program into an equivalent formula <span class="math inline">\phi</span> in a symbolic logic. Then, the program is written trying to implement that formula, before we prove that the program is correct or fix it until it is correct.</p>
<p>In this course we will use a core programming language that is a subset of C/C++ and Java with the most important features. For example, a program that calculates the factorial of <code>x</code>:</p>
<pre><code>y = 1;
z = 0;
while (z != x) {
    z = z + 1;
    y = y * z;
}</code></pre>
<p>This is a declarative program, and manipulates states (valuations of variables at a given point in the program) using commands.</p>
<p>A <strong>Hoare triple</strong> is an assertion used in formal verification, of the form <span class="math inline">\tup{P C Q}</span>, where <span class="math inline">P</span> is the set of preconditions, <span class="math inline">C</span> is the code or program, and <span class="math inline">Q</span> is the set of postconditions. This is also written <span class="math inline">\tup{\phi C \psi}</span>.</p>
<p>The Hoard triple <span class="math inline">\tup{P C Q}</span> means that if the program starting state satisfies <span class="math inline">P</span>, then the final state of the program after it finishes satisfies <span class="math inline">Q</span>.</p>
<p><span class="math inline">\tup{P C Q}</span> is a <strong>specification</strong> of <span class="math inline">C</span>. For example, a specification for a program <span class="math inline">C</span> that takes a positive number <span class="math inline">x</span> and computes a number whose square is less than <span class="math inline">x</span> might be written as <span class="math inline">\tup{\set{x &gt; 0} C \set{y * y &lt; x}}</span>. Note that this does not specify a unique <span class="math inline">C</span>.</p>
<p><span class="math inline">\tup{P C Q}</span> is satisfied under <strong>partially correctness</strong> if and only if when <span class="math inline">C</span> is executed with any starting state <span class="math inline">s</span> satisfying <span class="math inline">P</span> with <span class="math inline">C</span> eventually terminating, the final state <span class="math inline">s&#39;</span> satisfies <span class="math inline">Q</span>.</p>
<p><span class="math inline">\tup{P C Q}</span> being satisfied under partial correctness can be written as <span class="math inline">\models_{par} \tup{P C Q}</span>. If we can prove that <span class="math inline">\tup{P C Q}</span> is satisfied under partial correctness using partial correctness calculus, then <span class="math inline">\vdash_{par} \tup{P C Q}</span>.</p>
<h1 id="section-18">21/7/14</h1>
<p><span class="math inline">\tup{P C Q}</span> is satisfied under total correctness if and only if when <span class="math inline">C</span> is executed with any starting state <span class="math inline">s</span> satisfying <span class="math inline">P</span>, <span class="math inline">C</span> eventually terminates and the final state <span class="math inline">s&#39;</span> satisfies <span class="math inline">Q</span>.</p>
<p><span class="math inline">\tup{P C Q}</span> being satisfied under total correctness can be written as <span class="math inline">\models_{tot} \tup{P C Q}</span>. If we can prove that <span class="math inline">\tup{P C Q}</span> is satisfied under total correctness using total correctness calculus, then <span class="math inline">\vdash_{par} \tup{P C Q}</span>.</p>
<p>Total correctness is basically partial correctness plus the additional condition that the program must terminate.</p>
<p><span class="math inline">\operatorname{States}</span> is the set of all states. <span class="math inline">\operatorname{satisfies}(s, X)</span> is the state <span class="math inline">s</span> satisfying conditions <span class="math inline">X</span>. <span class="math inline">\operatorname{terminates}(C, s)</span> is the program <span class="math inline">C</span> terminating when run with starting state <span class="math inline">s</span>. <span class="math inline">s&#39; = \operatorname{result}(C, s)</span> is the final state <span class="math inline">s&#39;</span> after running the program <span class="math inline">C</span> with starting state <span class="math inline">s</span>, which is undefined if <span class="math inline">C</span> does not terminate.</p>
<p>So <span class="math inline">\models_{par} \tup{P C Q}</span> is equivalent to <span class="math inline">\forall s \in \operatorname{States}, \operatorname{satisfies}(s, P) \wedge \operatorname{terminates}(C, s) \rightarrow \operatorname{satisfies}(\operatorname{result}(C, s), Q)</span>.</p>
<p>So <span class="math inline">\models_{tot} \tup{P C Q}</span> is equivalent to <span class="math inline">\forall s \in \operatorname{States}, \operatorname{satisfies}(s, P) \implies (\operatorname{terminates}(C, s) \wedge \operatorname{satisfies}(\operatorname{result}(C, s), Q))</span>. Alternatively, <span class="math inline">\forall s \in \operatorname{States}, \operatorname{satisfies}(s, P) \wedge \text{(partially correct)} \rightarrow \operatorname{terminates}(C, s)</span>.</p>
<p>We prove total correctness by first proving partial correctness, then proving termination. We prove partial correctness by using some sound inference rules like in natural deduction. Termination is often easy to prove, but there is no algorithm that can check if a program terminates in general - proving termination is undecidable, just like proving things in general.</p>
<p>We also have <strong>logical variables</strong> that appear only in preconditions and postconditions, not the code itself. For example, we might have preconditions <span class="math inline">\set{x_0 \in \mb{N}, x = x_0, y \in \mb{N}}</span> where <span class="math inline">x_0</span> is a logical variable.</p>
<p>Partial correctness is also called <strong>validity</strong>, due to them being valid in the partial correctness calculus.</p>
<p>We now introduce the inference rules of partial correctness.</p>
<table>
<colgroup>
<col style="width: 13%" />
<col style="width: 41%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Rule</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Assignment</td>
<td style="text-align: left;"><span class="math inline">\vdash_{par} \set{\phi[E/x]} x = E; \set{\phi}</span></td>
<td style="text-align: left;"><span class="math inline">\vdash_{par} \tup{\set{y + 1 = 7} x = y + 1; \set{x = 7}}</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Precondition Strengthening (implied)</td>
<td style="text-align: left;"><span class="math inline">\set{\alpha} \rightarrow \set{\alpha&#39;}, \tup{\set{\alpha&#39;} C Q} \vdash_{par} \tup{\set{\alpha} C Q}</span></td>
<td style="text-align: left;"><span class="math inline">\set{y = 1} \rightarrow \set{y \ge 0}, \tup{\set{y \ge 0} C Q} \vdash_{par} \tup{\set{y = 1} C Q}</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Postcondition Weakening (implied)</td>
<td style="text-align: left;"><span class="math inline">\tup{P C \set{\alpha}}, \set{\alpha} \rightarrow \set{\alpha&#39;} \vdash_{par} \tup{P C \set{\alpha&#39;}}</span></td>
<td style="text-align: left;"><span class="math inline">\tup{P C \set{y = 1}}, \set{y = 1} \rightarrow \set{y \ge 0} \vdash_{par} \tup{P C \set{y \ge 0}}</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Composition</td>
<td style="text-align: left;"><span class="math inline">\tup{P C_1 Q}, \tup{Q C_2 R} \vdash_{par} \tup{P C_1;C_2 R}</span></td>
<td style="text-align: left;"><span class="math inline">\tup{\set{x = 1} y = x \set{y = 1}}, \tup{\set{y = 1} k = y * 5 \set{k = 5}} \vdash_{par} \tup{\set{x = 1} y = x; k = y * 5 \set{k = 5}}</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Conditional 1 (if-then)</td>
<td style="text-align: left;"><span class="math inline">\tup{P \cup B C Q}, P \cup \overline B \rightarrow Q \vdash_{par} \tup{P (if (B) C) Q}</span></td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">Conditional 2 (if-then-else)</td>
<td style="text-align: left;"><span class="math inline">\tup{P \cup B C_1 Q}, \tup{P \cup \overline B C_2 Q} \vdash_{par} \tup{P (if (B) C_1 else C_2) Q}</span></td>
<td style="text-align: left;">-</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Partial While (possibly non-terminating)</td>
<td style="text-align: left;"><span class="math inline">\tup{I \cup B C I} \vdash_{par} \tup{I (while (B) C) I \cup \overline B}</span></td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">Partial For 1 (possibly non-terminating)</td>
<td style="text-align: left;"><span class="math inline">\tup{I \cup \set{a \le v, v \le b} C I[v/v + 1]} \vdash_{par} \tup{I[v/a] \cup \set{a \le b} (for (v = a to b) C) I[v/b + 1]}</span></td>
<td style="text-align: left;">-</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Partial For 2 (possibly non-terminating)</td>
<td style="text-align: left;"><span class="math inline">\vdash_{par} \tup{I \cup \set{a &gt; b} (for (v = a to b) C) I}</span></td>
<td style="text-align: left;">-</td>
</tr>
</tbody>
</table>
<p>Note that in the textbook the <span class="math inline">\alpha[x/y]</span> (all occurrences of <span class="math inline">x</span> replaced by <span class="math inline">y</span>) rule is actually written <span class="math inline">\alpha[y/x]</span>. In this course we will be using the <span class="math inline">\alpha[x/y]</span> notation.</p>
<p>;wip: algebra vs calculus in terms of semantic vs syntactic</p>
<h3 id="annotated-programs">Annotated Programs</h3>
<p>We perform program verification by first writing the program in annotated form. This is a form of the program where we insert assertions after each program statement. The composition is implicit - it is assumed that the postconditions of each statement are part of the preconditions of the next.</p>
<p>We then use inference rules to try to justify the assertions and prove that they are true at the points they appear in the program. Implied rules such as precondition strengthening need additional proof that the implication holds - this can be done after everything else.</p>
<p>Each assertion should be an instance of an inference rule, without simplification.</p>
<p>;wip: annotated program example</p>
<h1 id="section-19">23/7/14</h1>
<p>For annotated programs, we usually work backwards from the postconditions to prove things all the way to the beginning.</p>
<p>To verify programs, we start by annotating the code with assertions, then justifying those assertions with inference rules, working upward until we reach the preconditions. Then, we prove the implications such as those used in the implied and if-then rules using thigns like predicate logic, algebra, and basic arithmetic.</p>
<p>For conditionals, the annotated form appears as follows:</p>
<pre><code>{P}
if (B) {
    {P \wedge B} (if-then)
    C
    {Q} (justify by some inference rule dependent on C)
}
{Q} (if-then (a)) [Proof of $P \wedge \neg B \rightarrow Q$]

{P}
if (B) {
    {P \wedge B} (if-then-else)
    C_1
    {Q} (justify by some inference rule)
} else {
    {P \wedge \neg B} (if-then-else)
    C_2
    {Q} (justify by some inference rule)
}
{Q} (if-then-else)</code></pre>
<p>An example of a conditional proof follows:</p>
<pre><code>{true}
if (max &lt; x) {
    {true \wedge max &lt; x} (if-then rule)
    {x \ge x} (assignment rule)
    (true \wedge max &lt; x) \rightarrow x \ge x (implied A)
    max = x;
    {max \ge x}
}
{max \ge x}
{true \wedge \neg (max &lt; x) \rightarrow (max \ge x)}
true \wedge \neg (max &lt; x) \rightarrow (max \ge x) (implied B)

Implied A:
Clearly $x \ge x$ is a tautology and the implication holds.

Implied B:
1. $true \wedge \neg(max &lt; x)$ (assumption)
2. $\neg(max &lt; x)$ (predicate logic)
3. $max \ge x$ (algebra)</code></pre>
<p>Also, the <span class="math inline">I</span> in the Partial While rule is called a <strong>loop invariant</strong>, because it is a condition that doesn't change with respect to the loop. This is basically something that is true both before and after every single run of the loop.</p>
<p>As a result, the loop invariant is true before the loop starts and after it ends. The invariant does not depend on how the loop runs.</p>
<p>Loop invariants must also express relationships between variables used in the body of the loop.</p>
<p>In the core language, only while loops and recursion can result in non-termination - programs that do not use either loops or recursion are guaranteed to terminate.</p>
<h1 id="section-20">28/7/14</h1>
<p>We want to prove that our programs are totally correct - that they are partially correct, and that they terminate. We can now prove partial correctness using the deduction rules given earlier, but now we need to prove that our programs terminate.</p>
<p>Clearly, any program that does not use loops or recursion must terminate since it is impossible that they do not. When we have while loops and recursion, proving termination is more difficult.</p>
<p>We often prove that while loops terminate by finding a variant - an integer expression in the loop that is always non-negative, yet is always decreasing. If we prove that this value exists, then it must be that after enough runs of the loop, it must terminate to prevent the variant from becoming negative.</p>
<p>For example, consider the following code:</p>
<pre><code>{x \ge 0}
y = 1;
z = 0;
while (z != x) {
    z = z+1;
    y = y * z;
}
{y = x!}</code></pre>
<p>A good candidate for the variant is <span class="math inline">x - z</span>, since inside the loop, <span class="math inline">x - z</span> is always non-negative, and on every iteration of the loop, <span class="math inline">x - z</span> must always decrease since <span class="math inline">z</span> increases by 1 and <span class="math inline">x</span> is constant. If we prove these two things are true, then we can prove that the while loop terminates using contradiction - supposing the loop didn't terminate, it would violate the variant.</p>
<p>For loops in our core language appear as follows:</p>
<pre><code>for v = a to b {
    C
}</code></pre>
<p>The value of <span class="math inline">v, a, b</span> cannot be changed within the loop body <span class="math inline">C</span>. The body is not executed at all if <span class="math inline">a &gt; b</span>, and executed <span class="math inline">1 + b - a</span> times otherwise. In each run of the loop, the value of <span class="math inline">v</span> is incremented afterwards. That means that if <span class="math inline">a \le b</span>, the above is equivalent to the following:</p>
<pre><code>v = a;
C
v = v + 1;
C
...
v = b;
C</code></pre>
<p>;wip: up to finishing for loops</p>
<h1 id="section-21">30/7/14</h1>
<p>Something is <strong>computable</strong> if it can be calculated using a systematic procedure - that given enough resources and a certain program, we could solve the problem. There are actually many types of problems that cannot be solved in this way.</p>
<p>For example, the halting problem is not computable - it is impossible to have a program that determines if any given program terminates.</p>
<div class="status-banner" style="display: none; position: fixed; bottom: 0; left: 0; right: 0; text-align: center;">
    <div style="display: inline-block; padding: 0.8em 2em 0.5em 2em; background: black; color: white; font-size: 2em;">
        Rendering <svg xmlns="http://www.w3.org/2000/svg" height="1.4em" viewbox="0 0 1200 500" style="vertical-align: text-bottom"><title>LaTeX logo</title><g transform="matrix(45 0 0 45 40 40)" fill="white"><path d="M5.5 4.4C5.5 4.4 5.2 4.4 5.2 4.4 5.1 5.4 5 6.7 3.2 6.7 3.2 6.7 2.4 6.7 2.4 6.7 1.9 6.7 1.9 6.6 1.9 6.3 1.9 6.3 1.9 1 1.9 1 1.9 0.6 1.9 0.5 2.9 0.5 2.9 0.5 3.2 0.5 3.2 0.5 3.2 0.5 3.2 0.2 3.2 0.2 2.8 0.2 1.9 0.2 1.5 0.2 1.1 0.2 0.3 0.2 0 0.2 0 0.2 0 0.5 0 0.5 0 0.5 0.2 0.5 0.2 0.5 1 0.5 1 0.6 1 0.9 1 0.9 1 6.2 1 6.2 1 6.6 1 6.7 0.2 6.7 0.2 6.7 0 6.7 0 6.7 0 6.7 0 7 0 7 0 7 5.2 7 5.2 7 5.2 7 5.5 4.4 5.5 4.4z"/><path d="M5.3 0.2C5.3 0 5.2 0 5.1 0 5 0 4.9 0 4.9 0.2 4.9 0.2 3.3 4.2 3.3 4.2 3.2 4.4 3.1 4.7 2.5 4.7 2.5 4.7 2.5 5 2.5 5 2.5 5 4 5 4 5 4 5 4 4.7 4 4.7 3.7 4.7 3.5 4.6 3.5 4.4 3.5 4.3 3.5 4.3 3.6 4.2 3.6 4.2 3.9 3.4 3.9 3.4 3.9 3.4 5.9 3.4 5.9 3.4 5.9 3.4 6.3 4.4 6.3 4.4 6.3 4.4 6.3 4.5 6.3 4.5 6.3 4.7 5.9 4.7 5.8 4.7 5.8 4.7 5.8 5 5.8 5 5.8 5 7.7 5 7.7 5 7.7 5 7.7 4.7 7.7 4.7 7.7 4.7 7.6 4.7 7.6 4.7 7.1 4.7 7.1 4.7 7 4.5 7 4.5 5.3 0.2 5.3 0.2zM4.9 0.9C4.9 0.9 5.8 3.1 5.8 3.1 5.8 3.1 4 3.1 4 3.1 4 3.1 4.9 0.9 4.9 0.9z"/><path d="M13.3 0.2C13.3 0.2 7.2 0.2 7.2 0.2 7.2 0.2 7 2.5 7 2.5 7 2.5 7.3 2.5 7.3 2.5 7.4 0.9 7.6 0.5 9.1 0.5 9.3 0.5 9.5 0.5 9.6 0.6 9.8 0.6 9.8 0.7 9.8 0.9 9.8 0.9 9.8 6.2 9.8 6.2 9.8 6.5 9.8 6.7 8.8 6.7 8.8 6.7 8.4 6.7 8.4 6.7 8.4 6.7 8.4 7 8.4 7 8.8 6.9 9.8 6.9 10.3 6.9 10.7 6.9 11.7 6.9 12.2 7 12.2 7 12.2 6.7 12.2 6.7 12.2 6.7 11.8 6.7 11.8 6.7 10.7 6.7 10.7 6.5 10.7 6.2 10.7 6.2 10.7 0.9 10.7 0.9 10.7 0.7 10.7 0.6 10.9 0.6 11 0.5 11.3 0.5 11.5 0.5 13 0.5 13.1 0.9 13.2 2.5 13.2 2.5 13.5 2.5 13.5 2.5 13.5 2.5 13.3 0.2 13.3 0.2z"/><path d="M18.7 6.7C18.7 6.7 18.4 6.7 18.4 6.7 18.2 8.2 17.9 8.9 16.2 8.9 16.2 8.9 14.9 8.9 14.9 8.9 14.4 8.9 14.4 8.8 14.4 8.5 14.4 8.5 14.4 5.9 14.4 5.9 14.4 5.9 15.3 5.9 15.3 5.9 16.3 5.9 16.4 6.2 16.4 7 16.4 7 16.6 7 16.6 7 16.6 7 16.6 4.4 16.6 4.4 16.6 4.4 16.4 4.4 16.4 4.4 16.4 5.2 16.3 5.5 15.3 5.5 15.3 5.5 14.4 5.5 14.4 5.5 14.4 5.5 14.4 3.2 14.4 3.2 14.4 2.8 14.4 2.8 14.9 2.8 14.9 2.8 16.2 2.8 16.2 2.8 17.7 2.8 18 3.3 18.1 4.7 18.1 4.7 18.4 4.7 18.4 4.7 18.4 4.7 18.1 2.5 18.1 2.5 18.1 2.5 12.5 2.5 12.5 2.5 12.5 2.5 12.5 2.8 12.5 2.8 12.5 2.8 12.7 2.8 12.7 2.8 13.5 2.8 13.5 2.9 13.5 3.2 13.5 3.2 13.5 8.4 13.5 8.4 13.5 8.8 13.5 8.9 12.7 8.9 12.7 8.9 12.5 8.9 12.5 8.9 12.5 8.9 12.5 9.2 12.5 9.2 12.5 9.2 18.2 9.2 18.2 9.2 18.2 9.2 18.7 6.7 18.7 6.7z"/><path d="M21.7 3.1C21.7 3.1 23 1.1 23 1.1 23.3 0.8 23.6 0.5 24.5 0.5 24.5 0.5 24.5 0.2 24.5 0.2 24.5 0.2 22.1 0.2 22.1 0.2 22.1 0.2 22.1 0.5 22.1 0.5 22.5 0.5 22.7 0.7 22.7 0.9 22.7 1 22.7 1.1 22.6 1.2 22.6 1.2 21.5 2.8 21.5 2.8 21.5 2.8 20.2 0.9 20.2 0.9 20.2 0.9 20.1 0.8 20.1 0.8 20.1 0.7 20.4 0.5 20.8 0.5 20.8 0.5 20.8 0.2 20.8 0.2 20.4 0.2 19.7 0.2 19.3 0.2 19 0.2 18.4 0.2 18 0.2 18 0.2 18 0.5 18 0.5 18 0.5 18.2 0.5 18.2 0.5 18.8 0.5 19 0.5 19.2 0.8 19.2 0.8 21 3.6 21 3.6 21 3.6 19.4 6 19.4 6 19.2 6.2 18.9 6.7 17.9 6.7 17.9 6.7 17.9 7 17.9 7 17.9 7 20.3 7 20.3 7 20.3 7 20.3 6.7 20.3 6.7 19.8 6.7 19.7 6.4 19.7 6.2 19.7 6.1 19.7 6.1 19.8 6 19.8 6 21.2 3.9 21.2 3.9 21.2 3.9 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.4 22.8 6.5 22.6 6.7 22.2 6.7 22.2 6.7 22.2 7 22.2 7 22.5 6.9 23.2 6.9 23.6 6.9 24 6.9 24.5 7 24.9 7 24.9 7 24.9 6.7 24.9 6.7 24.9 6.7 24.7 6.7 24.7 6.7 24.2 6.7 24 6.6 23.8 6.3 23.8 6.3 21.7 3.1 21.7 3.1z"/></g></svg> math...
    </div>
</div>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2017 Anthony Zhang.
</div>
</body>
</html>
