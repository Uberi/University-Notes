<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>MATH138 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso.light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>
function highlight() { // highlight all code blocks using HighlightJS
  var code_blocks = document.getElementsByTagName("code");
  for (var i = 0; i < code_blocks.length; i++)
    hljs.highlightBlock(code_blocks[i]);
}
</script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body onload="highlight()">
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/Résumé.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="http://www.linkedin.com/pub/anthony-zhang/8b/aa5/7aa" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:azhang9@gmail.com" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.mesecons.net/">mesecons</a></li>
    <span class="divider"></span>
    <li><a href="http://www.autohotkey.net/~Uberi/">autohotkey.net</a></li>
  </ul>
<h1 id="math138">MATH138</h1>
<p>Calculus II</p>
<pre><code>Instructor: Matthew Scott
Section 002
Email: mscott@uwaterloo.ca
Office: MC 6114
Office hours: Mondays 11:30am-12:15pm, 3:00pm-3:30pm
Tutorial: Wednesdays 3:30pm in MC 2035, starting Jan. 15</code></pre>
<p><span class="math">\[
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l&#39;H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\]</span></p>
<h1 id="section">6/1/14</h1>
<p>Assignments are due every Friday at 3:30pm. They are posted on LEARN.</p>
<p>My own drop box is box 5, slot 12</p>
<p>Midterm is Feb. 24, 7-9pm.</p>
<p>Lecture notes are on the <a href="http://www.math.uwaterloo.ca/~mscott/euler.htm">course website</a>, posted every week. The password to the website is &quot;euler&quot;. ;wip: get these every week</p>
<p>Course outline:</p>
<ul>
<li>Techniques of integration and applications.</li>
<li>Extensions of single variable calculus - differential equations, vector calculus, etc.</li>
<li>Taylor polynomials</li>
</ul>
<p>Sequence: <span class="math">\(1, 2, 3, \ldots\)</span> Series: <span class="math">\(1 + 2 + 3 + \ldots\)</span></p>
<p>Taylor polynomials are series of functions, which allow us to represent almost any function as a polynomial. This is the most powerful technique in applied mathematics - science and mathematics.</p>
<p>By the way, <span class="math">\(\dee x\)</span> is called an <strong>infinitesmal</strong>.</p>
<h2 id="techniques-of-integration">Techniques of Integration</h2>
<p>Techniques of integration rewrite functions in forms that we can't integrate into forms that we can integrate, or simpler forms that we might be able to apply other techniques on.</p>
<h3 id="method-of-substitution">Method of substitution</h3>
<p>The method of substitution is based on choosing a subexpression <span class="math">\(u\)</span>, and then integrating with respect to it. If <span class="math">\(u\)</span> is chosen carefully, it is occasionally possible to simplify the integral.</p>
<p>This method works best when a <strong>function and its derivative appear in the integrand</strong>.</p>
<p>This works with expressions of the form <span class="math">\(\int f(x) \frac{\dee f}{\dee x} \dee x\)</span>.</p>
<p>Let <span class="math">\(u = f(x)\)</span>. Since <span class="math">\(\frac{\dee u}{\dee x} = \frac{\dee u}{\dee x}\)</span>, <span class="math">\(\dee u = \frac{\dee u}{\dee x} \dee x\)</span> (multiply both sides by <span class="math">\(\dee x\)</span>). This is possible because of infinismals, which work in wierd and wonderful ways. So <span class="math">\(\dee x = \frac{1}{\frac{\dee u}{\dee x}} \dee u\)</span>.</p>
<p>So <span class="math">\(\int f(x) \frac{\dee}{\dee x} f(x) \dee x = \int u \frac{\dee u}{\dee x} \dee x = \int u \frac{\dee u}{\dee x} \frac{1}{\frac{\dee u}{\dee x}} \dee u = \int u \dee u = \frac{u^2}{2} + c = \frac{f(x)^2}{2} + c\)</span>.</p>
<p>Even if we can't simplify it far enough to get an antiderivative, integration by substitution can still considerably simplify an integrand into something more manageable.</p>
<p>What about definite integrals? We need to be aware of the limits of integration when doing the variable switch:</p>
<p>We are given <span class="math">\(\int_a^b f(x) \frac{\dee}{\dee x} f(x) \dee x\)</span>.</p>
<p>Let <span class="math">\(u = f(x)\)</span>. We know that <span class="math">\(\dee x = \frac{1}{\frac{\dee u}{\dee x}} \dee u\)</span>.</p>
<p>So <span class="math">\(\int_a^b f(x) \frac{\dee}{\dee x} f(x) \dee x = \int_{u(a)}^{u(b)} u \frac{\dee u}{\dee x} \dee x = \int_{u(a)}^{u(b)} u \frac{\dee u}{\dee x} \frac{1}{\frac{\dee u}{\dee x}} \dee u = \int_{u(a)}^{u(b)} u \dee u = \evalat{\frac{u^2}{2}}_{u(a)}^{u(b)} + c = \evalat{\frac{f(x)^2}{2}}_a^b + c\)</span>.</p>
<p>Basically, if we can find a factor of the integrand <span class="math">\(u\)</span> such that its derivative also appears in the integrand, the method of substitution can get rid of the derivative.</p>
<p>Evaluate <span class="math">\(\int \cos x \sin x \dee x\)</span></p>
<blockquote>
<p>Let <span class="math">\(u = \sin x\)</span>. So <span class="math">\(\dee u = \cos x \dee x\)</span>.<br />So <span class="math">\(\int \cos x \sin x \dee x = \int \sin x \dee u = -\int u \dee u\)</span>.<br />Clearly, <span class="math">\(\int u \dee u = \frac{u^2}{2} + c = \frac{\sin^2 x}{2} + c\)</span>.</p>
</blockquote>
<p>Substitution is useful when we can figure out what a useful substitution would be.</p>
<p>One clue that the substitution is a good choice is if the derivative of the substitution appears in the numerator of the function.</p>
<p>How do we prove that <span class="math">\(\int_1^x \frac{1}{t} = \ln x\)</span>? How do we know that both have the same properties:</p>
<ul>
<li>Property 1 - multiplication rule: <span class="math">\(\ln ab = \ln a + \ln b\)</span></li>
<li>Property 2 - power rule: <span class="math">\(\ln a^r = r \ln a\)</span>)</li>
</ul>
<p>We want to prove property 1:</p>
<blockquote>
<p>Select some <span class="math">\(a\)</span> and <span class="math">\(b\)</span>.<br />We want to prove that <span class="math">\(\int_1^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_1^b \frac{1}{t} \dee t\)</span>.<br />By linearity of integrals, <span class="math">\(\int_1^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_a^{ab} \frac{1}{t} \dee t\)</span>.<br />Let <span class="math">\(u = \frac{t}{a}\)</span>, so <span class="math">\(t = ua\)</span>. Then <span class="math">\(\dee t = \frac{\dee t}{\dee u} \dee u = a \dee u\)</span>.<br />So <span class="math">\(\int_a^{ab} \frac{1}{t} \dee t = \int_\frac{a}{a}^\frac{ab}{a} \frac{1}{ua} a \dee u = \int_1^b \frac{1}{u} \dee u\)</span>.<br />So <span class="math">\(\int_1^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_a^{ab} \frac{1}{t} \dee t = \int_1^a \frac{1}{t} \dee t + \int_1^b \frac{1}{u} \dee u\)</span>.</p>
</blockquote>
<p>Dummy variables can be swapped for any value, even functions like <span class="math">\(f(t)\)</span>.</p>
<h1 id="section-1">8/1/14</h1>
<p>To prove property 2, we need to show that <span class="math">\(\int_1^{a^r} \frac{1}{u} \dee u = r \int_1^a \frac{1}{t} \dee t\)</span>. To do this, we find a substitution that results in the desired limits of integration.</p>
<p>To prove property 2:</p>
<blockquote>
<p>Select some <span class="math">\(u\)</span>.<br />We want to prove that <span class="math">\(\int_1^{a^r} \frac{1}{t} \dee t = r \int_1^a \frac{1}{t} \dee t\)</span>.<br />Let <span class="math">\(u = t^\frac{1}{r}\)</span>, so <span class="math">\(t = u^r\)</span>. Then <span class="math">\(\dee t = \frac{\dee t}{\dee u} \dee u = \frac{\dee}{\dee u} u^r \dee u = ru^{r - 1} \dee u\)</span>.<br />So <span class="math">\(\int_1^{a^r} \frac{1}{t} \dee t = \int_{1^\frac{1}{r}}^{{a^r}^\frac{1}{r}} \frac{1}{u^r} ru^{r - 1} \dee u = \int_1^a \frac{1}{u} r \dee u = r \int_1^a \frac{1}{u} \dee u\)</span>.</p>
</blockquote>
<h3 id="differentiating-with-respect-to-functions">Differentiating with respect to functions</h3>
<p>As an aside, we can actually differentiate things with respect to functions.</p>
<p>The important property is that <span class="math">\(\frac{\dee x}{\dee b(x)} = \frac{1}{\frac{\dee b(x)}{\dee x}}\)</span>.</p>
<p>Note that <span class="math">\(\frac{\dee a(x)}{\dee b(x)} = \frac{\dee a(x)}{\dee x} \frac{\dee x}{\dee b(x)} = \frac{\dee a(x)}{\dee x} \frac{1}{\frac{\dee b(x)}{\dee x}}\)</span>.</p>
<p>So <span class="math">\(\frac{\dee a(x)}{\dee b(x)} = \frac{\frac{\dee a(x)}{\dee x}}{\frac{\dee b(x)}{\dee x}} = \frac{a&#39;(x)}{b&#39;(x)}\)</span>.</p>
<h3 id="integration-by-parts">Integration by Parts</h3>
<p>We often have integrands that are products. For example, <span class="math">\(\int x \sin x \dee x\)</span></p>
<p>It would be nice to be able to differentiate or integrate just one of the factors rather than having to do the whole thing.</p>
<p>Recall the product rule: <span class="math">\(\frac{\dee}{\dee x} (a(x) b(x)) = (\frac{\dee}{\dee x} a(x)) b(x) + a(x) \frac{\dee}{\dee x} b(x)\)</span>.</p>
<p>Move the terms around: <span class="math">\((\frac{\dee}{\dee x} a(x)) b(x) = \frac{\dee}{\dee x} (a(x) b(x)) - a(x) \frac{\dee}{\dee x} b(x)\)</span>.</p>
<p>If we integrate both sides with respect to <span class="math">\(x\)</span>, we get: <span class="math">\(\int (\frac{\dee}{\dee x} a(x)) b(x) = \int \frac{\dee}{\dee x} a(x) b(x) - \int a(x) \frac{\dee}{\dee x} b(x)\)</span>.</p>
<p>By FTC2, <span class="math">\(\int (\frac{\dee}{\dee x} a(x)) b(x) = a(x) b(x) + c - \int a(x) \frac{\dee}{\dee x} b(x)\)</span>.</p>
<p>Since there would also be a <span class="math">\(c\)</span> term from the second integral, we don't need to write it. So <span class="math">\(\int (\frac{\dee}{\dee x} a(x)) b(x) \dee x = a(x) b(x) - \int a(x) \frac{\dee}{\dee x} b(x) \dee x\)</span>.</p>
<p>This is the <strong>integration by parts rule</strong>.</p>
<p>Using the same idea, we find that <span class="math">\(\int_a^b (\frac{\dee}{\dee x} a(x)) b(x) = \evalat{a(x) b(x)}_{x = a}^{x = b} - \int_a^b a(x) \frac{\dee}{\dee x} b(x)\)</span>.</p>
<p>When we use the rule, we want to identify two parts of the product such that one of the parts (b) is the factor that becomes <strong>simpler when differentiated</strong>, and the other part (a) is chosen as the <strong>integral of the factor</strong>.</p>
<p>Simplify <span class="math">\(\int x \sin x \dee x\)</span>:</p>
<blockquote>
<p><span class="math">\(x\)</span> is much simpler when differentiated. Let <span class="math">\(b(x) = x\)</span>.<br /><span class="math">\(\sin x\)</span> is integrable. Let <span class="math">\(a(x) = \int \sin x = -\cos x\)</span>.<br />So <span class="math">\(\int x \sin x = \int x \frac{\dee}{\dee x} (-\cos x) = -x \cos x - \int (-\cos x) 1 \dee x\)</span>, by integration by parts.<br />So <span class="math">\(-x \cos x - \int (-\cos x) 1 \dee x = -x \cos x + \sin x + c\)</span>.</p>
</blockquote>
<p>We can check the answer by differentiating: <span class="math">\(\frac{\dee}{\dee x} (-x \cos x + \sin x + c) = x \sin x\)</span>.</p>
<p>When we use integration by parts, we differentiate one factor, and integrate the other. Then, we can apply the integration by parts formula and obtain a possibly simpler version.</p>
<p>Simplify <span class="math">\(\int_0^1 x e^{-x} \dee x\)</span>:</p>
<blockquote>
<p><span class="math">\[
\begin{align}
\int_0^1 x e^{-x} \dee x &amp;= \int_0^1 x \frac{\dee}{\dee x} (-e^{-x}) \dee x \\
&amp;= \evalat{x (-e^{-x})}_0^1 - \int_0^1 \left(\frac{\dee}{\dee x} x\right) (-e^{-x}) \dee x \\
&amp;= \evalat{x (-e^{-x})}_0^1 + \int_0^1 e^{-x} \dee x \\
&amp;= -\frac{2}{e} \\
\end{align}
\]</span></p>
</blockquote>
<p>Simplify <span class="math">\(\int_0^1 x^n (\ln x)^n \dee x\)</span>:</p>
<blockquote>
<p>;wip</p>
</blockquote>
<p>We often write the integration by parts formula in different forms: <span class="math">\(\int a \dee b = ab - \int b \dee a\)</span>, or <span class="math">\(\int f&#39;(x) g(x) \dee x = f(x) g(x) - \int f(x) g&#39;(x) \dee x\)</span>.</p>
<p>An interesting trick is that we can use integration by parts to integrate anything, since everything is a product of itself and 1.</p>
<p>For example, consider <span class="math">\(\int \arcsin x \dee x\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\int 1 \cdot \arcsin x \dee x = \int (\frac{\dee}{\dee x} x) \arcsin x \dee x\)</span>.<br />Using integration by parts, with <span class="math">\(a(x) = x, b(x) = \arcsin x\)</span>, <span class="math">\(\int (\frac{\dee}{\dee x} x) \arcsin x \dee x = x \arcsin x - \int \frac{x}{\sqrt{1 - x^2}} \dee x\)</span>.<br />We can now use integration by substitution with <span class="math">\(u = 1 - x^2\)</span> to simplify <span class="math">\(\int \frac{x}{\sqrt{1 - x^2}} \dee x\)</span>.<br />Clearly, <span class="math">\(\dee x = -\frac{1}{2x} \dee x\)</span> and <span class="math">\(\int \frac{1}{\sqrt{1 - x^2}} \dee x = -\frac{1}{2} \int \frac{1}{\sqrt{u}} \dee u = -\frac{1}{2} \int u^{-\frac{1}{2}} \dee u = -\frac{1}{2} 2 \sqrt{u} + c = -\sqrt{1 - x^2} + c\)</span>.<br />So <span class="math">\(\int \arcsin x \dee x = x \arcsin x - \int \frac{x}{\sqrt{1 - x^2}} \dee x = x \arcsin x + \sqrt{1 - x^2} + c\)</span>.</p>
</blockquote>
<p>Simplify <span class="math">\(\int \arccos x \dee x\)</span>:</p>
<blockquote>
<p>Using integration by parts, with <span class="math">\(a(x) = x, b(x) = \arccos x\)</span>, <span class="math">\(\int (\frac{\dee}{\dee x} x) \arccos x \dee x = x \arccos x - \int \frac{x}{\sqrt{1 - x^2}} \dee x\)</span>.<br />From the previous question, we know that <span class="math">\(\int \frac{x}{\sqrt{1 - x^2}} \dee x = -\sqrt{1 - x^2} + c\)</span>.<br />So <span class="math">\(\int (\frac{\dee}{\dee x} x) \arccos x \dee x = x \arccos x - \int \frac{x}{\sqrt{1 - x^2}} \dee x = x \arccos x + \sqrt{1 - x^2} + c\)</span>.</p>
</blockquote>
<p>Simplify <span class="math">\(\int \ln x \dee x\)</span>:</p>
<blockquote>
<p>Using integration by parts, with <span class="math">\(a(x) = x, b(x) = \arccos x\)</span>. <span class="math">\(\int (\frac{\dee}{\dee x} x) \ln x \dee x = x \ln x - \int \frac{x}{x} \dee x = x \ln x - x\)</span>.</p>
</blockquote>
<h1 id="section-2">10/1/14</h1>
<p>The integration by parts rule is also written as <span class="math">\(\int v \dee u = uv - \int u \dee v\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\dee a = \frac{\dee a}{\dee x} \dee x\)</span> and <span class="math">\(\dee b = \frac{\dee b}{\dee x} \dee x\)</span>.<br />We know that <span class="math">\(\int (\frac{\dee}{\dee x} a(x)) b(x) \dee x = a(x) b(x) - \int a(x) \frac{\dee}{\dee x} b(x) \dee x\)</span> and so <span class="math">\(\int \frac{\dee a}{\dee x} b(x) \dee x = a(x) b(x) - \int a(x) \frac{\dee b}{\dee x} \dee x\)</span>.<br />So <span class="math">\(\int b(x) \dee a = a(x) b(x) - \int a(x) \dee b\)</span>.</p>
</blockquote>
<p>We can also write it as <span class="math">\(\int f(x) g(x) \dee x = \int f(x) \dee x g(x) - \int \int f(x) \dee x \frac{\dee g}{\dee x} \dee x\)</span>.</p>
<h3 id="getting-back-what-we-started-with">Getting Back What We Started With</h3>
<p>Consider <span class="math">\(I = \int e^{-x} \sin x\)</span>:</p>
<blockquote>
<p>We choose <span class="math">\(\frac{\dee}{\dee x} e^{-x} = -e^{-x}\)</span> and <span class="math">\(\int \sin x \dee x = -\cos x\)</span>.<br />So <span class="math">\(I = \int e^{-x} \frac{\dee}{\dee x} (-\cos x) \dee x = e^{-x} (-\cos x) - \int e^{-x} \cos x\)</span>.<br />We choose <span class="math">\(\frac{\dee}{\dee x} (-e^{-x}) = e^{-x}\)</span> and <span class="math">\(\int \cos x \dee x = \sin x\)</span>.<br />Clearly, <span class="math">\(\int e^{-x} \cos x = \int e^{-x} \frac{\dee}{\dee x} \sin x = e^{-x} \sin x - \int (-e^{-x}) \sin x = e^{-x} \sin x + I\)</span>.<br />So <span class="math">\(I = -e^{-x} \cos x - \int e^{-x} \cos x = -e^{-x} \cos x - e^{-x} \sin x - I\)</span>.<br />So <span class="math">\(2I = -e^{-x} (\cos x + \sin x)\)</span> and <span class="math">\(I = -\frac{1}{2}e^{-x} (\cos x + \sin x)\)</span>.</p>
</blockquote>
<p>Basically, we used integration by parts to rewrite the expression, then used integration by parts again to simplify the remaining integral. In doing so we obtained a result that contained the original expression, which we substituted and solved algebraically.</p>
<p>This technique is only really useful for problems of the form <span class="math">\(\int e^{ax} \sin bx \dee x\)</span> or <span class="math">\(\int e^{ax} \cos bx \dee x\)</span>.</p>
<p>Simplify <span class="math">\(\int_0^1 (-\ln x)^n \dee x, n \in \mb{N}\)</span>:</p>
<blockquote>
<p>We will try it for the first few values of <span class="math">\(n\)</span>.<br />For <span class="math">\(n = 1\)</span>, <span class="math">\(\int_0^1 (-\ln x)^n \dee x = -\int_0^1 1 \ln x \dee x = -\int_0^1 \ln x \frac{\dee}{\dee x} x = -\evalat{x \ln x}_0^1 + \int_0^1 x \frac{1}{x} = -1 \ln 1 + 0 \ln 0 + 1\)</span> (indeterminate form <span class="math">\(0 \cdot -\infty\)</span>).<br />This is a thing known as an improper integral (covered later in the course).<br />We can solve it because what we really want is <span class="math">\(\lim_{x \to 0} x \ln x = \lim_{x \to 0} \frac{\ln x}{\frac{1}{x}} \lH \lim_{x \to 0} \frac{\frac{1}{x}}{-\frac{1}{x^2}} = \lim_{x \to 0} (-x) = 0\)</span> rather than the value <span class="math">\(0 \ln 0\)</span>.<br />So <span class="math">\(-\int_0^1 \ln x \dee x = -1 \ln 1 + 0 + 1 = 1\)</span>.<br />If we repeat this for <span class="math">\(n = 2, 3, \ldots\)</span>, we find that <span class="math">\(\int_0^1 (-\ln x)^n \dee x = n!, n \in \mb{N}\)</span>, yet it also works for fractional values of <span class="math">\(n\)</span> - this is the generalized factorial over positive real numbers!<br />;wip: use induction</p>
</blockquote>
<h1 id="section-3">13/1/14</h1>
<h2 id="trigonometric-substitution">Trigonometric Substitution</h2>
<p>This is integration by substitution with the substitution using trignonometric functions.</p>
<p>We use trigonometric functions in our substitutions and use trigonometric identities to simplify the integrand.</p>
<p>We will need to know:</p>
<ul>
<li>Pythagorean theorem: <span class="math">\(\cos^2 \theta + \sin^2 \theta = 1\)</span></li>
<li>Half angle cosine formula: <span class="math">\(\cos^2 \theta = \frac{1}{2}(1 + \cos 2\theta)\)</span></li>
<li>Half angle sine formula: <span class="math">\(\sin^2 \theta = \frac{1}{2}(1 - \cos 2\theta)\)</span></li>
<li>Pythagorean theorem divided by <span class="math">\(\cos^2 \theta\)</span>: <span class="math">\(1 + \tan^2 \theta = \sec^2 \theta\)</span></li>
</ul>
<p>We usually need this method when we have a square root of a quadratic expression.</p>
<p>Common substitutions:</p>
<ul>
<li>Use <span class="math">\(1 - \sin^2 \theta = \cos^2 \theta\)</span> to use <span class="math">\(\sqrt{1 - x^2} = \sqrt{\cos^2 \theta} = \cos \theta\)</span> via <span class="math">\(x = \sin \theta\)</span>.</li>
<li>Use <span class="math">\(1 + \tan^2 \theta = \sec^2 \theta\)</span> to use <span class="math">\(\sqrt{1 + x^2} = \sqrt{\sec^2 \theta} = \sec \theta\)</span> via <span class="math">\(x = \tan \theta\)</span>.</li>
<li>Use <span class="math">\(\sec^2 \theta - 1 = \tan^2 \theta\)</span> to use <span class="math">\(\sqrt{x^2 - 1} = \sqrt{\tan^2 \theta} = \tan \theta\)</span> via <span class="math">\(x = \sec \theta\)</span>.</li>
</ul>
<p>Using this technique, we can replace <span class="math">\(\sqrt{\pm a^2 \pm x^2}\)</span> with trigonometric functions, and then use trigonometric identities on them. Afterwards, we might simplify by changing the trigonometric functions back into square roots.</p>
<p>Derivatives:</p>
<ul>
<li><span class="math">\(\cos&#39; \theta = -\sin \theta\)</span> where <span class="math">\(-\frac{\pi}{2} \le \theta &lt; \frac{\pi}{2}\)</span></li>
<li><span class="math">\(\sin&#39; \theta = \cos \theta\)</span> where <span class="math">\(-\frac{\pi}{2} \le \theta &lt; \frac{\pi}{2}\)</span></li>
<li><span class="math">\(\tan&#39; \theta = \sec^2 \theta\)</span> where <span class="math">\(0 \le \theta &lt; \frac{\pi}{2}\)</span></li>
</ul>
<p>Consider <span class="math">\(\int \frac{1}{x^2 \sqrt{x^2 + 4}} \dee x\)</span>:</p>
<blockquote>
<p>We can draw a triangle with hypotenuse <span class="math">\(\sqrt{x^2 + 4}\)</span>, opposite side <span class="math">\(x\)</span>, and adjacent side <span class="math">\(2\)</span> representing this value.<br />Let <span class="math">\(\theta\)</span> represent the angle between the adjacent side and the hypotenuse. By the Pythagorean theorem. Then <span class="math">\(x = 2 \tan \theta\)</span>. Then <span class="math">\(\dee x = 2 \sec^2 \theta \dee \theta\)</span>.<br />Clearly, <span class="math">\(\int \frac{1}{x^2 \sqrt{x^2 + 4}} \dee x = \int \frac{1}{4 \tan^2 \theta \sqrt{4 \tan^2 \theta + 4}} 2 \sec^2 \theta \dee \theta = \int \frac{1}{4 \tan^2 \theta \sqrt{4 (\tan^2 \theta + 1)}} 2 \sec^2 \theta \dee \theta = \int \frac{1}{4 \tan^2 \theta 2 \sec \theta} 2 \sec^2 \theta \dee \theta = \frac{1}{4} \int \frac{\sec \theta}{\tan^2 \theta} \dee \theta = \frac{1}{4} \int \frac{\\cos \theta}{\sin^2 \theta} \dee \theta\)</span>.<br />Let <span class="math">\(u = \sin \theta\)</span>. Then <span class="math">\(\dee x = \frac{1}{\cos \theta} \dee \theta\)</span>.<br />So <span class="math">\(\frac{1}{4} \int \frac{\cos \theta}{\sin^2 \theta} \dee \theta = \frac{1}{4} \int \frac{\cos \theta}{u^2} \frac{1}{\cos \theta} \dee u = \frac{1}{4} \int \frac{1}{u^2} \dee u = -\frac{1}{4u} + c = -\frac{1}{4 \sin \theta} + c\)</span>.<br />Since <span class="math">\(x = 2 \tan \theta\)</span>, <span class="math">\(\theta = \arctan \frac{x}{2}\)</span>.<br />;wip: rewrite in terms of x using the triangle again So <span class="math">\(\int \frac{1}{x^2 \sqrt{x^2 + 4}} \dee x = -\frac{1}{4} \frac{\sqrt{4 + x^2}}{x} + c\)</span>.</p>
</blockquote>
<p>This works because <span class="math">\(\cos \theta\)</span> is always positive or 0 in the domain we are considering.</p>
<p>;wip: improve this day's notes so they actually make sense</p>
<h1 id="section-4">15/1/14</h1>
<p>We do substitution by choosing a <span class="math">\(u = f(x)\)</span>, then doing <span class="math">\(\frac{\dee u}{\dee x} = f&#39;(x)\)</span>, so <span class="math">\(\dee u = f&#39;(x) \dee x\)</span>, so <span class="math">\(\dee x = \frac{1}{f&#39;(x)} \dee x\)</span>.</p>
<p>Evaluate <span class="math">\(\int \frac{x}{\sqrt{3 - 2x - x^2}}\)</span>:</p>
<pre><code>          /|
       2 / |
        /  | $u$
       /___|
$\theta$ $\sqrt{4 - u^2}$</code></pre>
<blockquote>
<p>We want to use trigonometric substitution to solve this, but it isn't in the right form.<br />We want to write <span class="math">\(3 - 2x - x^2\)</span> in the form of <span class="math">\(a^2 + (x + b)^2\)</span> (completing the square).<br />Clearly, <span class="math">\(3 - 2x - x^2 = 3 - (2x + x^2) = 3 - (2x + x^2 + 1) + 1\)</span> (make the term into a perfect square trinomial by adding <span class="math">\(\frac{b}{2}\)</span> in a way that cancels out).<br />So <span class="math">\(3 - 2x - x^2 = 4 - (x + 1)^2\)</span> and <span class="math">\(\int \frac{x}{\sqrt{3 - 2x - x^2}} = \int \frac{x}{\sqrt{4 - (x + 1)^2}}\)</span>.<br />Let <span class="math">\(u = x + 1\)</span>. Then <span class="math">\(\dee u = \dee x\)</span>.<br />We can draw a triangle with the hypotenuse being 2, the opposite side <span class="math">\(u\)</span>, and adjacent side <span class="math">\(\sqrt{4 - u^2}\)</span>.<br />From the triangle, we know that <span class="math">\(u = 2\sin \theta\)</span> (<span class="math">\(x = 2\sin \theta - 1\)</span>) and <span class="math">\(\sqrt{4 - u^2} = 2 \cos \theta\)</span>, so <span class="math">\(\dee u = 2 \cos \theta \dee \theta\)</span>.<br />So <span class="math">\(\int \frac{x}{\sqrt{4 - (x + 1)^2}} = \int \frac{2\sin \theta - 1}{2 \cos \theta} 2\cos \theta \dee \theta = \int 2\sin \theta - 1 \dee \theta = -2 \cos \theta - \theta + c\)</span>.<br />From the triangle, we can tell that <span class="math">\(\cos \theta = \frac{\sqrt{4 - u^2}}{2}\)</span>, since the cosine is the adjacent over the hypotenuse.<br />Clearly, <span class="math">\(\theta = \arcsin \frac{u}{2}\)</span> So <span class="math">\(\int \frac{x}{\sqrt{3 - 2x - x^2}} = -2 \cos \theta - \theta + c = -2 \frac{\sqrt{4 - (x + 1)^2}}{2} - \arcsin \frac{x + 1}{2} + c\)</span>.</p>
</blockquote>
<h2 id="partial-fraction-decomposition">Partial Fraction Decomposition</h2>
<p>Consider <span class="math">\(\frac{1}{2} + \frac{1}{3} = \frac{3 + 2}{2 \cdot 3} = \frac{5}{6}\)</span>.</p>
<p>What if we went the opposite way? We go from <span class="math">\(\frac{5}{6}\)</span> to <span class="math">\(\frac{A}{2} + \frac{B}{3}\)</span> by factoring <span class="math">\(6\)</span>, and then solve for possible solutions for <span class="math">\(3A + 2B = 5\)</span> and pick <span class="math">\(A = 1, B = 1\)</span>. Now we have <span class="math">\(\frac{1}{2} + \frac{1}{3}\)</span>, as required.</p>
<p>This can also be done with polynomials. Using this technique, we can integrate <strong>rational functions of polynomials</strong>.</p>
<p>Consider <span class="math">\(\int \frac{P(x)}{Q(x)} \dee x\)</span>. We can always factor polynomials into a set of linear factors <span class="math">\(Q(x) = (x + c_1) \cdot \ldots \cdot (x + c_n)\)</span>.</p>
<p>So <span class="math">\(\int \frac{P(x)}{Q(x)} \dee x = \int \frac{P(x)}{(x + c_1) \cdot \ldots \cdot (x + c_n)} \dee x = \int \frac{A_1}{x + c_1} \dee x + \ldots + \int \frac{A_n}{x + c_n} \dee x\)</span>.</p>
<p>Now we have a bunch of integrals of constants over <span class="math">\(x\)</span> with offsets. This is easily integrated into logarithms.</p>
<p>We can solve for <span class="math">\(A_1, \ldots, A_n\)</span> by cross multiplying: <span class="math">\(\frac{P(x)}{Q(x)} = \frac{A_1 ((x + c_2) \cdot \ldots \cdot (x + c_n)) + \ldots + A_n ((x + c_1) \cdot \ldots \cdot (x + c_{n - 1}))}{(x + c_1) \cdot \ldots \cdot (x + c_n)}\)</span>. So <span class="math">\(P(x) = A_1 ((x + c_2) \cdot \ldots \cdot (x + c_n)) + \ldots + A_n ((x + c_1) \cdot \ldots \cdot (x + c_{n - 1}))\)</span>.</p>
<p>For now, assume that the order of <span class="math">\(P\)</span> is less than that of <span class="math">\(Q\)</span>.</p>
<p>We can find <span class="math">\(A\)</span> and <span class="math">\(B\)</span> using the <strong>cover up method</strong>: if we choose values of <span class="math">\(x = -c_i, 1 \le i \le n\)</span>, then there is a 0 factor in every term on the right side except the one containing <span class="math">\(A_i\)</span>. It is then trivial to solve for <span class="math">\(A_i\)</span>. Repeat this for each <span class="math">\(i\)</span> and we can find <span class="math">\(A_1, \ldots, A_n\)</span>.</p>
<p>We can also find <span class="math">\(A\)</span> and <span class="math">\(B\)</span> by setting up a system of equations. Clearly, <span class="math">\(x + 1 = A(x + 3) + B(x + 2) = (A + B)x + (3A + 2B)\)</span>. Since <span class="math">\((A + B)x = x\)</span> and <span class="math">\((3A + 2B) = 1\)</span>, <span class="math">\(A + B = 1\)</span> and <span class="math">\(3A + 2B = 1\)</span>, so we solve for the two linear equations to find <span class="math">\(A\)</span> and <span class="math">\(B\)</span>.</p>
<p>Evaluate <span class="math">\(\int \frac{x - 1}{x^2 + 5x + 6} \dee x\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\int \frac{x - 1}{x^2 + 5x + 6} \dee x = \int \frac{x - 1}{(x + 2)(x + 3)} \dee x = \int \frac{A}{x + 2} \dee x + \int \frac{B}{x + 3} \dee x\)</span> for some <span class="math">\(A\)</span> and <span class="math">\(B\)</span>.<br />Now we need to find <span class="math">\(A\)</span> and <span class="math">\(B\)</span>. We do this by solving <span class="math">\(x + 1 = A(x + 3) + B(x + 2)\)</span>.<br />Note that <span class="math">\(A\)</span> and <span class="math">\(B\)</span> must work for any <span class="math">\(x\)</span>. We now solve using the cover up method.<br />Choose <span class="math">\(x = -3\)</span> (because <span class="math">\(A(x + 3) = 0\)</span>). Then <span class="math">\(-3 + 1 = A(-3 + 3) + B(-3 + 2) = -2 = -B\)</span>. Then <span class="math">\(B = 2\)</span>.<br />Choose <span class="math">\(x = -2\)</span> (because <span class="math">\(B(x + 2) = 0\)</span>). Then <span class="math">\(-2 + 1 = A(-2 + 3) + B(-2 + 2) = -1 = B\)</span>. Then <span class="math">\(A = -1\)</span>.<br />Then <span class="math">\(\int \frac{x - 1}{x^2 + 5x + 6} \dee x = -\int \frac{1}{x + 2} \dee x + \int \frac{2}{x + 3} \dee x = -\ln(x + 2) + 2\ln(x + 3) + c\)</span>.</p>
</blockquote>
<h1 id="section-5">17/1/14</h1>
<p>Note that partial fraction decomposition only works for factorable polynomials.</p>
<p>What if the numerator has a higher or equal degree than the denominator? We can use long division to make it lower again to apply partial fraction decomposition. When we do long division, we get a normal polynomial as the quotient and a rational function with the degree of the numerator lower than that of the denominator.</p>
<p>Evaluate <span class="math">\(\int \frac{x^3 + 4x^2 + 2x - 5}{x^2 + 5x + 6} \dee x\)</span>:</p>
<pre><code>                             x - 1
              ____________________
x^2 + 5x + 6 | x^3 + 4x^2 + 2x - 5
               x^3 + 5x^2 + 6x
               -------------------
                     -x^2 - 4x - 5
                     -x^2 - 5x - 6
                     -------------
                             x + 1</code></pre>
<blockquote>
<p>Clearly, <span class="math">\(\int \frac{x^3 + 4x^2 + 2x - 5}{x^2 + 5x + 6} \dee x = \int (x - 1) \dee x + \int \frac{x + 1}{x^2 + 5x + 6} \dee x = \frac{x^2}{2} - x +  \int \frac{x + 1}{(x + 2)(x + 3)} \dee x\)</span>.<br />;wip</p>
</blockquote>
<p>What if there are repeated factors? We can keep the repeated factors as part of the group to use this technique.</p>
<p>Consider <span class="math">\(\int \frac{x + 1}{(x + 2)^2 (x + 3)}\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\frac{x + 1}{(x + 2)^2 (x + 3)} = \frac{A}{(x + 2)^2 (x + 3)} + \frac{B}{(x + 2) (x + 3)} + \frac{C}{(x + 2)^2}\)</span> ;wip</p>
</blockquote>
<p>For each factor <span class="math">\((ax + b)^n\)</span>, include <span class="math">\(n\)</span> terms in the form <span class="math">\(\frac{A_1}{(ax + b)} + \ldots + \frac{A_n}{(ax + b)^n}\)</span>.</p>
<p>What if the denominator is not factorable into linear factors of real numbers (factors contain irreducable quadratics)? For example, <span class="math">\(\frac{x}{x^2 + x + 1}\)</span>.</p>
<p>We want to avoid imaginary numbers when doing this. Therefore, each irreducable quadratic of the form <span class="math">\(x^2 + x + 1\)</span>, we get a term of the form <span class="math">\(\frac{A + Bx}{ax^2 + bx + c}\)</span>.</p>
<p>Consider <span class="math">\(\int \frac{5x + 1}{(x^2 + x + 1)(x - 2)} \dee x\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\int \frac{5x + 1}{(x^2 + x + 1)(x - 2)} \dee x = \int \frac{A + Bx}{x^2 + x + 1} \dee x + \int \frac{C}{x - 2} \dee x\)</span>.<br />So <span class="math">\(\int \frac{5x + 1}{(x^2 + x + 1)(x - 2)} \dee x = \int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x + \int \frac{\frac{11}{7}}{x - 2} \dee x\)</span>.<br />So <span class="math">\(\int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x + \int \frac{\frac{11}{7}}{x - 2} \dee x = \int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x + \frac{11}{7} \ln (x - 2)\)</span>.<br />How do we integrate the first term? We can use a trigonometric substitution to solve this.<br />Clearly, <span class="math">\(\frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} = \frac{\frac{2}{7} - \frac{11}{7}x}{(x^2 + x + \frac{1}{4}) + 1 - \frac{1}{4}} = \frac{\frac{2}{7} + \frac{11}{7}x}{(x + \frac{1}{2})^2 + \frac{3}{4}}\)</span>, by completing the square.<br />Let <span class="math">\(u = x + \frac{1}{2}\)</span>. Then <span class="math">\(\dee x = \dee u\)</span>.<br />Clearly, <span class="math">\(\int \frac{\frac{2}{7} - \frac{11}{7}x}{x^2 + x + 1} \dee x = \frac{1}{7} \int \frac{2 - 11x}{(x + \frac{1}{2})^2 + \frac{3}{4}} \dee x = \frac{1}{7} \int \frac{-11u + \frac{15}{2}}{u^2 + \frac{3}{4}} \dee x\)</span>.<br />Let <span class="math">\(u = \frac{\sqrt{3}}{2} \tan \theta\)</span>. Then <span class="math">\(\frac{1}{7} \int \frac{-11u + \frac{15}{2}}{u^2 + \frac{3}{4}} \dee x = \frac{1}{7} \int \frac{-11\frac{\sqrt{3}}{2}\tan \theta + \frac{15}{2}}{\frac{3}{4}(\tan^2 \theta + 1)} \dee x = \frac{1}{7} \int \frac{-11\frac{\sqrt{3}}{2}\tan \theta + \frac{15}{2}}{\frac{3}{4\cos^2 \theta}} \dee x = \frac{1}{21} \int 4\cos^2 \theta (-11\frac{\sqrt{3}}{2}\tan \theta + \frac{15}{2}) \dee x = \frac{1}{21} \int 4\cos^2 \theta (-11\frac{\sqrt{3}}{2}\tan \theta) \dee x + \frac{4}{21}\frac{15}{2} \int \cos^2 \theta \dee x ;wip: use substitution with \)</span>s =  $</p>
</blockquote>
<p>Completing the square: we want the resulting polynomial to have repeated roots. In the quadratic formula, this is when the discriminant <span class="math">\(b^2 - 4ac = 0\)</span>, so <span class="math">\(c = \frac{b^2}{4a}\)</span>.</p>
<p>When we have an irreducible quadratic, we always get an <span class="math">\(\arctan\)</span> and a <span class="math">\(\ln \abs{ax^2 + bx + c}\)</span>. ;wip: do we always need the arctan? maybe we can subsitutute back to get a knarly expression with sqrt</p>
<h1 id="section-6">20/1/14</h1>
<p>The techniques of integration so far can be summarized as follows:</p>
<ol style="list-style-type: decimal">
<li>Expression in the numerator of the integrand would be simplified by the derivative of a substitution: use integration by subsitution.</li>
<li>Integrand is a product, integrand would be simplified by differentiating one and integrating another: use integration by parts.</li>
<li>There is a sum of difference of squares (<span class="math">\(\pm a^2 \pm x^2\)</span>): use trigonometric substitution.</li>
<li>Integrand contains a rational function (quotient of polynomials): use partial fraction decomposition.</li>
</ol>
<p>;wip: do some textbook questions for once</p>
<p>The two other common methods of integration are infinite series expansion and another that uses complex numbers.</p>
<h2 id="volumes-of-solids">Volumes of Solids</h2>
<p>Recall that a single-variable integral can be geometrically interpreted as the area underneath the curve.</p>
<p>In the Riemann integral, that would be represented as <span class="math">\(\int_a^b f(x) \dee x = \lim_{n \to \infty} \sum_{i = 1}^n \Delta x_i f(x_i)\)</span>. Here, <span class="math">\(\Delta x_i\)</span> is the base, and <span class="math">\(f(x_i)\)</span> is the height, and they form a rectangle.</p>
<p>The same idea can be applied to 3D, for the volume under a surface. We want to find the area under <span class="math">\(f(x, y)\)</span>.</p>
<p>In the Riemann integral, that would be represented as <span class="math">\(\iint f(x, y) \dee x \dee y = \lim_{n \to \infty} \sum_{i = 1}^n \sum_{j = 1}^n \Delta x_i \Delta y_i f(x_i, y_i)\)</span>. Here, <span class="math">\(\Delta x_i \Delta y_i\)</span> is the base, and <span class="math">\(f(x_i, y_i)\)</span>, and they form a rectangle.</p>
<p>In general, the volume of an arbitrary solid requires a multi-variable/multi-dimensional integral (a calculus III topic). However, there are cases where symmetry allows us to use a single variable integral.</p>
<p>Main axes:</p>
<pre><code>   y
   |
   |
   |_____ x
  /
 /
z</code></pre>
<p>Find the volume of a square prism with dimensions <span class="math">\(b \times b \times h\)</span>:</p>
<blockquote>
<p>The area of the base slice stays the same as we go along the z-axis - as we vary <span class="math">\(h\)</span>, the slice is still <span class="math">\(b \times b\)</span>.<br />So the volume is <span class="math">\(\int_0^h b^2 \dee x = b^2 \int_0^h 1 \dee x = b^2 h\)</span>.</p>
</blockquote>
<p>The basic idea is that we take the solid, slice the shape along one axis, then integrate the area as a function of the extent along the axis that we sliced along. This works because of the symmetry of some shapes that allows us to avoid considering some dimensions.</p>
<p><span class="math">\(V = \int_a^b A(x) \dee x\)</span>, where <span class="math">\(V\)</span> is the volume, <span class="math">\(A(x)\)</span> is the area of a slice at extent <span class="math">\(x\)</span> (though other axes can be used too depending on the problem), and <span class="math">\(\dee x\)</span> is the width of the slice.</p>
<p>Find the area of the cone with base radius 1 unit and height 1 pointing along the x-axis:</p>
<blockquote>
<p>This is the same as the line <span class="math">\(y = 1 - x\)</span> rotated about the x-axis.<br />The area of any slice of the cone along the x-axis is <span class="math">\(A(x) = \pi (1 - x)^2\)</span>, because the slice is a circle.<br />The thickness of this slice is <span class="math">\(\dee x\)</span>, and the cone is defined from <span class="math">\(x = 0\)</span> to <span class="math">\(x = 1\)</span>.<br />So the volume of the cone is <span class="math">\(\int_0^1 \pi (1 - x)^2 \dee x = \pi \int_0^1 (1 - 2x + x^2) \dee x = \frac{\pi}{3}\)</span>.</p>
</blockquote>
<p>We can generalize this to any function rotated about a line. The resulting solids are called <strong>solids of rotation</strong>.</p>
<p>The reason this works is because the z-axis is basically redundant information that is already expressed in the y-axis.</p>
<p>Find the volume of the solid represented by rotating <span class="math">\(f(x)\)</span> about the x-axis:</p>
<blockquote>
<p>The area of each slice at each extent along the x-axis is the area of a circle with the radius <span class="math">\(f(x)\)</span>.<br />The area function is <span class="math">\(A(x) = \pi f(x)^2\)</span>.<br />So the volume is <span class="math">\(\int_a^b A(x) \dee x = \pi \int_a^b f(x)^2 \dee x\)</span>.</p>
</blockquote>
<h1 id="section-7">22/1/14</h1>
<p>The rotation method works whenever we can find the area function for a given slice along a certain axis.</p>
<p>Here, <span class="math">\(\Delta V = A(x) \Delta x\)</span>, and then we add up all these tiny volumes to get the total volume.</p>
<p>This method is called the <strong>method of disks</strong>, because we are integrating the volume of a lot of small disks along the axis of rotation.</p>
<p>There is another way to approximate the area and have it converge into an exact value. We can estimate the volume of solids of rotation by integrating the volume of a lot of nested cylinders lying along the axis of rotation - this is the <strong>method of shells</strong>.</p>
<p>Consider a hollow cylinder of thickness <span class="math">\(\dee x\)</span> with inner radius <span class="math">\(x\)</span> and height <span class="math">\(h(x)\)</span>. If we cut it and unroll it, then it becomes very close to a cuboid of dimensions <span class="math">\(2\pi x\)</span> by <span class="math">\(h(x)\)</span> by <span class="math">\(\dee x\)</span>. In other words, we assume the inner circumference is almost the same as the outer circumference, since <span class="math">\(\dee x\)</span> is so small.</p>
<p>So the enclosed volume of the cylinder is <span class="math">\(2\pi x h(x) \dee x\)</span>.</p>
<p>How do we use these shells to find the volume of a solid? If we look at the cross section of our shape, we can approximate the area of this cross section using rectangles that have a fixed width <span class="math">\(\dee x\)</span> perpendicular to the axis of rotation, and length <span class="math">\(h(x)\)</span> along the axis of rotation.</p>
<p>Then the volume of the solid is the sum of the volume of all the nested cylinders: <span class="math">\(\int_a^b 2 \pi x h(x) \dee x\)</span>.</p>
<p>Consider a cone extending along the x-axis represented by the equation <span class="math">\(y = 1 - x\)</span> from 0 to 1 rotated about the x-axis:</p>
<blockquote>
<p>We want the height of the cylinder at each point along the y-axis, an axis perpendicular to the axis of rotation.<br />The height is <span class="math">\(x = 1 - y\)</span>. So the volume of the shell at any extent along the radius is <span class="math">\(2 \pi y(1 - y) \dee x\)</span>.<br />So the volume is <span class="math">\(\int_0^1 2 \pi y(1 - y) \dee y\)</span>. Note that we only integrate from the axis of rotation to the radius, not the diameter, because the cylinders go around over to the other side.<br />So the volume is <span class="math">\(\frac{\pi}{3}\)</span>.</p>
</blockquote>
<p>Finding the height of the shell is not always the same as finding the inverse. Consider the bowl-like shape formed by rotating <span class="math">\(y = \sqrt{x}\)</span> from 0 to 0 about the y-axis:</p>
<blockquote>
<p>We want the height of the bowl at each point along the x-axis, an axis perpendicular to the axis of rotation.<br />The height is <span class="math">\(y = 1 - x^2\)</span>, since the height of each cylinder is decreasing as we move outwards.<br />So the volume is <span class="math">\(\int_0^1 2 \pi x(1 - x^2) \dee x = \frac{\pi}{2}\)</span>.</p>
</blockquote>
<p>Note that this is the same as if we used <span class="math">\(x = y^2\)</span> (the inverse of the function). There are two possibilities for the cylinder height: either the inverse of the function, if the shape gets thinner as we move along the axis of rotation, or the maximum height minus the inverse, if the shape gets thicker as we move along the axis of rotation. Here, since the <span class="math">\(\sqrt{x}\)</span> shape gets thicker, we used <span class="math">\(1 - x^2\)</span>.</p>
<p>The method of shells works best when we know the height from the axis perpendicular to the axis of rotation, and the method of disks works when we can find the area of each slice along the axis of rotation.</p>
<h1 id="section-8">24/1/14</h1>
<p>The method of shells and the method of disks both have cases where they work better than the other. The method of disks works best for functions that extend parallel to the axis of rotation, while the method of shells, for functions that extend perpendicular to the axis of rotation.</p>
<p>The method of disks uses the formula <span class="math">\(\int_a^b A(x) \dee x\)</span>, where <span class="math">\(a, b\)</span> are the extents along the axis of rotation.</p>
<p>The method of shells uses the formula <span class="math">\(\int_a^b h(x) 2\pi x \dee x\)</span>, where <span class="math">\(a, b\)</span> are the extents perpendicular to the axis of rotation.</p>
<p>Consider <span class="math">\(y = 2x^2 - x^3 = x^2(2 - x)\)</span> from 0 to 2 rotated about the y-axis:</p>
<blockquote>
<p>This solid looks like the top half of a donut.<br />The method of disks is difficult to use here, because we would need disks with holes in them. We will use the method of shells.<br />The height of each of our cylinders is <span class="math">\(h(x) = 2x^2 - x^3\)</span>.<br />The volume of each shell is <span class="math">\(\Delta V = h(x) 2\pi x \dee x = 4\pi x^3 \dee x - 2\pi x^4 \dee x\)</span>.<br />So the volume of the solid is <span class="math">\(4\pi \int_0^2 x^3 \dee x - 2\pi \int_0^2 x^4 \dee x = 4\pi \evalat{\frac{x^4}{4}}_0^2 - 2\pi \evalat{\frac{x^5}{5}}_0^2 = 4\pi \frac{2^4}{4} - 2\pi \frac{2^5}{5} = \frac{16\pi}{5}\)</span>.</p>
</blockquote>
<p>A variation on the method is disks is the <strong>method of washers</strong>. Here, we have disks with holes in them for whatever reason, and our area, rather than simply being the area of a circle, is the area of the circle minus the area of the hole in the middle. Make sure to use <span class="math">\(\pi \int (r_o^2 - r_i^2) \dee x\)</span> rather than <span class="math">\(\pi \int (r_o - r_i)^2 \dee x\)</span>, where <span class="math">\(r_o\)</span> is the outer radius and <span class="math">\(r_i\)</span> is the inner radius.</p>
<p>For example, what is the volume enclosed by rotating the area between <span class="math">\(y = \sqrt{x}\)</span> and <span class="math">\(y = x\)</span> about the x-axis? We could use the disk method, except instead of finding the area of a disk, we find the area of a disk with a hole in it, a washer. However, in this case it would be easier to do it with the method of shells.</p>
<h1 id="section-9">27/1/14</h1>
<h2 id="improper-integrals">Improper Integrals</h2>
<p>An integral is improper if some part of it goes to <span class="math">\(\pm \infty\)</span> - either the integrand or the domain of integration (limits of integration).</p>
<p>The way we deal with this is to take limits of the infinite values instead of using these infinite values.</p>
<p>Improper integrals work when the domain is infinite (<span class="math">\(\int_0^\infty f(x) \dee x\)</span>), when the integrand is infinite at one of the endpoints (<span class="math">\(\int_0^1 \frac{1}{x}\)</span>), or when the integrand is infinite within the domain (<span class="math">\(\int_{-1}^1 \frac{1}{x} \dee x\)</span>)</p>
<p>For example, <span class="math">\(\int_a^\infty f(x) \dee x = \lim_{T \to \infty} \int_a^T f(x) \dee x\)</span>.</p>
<p>For example, <span class="math">\(\int_0^\infty e^{-x} \dee x = \lim_{T \to \infty} \int_0^T e^{-x} \dee x = \lim_{T \to \infty} \evalat{-e^{-x}}_0^T = \lim_{T \to \infty} (-e^{-T}) - (-e^{-0}) = 0 + 1 = 1\)</span>.</p>
<p>Prove that the volume obtained by rotating <span class="math">\(y = \frac{1}{x}\)</span> about the x-axis for <span class="math">\(x \in [1, \infty)\)</span> is finite:</p>
<blockquote>
<p>The volume is <span class="math">\(\int_1^\infty \pi \frac{1}{x^2} \dee x = \pi \lim_{T \to \infty} \evalat{-\frac{1}{x}}_1^T = \pi\)</span>, found via the method of disks. Clearly, the volume is finite.</p>
</blockquote>
<p>Sometimes, the integrand itself will diverge. Consider <span class="math">\(\int_0^1 \ln x \dee x\)</span>:</p>
<blockquote>
<p><span class="math">\(\ln 0 = -\infty\)</span>, and we cannot evaluate the antiderivative at this point.<br />Instead, we write it as <span class="math">\(\lim_{\epsilon \to 0} \int_\epsilon^1 \ln x \dee x = \lim_{\epsilon \to 0} \evalat{x \ln x - x}_\epsilon^1 = 0 - 1 - (\lim_{\epsilon \to 0} \epsilon \ln \epsilon - \lim_{\epsilon \to 0} \epsilon) = 0 - 1 - (0 - 0) = -1\)</span>.</p>
</blockquote>
<p>Also, the integrand might diverge somewhere within the domain of integration. This is not always immediately obvious and must always be considered when doing integrals.</p>
<p>Consider <span class="math">\(\int_{-1}^1 \frac{1}{\sqrt{\abs{x}}} \dee x\)</span>:</p>
<blockquote>
<p>There is a vertical asymptote at <span class="math">\(x = 0\)</span>. This makes it so that we can't directly use the fundemental theorem of calculus to evaluate the integral.<br />We can instead split the integral at the middle, and since it is an even function, we can combine the two integrals: <span class="math">\(2\int_0^1 \frac{1}{\sqrt{x}} \dee x\)</span>.<br />There is an asymptote, so the integral is an improper one: <span class="math">\(2\int_0^1 \frac{1}{\sqrt{x}} \dee x = 2 \lim_{T \to 0} \int_T^1 \frac{1}{\sqrt{x}} \dee x = 2 (2 \cdot 1^\frac{1}{2} - 2\lim_{T \to 0} T^\frac{1}{2}) = 4\)</span>.</p>
</blockquote>
<p>Consider <span class="math">\(\int_{-1}^1 \frac{1}{2\sqrt{x}} \dee x\)</span>: ;wip: what was the actual example here?</p>
<blockquote>
<p>We might do <span class="math">\(\int_{-1}^1 \frac{1}{2\sqrt{x}} \dee x = \evalat{-\sqrt{\abs{x}}}_{-1}^1 = -2\)</span>.<br />However, the integral <strong>does not exist</strong>. We need to be careful because the result looks just fine, and does not indicate that an error occurred.<br />The integral does not make any sense because the integrand diverges towards <span class="math">\(\infty\)</span> at <span class="math">\(x = 0\)</span>.</p>
</blockquote>
<p>The idea behind this is that we need to figure out if an improper integral exists even without integrating it first.</p>
<p>If a function <strong>converges</strong>, that means it goes to a finite value. The opposite is if it <strong>diverges</strong>, when it goes to <span class="math">\(\pm \infty\)</span> or does not exist.</p>
<p>In other words, convergence means the result is a number, and divergence means the result is not a number.</p>
<p>If an improper integral converges, then the value we get by evaluating its antiderivatives at the endpoints is the correct value of the integral. However, if it diverges, then the answer could be different. We always need to check for divergence in order to catch these cases.</p>
<h3 id="comparison-theorem">Comparison Theorem</h3>
<p>Given functions <span class="math">\(f(x), g(x)\)</span> such that <span class="math">\(f(x) \ge g(x) \ge 0\)</span> for <span class="math">\(x \ge a\)</span>, if <span class="math">\(\int_a^b f(x) \dee x\)</span> converges, then <span class="math">\(\int_a^b g(x) \dee x\)</span> also converges.</p>
<p>The contrapositive is also useful in that if <span class="math">\(\int_a^b g(x) \dee x\)</span> diverges, then <span class="math">\(\int_a^b f(x) \dee x\)</span> also diverges.</p>
<p>Prove that <span class="math">\(\int_1^\infty \frac{1}{x^P} \dee x\)</span> converges if and only if <span class="math">\(P &gt; 1\)</span></p>
<blockquote>
<p>Clearly, if <span class="math">\(P = 1\)</span>, <span class="math">\(\int_1^\infty \frac{1}{x^P} \dee x = \evalat{\ln x}_1^\infty\)</span>, which is <span class="math">\(\infty\)</span>, so the integral diverges.<br />Clearly, <span class="math">\(\int_1^\infty \frac{1}{x^P} \dee x = \evalat{\frac{x^{1 - P}}{1 - P}}_1^\infty = \frac{\infty^{1 - P}}{1 - P} - \frac{1}{1 - P}\)</span> if <span class="math">\(P \ne 1\)</span>.<br />Clearly, if <span class="math">\(P &lt; 1\)</span>, <span class="math">\(\infty^{1 - P} = \infty\)</span>, so the integral diverges.<br />Clearly, if <span class="math">\(P &gt; 1\)</span>, <span class="math">\(\infty^{1 - P} = 0\)</span>, so the integral converges.<br />So the integral converges to <span class="math">\(\frac{1}{P - 1}\)</span> for <span class="math">\(P &gt; 1\)</span>.</p>
</blockquote>
<p>Interestingly, <span class="math">\(e^{-x^2}\)</span> doesn't have an antiderivative. Figure out if <span class="math">\(\int_0^\infty e^{-x^2} \dee x\)</span> converges or diverges:</p>
<blockquote>
<p>Clearly, <span class="math">\(0 \le e^{-x^2} \le e^{-x}\)</span> for <span class="math">\(x \ge 1\)</span>.<br />Since <span class="math">\(\int_1^\infty e^{-x} \dee x\)</span> converges, <span class="math">\(\int_1^\infty e^{-x^2} \dee x\)</span> converges, by the comparison theorem.<br />Clearly, <span class="math">\(\int_0^\infty e^{-x^2} \dee x = \int_0^1 e^{-x^2} \dee x + \int_1^\infty e^{-x^2} \dee x\)</span>.<br />Clearly, <span class="math">\(e^{-x^2}\)</span> does not diverge for all <span class="math">\(x \in [0, 1]\)</span>. So <span class="math">\(\int_0^1 e^{-x^2} \dee x\)</span> converges.<br />Since <span class="math">\(\int_0^1 e^{-x^2} \dee x\)</span> and <span class="math">\(\int_1^\infty e^{-x^2} \dee x\)</span> converge, <span class="math">\(\int_0^\infty e^{-x^2} \dee x\)</span> converges.</p>
</blockquote>
<h1 id="section-10">29/1/14</h1>
<p>Consider <span class="math">\(\int_1^\infty \frac{1 + e^{-x}}{x} \dee x\)</span>:</p>
<blockquote>
<p>Clearly, the function is well behaved for all <span class="math">\(x \in [1, \infty]\)</span>.<br />So we do not need to worry about the integrand diverging.<br />Clearly, <span class="math">\(\frac{1 + e^{-x}}{x} \le \frac{2}{x}\)</span>.<br />Clearly, <span class="math">\(\frac{2}{x}\)</span> diverges.<br />However, we can't say anything about the original function using the comparison theorem, since it could still either converge or diverge.<br />Instead, we look for divergence. Clearly, <span class="math">\(\frac{1}{x} \le \frac{1 + e^{-x}}{x}\)</span>.<br />Since <span class="math">\(\int_1^\infty \frac{1}{x} \dee x\)</span> diverges, <span class="math">\(\int_1^\infty \frac{1 + e^{-x}}{x} \dee x\)</span> also diverges.</p>
</blockquote>
<h2 id="applications-of-integration">Applications of Integration</h2>
<p>Many physical phenomena can be represented by <strong>differential equations</strong> - equations that include derivatives.</p>
<p>This comes about usually through empirical evidence/oberservation, and some by conservation principles.</p>
<h3 id="cooling">Cooling</h3>
<p>For example, Newton's Law of Cooling was discovered by Newton's measurements of hot materials in cooler surroundings.</p>
<p>The law states that the change in temperature is linearly propertional to the temperature difference with the surroundings.</p>
<p>In other words, <span class="math">\(\frac{\dee}{\dee x} T_h = -k(T_h - T_r)\)</span>, where <span class="math">\(T_h\)</span> is the temperature of the hot thing, <span class="math">\(T_r\)</span> is the surrounding temperature, and <span class="math">\(k\)</span> is the cooling coefficient.</p>
<p>Note that <span class="math">\(k\)</span> is non-negative and we use <span class="math">\(-k\)</span> because hot things cool. This cooling coefficient is influenced by the material and shape of the object.</p>
<p>From this we can tell that the object stops cooling when <span class="math">\(T_h = T_r\)</span>, so <span class="math">\(\frac{\dee}{\dee x} T_h = 0\)</span>.</p>
<p>Values of <span class="math">\(T\)</span> for which <span class="math">\(\frac{\dee T_h}{\dee x} = 0\)</span> are called <strong>equilibria</strong>.</p>
<h3 id="conservation">Conservation</h3>
<p>Most differential equations in science and engineering come from <strong>conservation principles</strong> - principles that apply universally and constrain what can happen. For example, conservation of mass/energy/charge/momentum.</p>
<p>Conservation principles are easy to represent in mathematics, though the models can be pretty elaborate. Basically, what they state is that the rate of the change of something is the rate of change of something increasing minus the rate of stuff decreasing.</p>
<p>For example, the rate of change of people of the people in the room is the rate of change of people entering minus the rate of change of people leaving.</p>
<p>The rate of something increasing is called a <strong>source</strong>. The rate of something decreasing is called a <strong>sink</strong>.</p>
<p>For example, consider a skydiver immediately after their parachute opens:</p>
<blockquote>
<p>Clearly, <span class="math">\(m\frac{\dee \vec{v}}{\dee x} = \sum \vec{F} = m \vec{g} - \vec{F}_d\)</span>, where <span class="math">\(\vec{F}_d\)</span> is the drag force.<br />We can calculate the drag force in a lab independent of everything else, and not have to worry about the other things like the height or gravity.<br />Typically, <span class="math">\(\vec{F}_d = k\vec{v}\)</span> for some constant <span class="math">\(k\)</span>.<br />So <span class="math">\(\frac{\dee \vec{v}}{\dee x} = \vec{g} - \frac{k}{m} \vec{v}\)</span>.</p>
</blockquote>
<h1 id="section-11">31/1/14</h1>
<p>An example of a mathematical representation of conservation principles is a mixing problem.</p>
<p>A tank holds 80L of water at time <span class="math">\(t = 0\)</span>. A salt solution of 0.25 kg/L flows into the tank at 8L/min. Liquid drains at a rate of 12L/min from the tank. Find a differential equation for the mass of salt <span class="math">\(x(t)\)</span> in kg for <span class="math">\(t &gt; 0\)</span>, where <span class="math">\(t\)</span> is measures in seconds:</p>
<blockquote>
<p>We assume the salt solution instantly mixes with the water.<br />We want to find <span class="math">\(\frac{\dee}{\dee t} x(t)\)</span>, which is <span class="math">\(\text{source} - \text{sink}\)</span>.<br />The source is <span class="math">\(\text{salt concentration} \cdot \text{inflow rate} = 0.25 \text{kg/L} \cdot 8 \text{L/min} = 2 \text{kg/min}\)</span>.<br />Clearly, <span class="math">\(\frac{\dee}{\dee x} \text{liquid level} = \text{inflow rate} - \text{outflow rate} = 8 \text{L/min} - 12 \text{L/min} = -4 \text{L/min}\)</span>.<br />So the liquid level is <span class="math">\(80 + \int \frac{\dee}{\dee x} \text{liquid level} \dee t = 80 - 4t\)</span>.<br />Clearly, <span class="math">\(\text{salt concentration} = \frac{\text{mass of salt}}{\text{volume of tank}} = \frac{x(t)}{80 - 4t}\)</span>.<br />The sink is <span class="math">\(\text{salt concentration} \cdot \text{outflow rate} = \frac{x(t)}{80 - 4t} \cdot 12 \text{kg/L} = \frac{3x(t)}{20 - t}\)</span>.<br />So <span class="math">\(\frac{\dee}{\dee t} x(t) = 2 - \frac{3x(t)}{20 - t}\)</span>.<br />Note that the tank is empty when <span class="math">\(t = 20\)</span>, when the outflow rate is undefined.</p>
</blockquote>
<p>There are many things we can say about the function even without solving it. These are called <strong>qualitiative analyses</strong>.</p>
<p>Suppose we have <span class="math">\(\frac{\dee y}{\dee x} = f(x, y)\)</span>. Note that the left side is equal to the slope of the tangent line, and the right side is an expression for the slope of the tangent line for any point <span class="math">\((x, y)\)</span>.</p>
<p>Basically, every point on the Cartesian plane now has an associated slope, and we can represent this roughly with arrows on the graph representing the trend in the slopes.</p>
<p>These arrows/contours are called streamlines.</p>
<p>Think of this as a stream with currents and eddies. Every possible solution is a possible path a floating object will take if dropped at a particular place in the stream and allowed to bob along with the stream. The solutions are we get if we start at a possible point and draw a curve that has the slope of the tangent always equal to the value at the flow field at the point under the curve.</p>
<p>We can also think of them as a topographical map of some terrain. If we drop a ball along a point on the map, it will trace out a certain line. If we drop it slightly off to one side, it may take a different path, which could be similar, or completely different. The slope of the tangent represents the slope of the hill at a particular point.</p>
<p>The set of all possible solutions is therefore a family of functions that look like a map of water currents.</p>
<p>An <strong>equilibrium</strong> is a place where <span class="math">\(\frac{\dee y}{\dee x} = f(x) = 0\)</span>. Because the slope of the tangent is 0, it must be 0 for all <span class="math">\(x\)</span> values. There are <strong>stable</strong> and <strong>unstable</strong> equilibria.</p>
<p>Stable equilibria are those where values that are close to them get closer to them, like dropping a ball on the side of a valley and having it eventually roll to the bottom of the valley.</p>
<p>Unstable equilibria are those where values that are close to them get farther away from them, like dropping a ball at the peak of a mountain and having it roll away from the peak. Only values that are exactly on the unstable equilibrium will stay there.</p>
<p>Consider <span class="math">\(\frac{\dee y}{\dee x} = 1 - y^2\)</span>:</p>
<blockquote>
<p>The slope of the tangent line is <span class="math">\(\begin{cases} \text{negative} &amp;\text{if } y &lt; -1 \\ \text{positive} &amp;\text{if } -1 &lt; y &lt; 1 \\ \text{negative} &amp;\text{if } y &gt; 1 \end{cases}\)</span>.<br />We can visualize this as a flow field with three distinct sections.<br />Note that if we start at <span class="math">\(y = -1, 1\)</span>, we stay at that same value regardless of the value of <span class="math">\(x\)</span>. This is called an equilibrium, since the value isn't changing.<br />Note that if we start at any <span class="math">\(y &gt; -1\)</span>, <span class="math">\(y \to 1\)</span> as <span class="math">\(x \to \infty\)</span> (convergent), and if we start at any <span class="math">\(y &lt; -1\)</span>, <span class="math">\(y \to -\infty\)</span> as <span class="math">\(x \to \infty\)</span> (divergent).</p>
</blockquote>
<h1 id="section-12">3/2/14</h1>
<p>Differential equations of the form <span class="math">\(\frac{\dee y}{\dee x} = f(y)\)</span> are called autonomous differential equations. Note that they do not depend on the value of <span class="math">\(x\)</span>.</p>
<p>The equilibria of an autonomous differential equation are those <span class="math">\(y\)</span> values for which <span class="math">\(\frac{\dee y}{\dee x} = f(y) = 0\)</span>.</p>
<p>An equilibrium <span class="math">\(y = k\)</span> is stable if and only if <span class="math">\(f&#39;(k) &lt; 0\)</span> - if the change in the slope at the location is negative. Otherwise, it is unstable. This is because a negative value for the derivative means a negative feedback loop, which makes the function settle toward the equilibrium. ;wip: what? why? shouldn't the derivative be 0 at <span class="math">\(y = k\)</span>?</p>
<h2 id="solving-differential-equations">Solving Differential Equations</h2>
<h3 id="estimation">Estimation</h3>
<p>Consider <span class="math">\(\frac{\dee y}{\dee x} = y - x\)</span>, with <span class="math">\(y(0) = 2\)</span>.</p>
<p>This is a differential equation of the form <span class="math">\(\frac{\dee y}{\dee x} = f(x, y)\)</span></p>
<p>We can use the differential equation to estimate a certain solution, much like a Riemann sum.</p>
<p>First, we pick a starting point so we have a single solution to the differential equation, a member of the family of solutions. This is a curve on the Cartesian plane.</p>
<p>This starting point is called the <strong>initial condition</strong>. The initial condition often takes the form of <span class="math">\(y(x) = y(0) = 2\)</span> - the <span class="math">\(y\)</span>-value at <span class="math">\(x = 0\)</span> is 2 for this solution.</p>
<p>First, we break up the domain into pieces, by choosing value for <span class="math">\(x_1, \ldots, x_n\)</span>.</p>
<p>Then, we use <span class="math">\(\frac{\dee y}{\dee x} = f(x, y)\)</span> to estimate the slope of the tangent at any given <span class="math">\(x\)</span> value.</p>
<p>Then, we observe that <span class="math">\(\frac{\dee y}{\dee x} = f(x_{n - 1}, y_{n - 1}) \approx \frac{y_n - y_{n - 1}}{x_n - x_{n - 1}}\)</span> - the slope of the tangent is close to the slope of the secant.</p>
<p>So <span class="math">\(y_n(x) \approx y_{n - 1} + (x_n - x_{n - 1})f(x_{n - 1}, y_{n - 1})\)</span>. This is written in update form, so we can now use a table of values to calculate it.</p>
<p>Let <span class="math">\(\Delta x = x_n - x_{n - 1}\)</span>. Then <span class="math">\(y_n(x) \approx y_{n - 1} + f(x_{n - 1}, y_{n - 1}) \Delta x\)</span>.</p>
<p>We can also write this as <span class="math">\(y_{n + 1}(x) \approx y_n + f(x_n, y_n) \Delta x\)</span> where <span class="math">\(\Delta x = x_{n + 1} - x_n\)</span>.</p>
<p>Now we can write <span class="math">\(\frac{\dee y}{\dee x} = y - x\)</span> as <span class="math">\(y_n(x) \approx y_{n - 1} + (x_n - x_{n - 1})(x_{n - 1} - y_{n - 1})\)</span>.</p>
<p>We can actually approximate this function by using a table of values. Since <span class="math">\(y(0) = 2\)</span>, <span class="math">\(y_0 = 2\)</span>:</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math">\(n\)</span></th>
<th align="left"><span class="math">\(x_n\)</span></th>
<th align="left"><span class="math">\(y_n\)</span></th>
<th align="left"><span class="math">\(f(x_n, y_n) \Delta x\)</span></th>
<th align="left"><span class="math">\(y_{n + 1} \approx y_n + f(x_n, y_n) \delta x\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="left">0.0</td>
<td align="left">2</td>
<td align="left"><span class="math">\((2 - 0.0)0.1 = 0.20\)</span></td>
<td align="left"><span class="math">\(2.2 \approx 2 + 0.2\)</span></td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">0.1</td>
<td align="left">2.2</td>
<td align="left"><span class="math">\((2 - 0.1)0.2 = 0.38\)</span></td>
<td align="left"><span class="math">\(2.58 \approx 2.2 + 0.38\)</span></td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="left">0.2</td>
<td align="left">2.58</td>
<td align="left"><span class="math">\((2 - 0.2)0.3 = 0.54\)</span></td>
<td align="left"><span class="math">\(3.12 \approx 2.58 + 0.54\)</span></td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">0.3</td>
<td align="left">3.12</td>
<td align="left"><span class="math">\((2 - 0.3)0.4 = 0.68\)</span></td>
<td align="left"><span class="math">\(\ldots\)</span></td>
</tr>
</tbody>
</table>
<p>Now we can a table of values for the equation. We can plot this on a graph to approximate the curve.</p>
<p>The actual solution can also be found, though not through these techniques. The general solution is <span class="math">\(y = 1 + x + c^x, c \in \mb{R}\)</span>.</p>
<p>This is called <strong>Euler's method</strong>. It is a method for numerically solving differential equations.</p>
<h3 id="integration">Integration</h3>
<p>If we want exact solutions, we have to integrate. This is not always possible, but is in certain cases.</p>
<p><strong>Separable equations</strong> are one variety of them. They are equations of the form <span class="math">\(\frac{\dee y}{\dee x} = A(x) B(y)\)</span>.</p>
<p>Note that <span class="math">\(y\)</span> is also a function of <span class="math">\(x\)</span>, so <span class="math">\(B(y)\)</span> is another function of <span class="math">\(x\)</span>. We write <span class="math">\(y = y(x)\)</span>.</p>
<p>Clearly, <span class="math">\(\frac{\dee y}{\dee x} = A(x) B(y)\)</span> is the same as <span class="math">\(\frac{1}{B(y)} \frac{\dee y}{\dee x} = A(x)\)</span>.</p>
<p>If we integrate both sides, we get <span class="math">\(\int \frac{1}{B(y)} \frac{\dee y}{\dee x} \dee x = \int A(x) \dee x\)</span>.</p>
<p>Now we can &quot;cancel <span class="math">\(\dee x\)</span>&quot;. Let <span class="math">\(u = y(x)\)</span>. Then <span class="math">\(\dee u = \frac{\dee u}{\dee x} \dee x\)</span> and <span class="math">\(\dee x = \frac{1}{\frac{\dee u}{\dee x}} \dee u = \frac{1}{\frac{\dee y}{\dee x}} \dee u\)</span>. This is basically the definition of the substitution rule for integrals.</p>
<p>So <span class="math">\(\int \frac{1}{B(y)} \frac{\dee y}{\dee x} \dee x = \int \frac{1}{B(u)} \frac{\dee y}{\dee x} \frac{1}{\frac{\dee y}{\dee x}} \dee u = \int \frac{1}{B(u)} \dee u = \int \frac{1}{B(y)} \dee y\)</span>.</p>
<p>So <span class="math">\(\int \frac{1}{B(y)} \dee y = \int A(x) \dee x\)</span>.</p>
<p>We can also think of this as multiplying both sides of <span class="math">\(\frac{1}{B(y)} \frac{\dee y}{\dee x} = A(x)\)</span> by <span class="math">\(\dee x\)</span> and integrating both sides.</p>
<p>Solve <span class="math">\(\frac{\dee y}{\dee x} = \frac{x}{y}\)</span> for <span class="math">\(y(0) = -3\)</span>:</p>
<blockquote>
<p>Clearly, this is equivalent to <span class="math">\(y \frac{\dee y}{\dee x} = x\)</span>, or <span class="math">\(y \dee y = x \dee x\)</span>, or <span class="math">\(\int y \dee y = \int x \dee x\)</span>.<br />Integrating both sides, we get <span class="math">\(\frac{y^2}{2} = \frac{x^2}{2} + c\)</span>.<br />We want to find the value of <span class="math">\(c\)</span>. Since <span class="math">\(y(0) = -3\)</span>, <span class="math">\(\frac{(-3)^2}{2} = \frac{0^2}{2} + c\)</span> and <span class="math">\(c = \frac{9}{2}\)</span>.<br />So the solution is <span class="math">\(y^2 = 2x^2 + 2 \cdot \frac{9}{2} = 2x^2 + 9\)</span>.</p>
</blockquote>
<p>;wip: try <span class="math">\(\frac{\dee}{\dee x} 2^y \sin^2 x\)</span> and <span class="math">\(\sqrt{x \frac{\dee x}{\dee t}} = \frac{1}{1 + t}\)</span></p>
<h1 id="section-13">5/2/14</h1>
<p><strong>Constant solutions</strong> are another name for equilibria. They are simply where <span class="math">\(\frac{\dee y}{\dee x} = 0\)</span> for <span class="math">\(\frac{\dee y}{\dee x} = f(y)\)</span>.</p>
<p>Solve <span class="math">\(\sqrt{x \frac{\dee x}{\dee t}} = \frac{1}{1 + t}\)</span> for <span class="math">\(x(t) = x(0) = 0, t \ge 0\)</span>:</p>
<blockquote>
<p><span class="math">\[
\begin{align}
\sqrt{x \frac{\dee x}{\dee t}} &amp;= \frac{1}{1 + t} \\
x \frac{\dee x}{\dee t} &amp;= \frac{1}{(1 + t)^2} \\
x \dee x &amp;= \frac{1}{(1 + t)^2} \dee t \\
\int x \dee x &amp;= \int \frac{1}{(1 + t)^2} \dee t \\
\frac{x^2}{2} &amp;= -\frac{1}{1 + t} + c \\
t &amp;= 0; x(0) = 0 \\
\frac{0^2}{2} &amp;= -\frac{1}{1 + 0} + c \\
c &amp;= 1 \\
\frac{x^2}{2} &amp;= -\frac{1}{1 + t} + 1 \\
x &amp;= \sqrt{2 - \frac{2}{1 + t}} = \sqrt{\frac{2(1 + t) - 2}{1 + t}} = \sqrt{\frac{2t}{1 + t}} \\
\end{align}
\]</span></p>
</blockquote>
<p>First we rearrange until there is only one variable on each side, then we integrate, and finally, fix the constant of integration <span class="math">\(c\)</span> by solving for it with the given values for the axis variables.</p>
<p>Solve <span class="math">\(\frac{\dee T}{\dee t} = -k(T - T_{ambient})\)</span> - Newton's law of cooling:</p>
<blockquote>
<p><span class="math">\[
\begin{align}
\frac{\dee T}{\dee t} &amp;= -k(T - T_{ambient}) \\
\frac{1}{T - T_{ambient}} \dee T &amp;= -k \dee t \\
\int \frac{1}{T - T_{ambient}} \dee T &amp;= -k \int 1 \dee t \\
\ln \abs{T - T_{ambient}} &amp;= -kt + c \\
e^{\ln \abs{T - T_{ambient}}} &amp;= e^{-kt + c} \\
\abs{T - T_{ambient}} &amp;= e^{-kt}e^c \\
T - T_{ambient} &amp;= \pm e^ce^{-kt} \\
\end{align}
\]</span> Let <span class="math">\(A = \pm e^c\)</span>. Then <span class="math">\(T - T_{ambient} = Ae^{-kt}\)</span>.<br />Note that at <span class="math">\(t = 0\)</span>, <span class="math">\(T = T_0\)</span> for some fixed <span class="math">\(T_0\)</span>.<br />So <span class="math">\(T_0 - T_{ambient} = Ae^{-k0}\)</span> and <span class="math">\(T_0 - T_{ambient} = A\)</span>.<br />So <span class="math">\(T = T_{ambient} + (T_0 - T_{ambient})e^{-kt}\)</span>.</p>
</blockquote>
<p>Suppose we have a population of <span class="math">\(n\)</span> individuals. The simplest population model is <span class="math">\(\frac{\dee n}{\dee t} = kn\)</span> for some <span class="math">\(k \ge 0\)</span>. Solve for <span class="math">\(n\)</span>:</p>
<blockquote>
<p><span class="math">\[
\begin{align}
\frac{\dee n}{n} &amp;= k \dee t \\
\int \frac{\dee n}{n} &amp;= k \int \dee t \\
\ln \abs{n} &amp;= kt + c \\
n &amp;= \pm e^ce^{kt} \\
A = \pm e^c; n &amp;= Ae^{kt} \\
\end{align}
\]</span> Note that at <span class="math">\(t = 0\)</span>, <span class="math">\(n = n_0\)</span> for some constant <span class="math">\(n_0\)</span> - the starting population.<br />So <span class="math">\(n_0 = Ae^{k0}\)</span> and <span class="math">\(A = n_0\)</span>.<br />So <span class="math">\(n = n_0e^{kt}\)</span>.</p>
</blockquote>
<p>A simple variation on this population growth model is <strong>logistic growth</strong>, which also models resource exhaustion: <span class="math">\(\frac{\dee N}{\dee t} = rN\left(1 - \frac{N}{k}\right)\)</span>. Note that there are two equalibria - <span class="math">\(N = 0\)</span> and <span class="math">\(N = k\)</span>. <span class="math">\(k\)</span> is a constant called the <strong>carrying capacity</strong>.</p>
<p>For <span class="math">\(\frac{n}{k} \ll 1\)</span> (much less than), logistic growth behaves like exponential growth.</p>
<p>The flow field looks like arrows pointing right toward <span class="math">\(N(t) = k\)</span> starting from <span class="math">\(N(t) = 0\)</span>. Therefore, the population always tends toward <span class="math">\(k\)</span> in this model.</p>
<h1 id="section-14">7/2/14</h1>
<p>The main idea is that there is a lot more to the equations than just the solutions. The flow field is useful for discovering how the equation behaves.</p>
<p>Even when we solve the equation, it does not tell us much about how the function works intuitively.</p>
<p>Solve <span class="math">\(\frac{\dee N}{\dee t} = rN\left(1 - \frac{N}{k}\right)\)</span>:</p>
<blockquote>
<p><span class="math">\[
\begin{align}
\frac{\dee N}{\dee t} &amp;= rN\left(1 - \frac{N}{k}\right) \\
\int \frac{1}{N\left(1 - \frac{N}{k}\right)} \frac{\dee N}{\dee t} \dee t &amp;= \int r \dee t \\
\int \frac{1}{N\left(1 - \frac{N}{k}\right)} \dee N &amp;= rt + c \\
\int \frac{A}{N} + \frac{B}{1 - \frac{N}{k}} \dee N &amp;= rt + c \\
A\left(1 - \frac{N}{k}\right) + BN &amp;= 1; A = 1; B = \frac{1}{k} \\
\int \frac{1}{N} + \frac{\frac{1}{k}}{1 - \frac{N}{k}} \dee N &amp;= rt + c \\
\ln \abs{N} + \int \frac{1}{k - N} \dee N &amp;= rt + c \\
\ln \abs{N} - \ln \abs{N - k} &amp;= rt + c \\
\ln \abs{\frac{N}{N - k}} &amp;= rt + c \\
-\ln \abs{\frac{N}{N - k}} &amp;= -rt - c \\
\ln \abs{\frac{N - k}{N}} &amp;= -rt - c \\
\abs{\frac{N - k}{N}} &amp;= e^{-rt - c} \\
\frac{N - k}{N} &amp;= \pm e^{-rt} e^{-c} \\
F &amp;= \pm e^{-c} \\
1 - \frac{k}{N} &amp;= Fe^{-rt} \\
\frac{k}{N} &amp;= Fe^{-rt} + 1 \\
N &amp;= \frac{k}{1 + Fe^{-rt}} \\
\end{align}
\]</span> Note that all solutions tend toward <span class="math">\(k\)</span>, which we can verify by taking the limit of <span class="math">\(N\)</span> at infinity.<br />Now we will solve for <span class="math">\(F\)</span> - at <span class="math">\(t = 0\)</span>, <span class="math">\(N = N_0\)</span>. Assume <span class="math">\(t = 0\)</span>.<br />So <span class="math">\(N_0 = \frac{k}{1 + Fe^{-r0}}\)</span> and <span class="math">\(N_0 + FN_0 = k\)</span>, so <span class="math">\(F = \frac{k}{N_0} - 1\)</span>.<br />So <span class="math">\(N = \frac{k}{1 + \left(\frac{k}{N_0} - 1\right)e^{-rt}}\)</span>.</p>
</blockquote>
<h1 id="section-15">10/2/14</h1>
<p>Differential equations appear quite often in equations for time based physical phenomena.</p>
<p>Separable differential equations are one type of differential equation that can be directly solved. However, there are other types.</p>
<h2 id="linear-differential-equations">Linear Differential Equations</h2>
<p><strong>Linear differential equations</strong> are those of the form <span class="math">\(\frac{\dee y}{\dee x} = A(x) y + B(x), A(x) \ne B(x)\)</span>. It is called linear because the degree of <span class="math">\(y\)</span> on the right side is 1.</p>
<p>If <span class="math">\(A(x) = B(x)\)</span>, then the equation is separable since <span class="math">\(A(x)y + B(x) = (y + 1)A(x)\)</span>, so it would be simpler to solve it that way, but the following technique would also work.</p>
<p>We can solve these by splitting the equation into two separable equations and then solving each of those. This technique is developed by Euler.</p>
<p>Note that if we multiply the equation by an arbitrary function <span class="math">\(I(x)\)</span>, we get <span class="math">\(I(x) \frac{\dee y}{\dee x} = I(x) A(x) y + I(x) B(x)\)</span>.</p>
<h3 id="first-equation">First equation</h3>
<p>So <span class="math">\(I(x) \frac{\dee y}{\dee x} - I(x) A(x) y = I(x) B(x)\)</span>.</p>
<p>Assume <span class="math">\(I(x)\)</span> is a function that satisfies <span class="math">\(\frac{\dee}{\dee x} (I(x) y) = I(x) B(x)\)</span> or <span class="math">\(I(x) y = \int I(x) B(x) \dee x\)</span>.</p>
<p>So <span class="math">\(y = \frac{1}{I(x)} \left(\int I(x) B(x) \dee x\right)\)</span>.</p>
<p>Clearly, <span class="math">\(\frac{\dee}{\dee x} I(x) y = y \frac{\dee}{\dee x} I(x) + I(x) \frac{\dee y}{\dee x} = I(x) B(x) = I(x) \frac{\dee y}{\dee x} - I(x) A(x) y\)</span></p>
<p>So <span class="math">\(y \frac{\dee}{\dee x} I(x) + I(x) \frac{\dee y}{\dee x} = I(x) \frac{\dee y}{\dee x} - I(x) A(x) y\)</span> and <span class="math">\(y \frac{\dee}{\dee x} I(x) = -I(x) A(x) y\)</span>.</p>
<h3 id="second-equation">Second equation</h3>
<p>So <span class="math">\(\frac{\dee}{\dee x} I(x) = -I(x) A(x)\)</span>. This is a separable differential equation.</p>
<p>Solving, we get <span class="math">\(\int \frac{1}{I(x)} \dee I(x) = -\int A(x) \dee x\)</span>.</p>
<p>Clearly, <span class="math">\(\int \frac{1}{I(x)} \dee I(x) = \ln \abs{I(x)}\)</span> so <span class="math">\(\abs{I(x)} = e^{-\int A(x) \dee x}\)</span> and <span class="math">\(I(x) = \pm e^{-\int A(x) \dee x}\)</span>.</p>
<p>Here, <span class="math">\(I(x)\)</span> is called the <strong>integrating factor</strong>. In general, <span class="math">\(I(x) = \pm e^{-\int A(x) \dee x}\)</span>.</p>
<h3 id="substitution">Substitution</h3>
<p>Now we substitute back into the original equation: <span class="math">\(y = \frac{1}{I(x)} \int I(x) B(x) \dee x = \frac{1}{\pm e^{-\int A(x) \dee x}} \int (\pm e^{-\int A(x) \dee x} B(x)) \dee x = \frac{1}{e^{-\int A(x) \dee x}} \int e^{-\int A(x) \dee x} B(x) \dee x\)</span>.</p>
<p>The <strong>general rule</strong> is that given <span class="math">\(\frac{\dee y}{\dee x} = A(x) y + B(x)\)</span>, <span class="math">\(y = \frac{1}{I(x)} \int I(x) B(x) \dee x\)</span> where <span class="math">\(I(x) = e^{-\int A(x) \dee x}\)</span>.</p>
<p>Consider the velocity of a falling object, <span class="math">\(\frac{\dee v}{\dee t} = g - \beta v\)</span>, where <span class="math">\(g\)</span> is gravitational acceleration and <span class="math">\(\beta\)</span> is the drag coefficient:</p>
<blockquote>
<p>Clearly, this is an equation of the form <span class="math">\(\frac{\dee v}{\dee t} = A(t) v + B(t)\)</span> where <span class="math">\(A(t) = -\beta\)</span> and <span class="math">\(B(x) = g\)</span>.<br />So <span class="math">\(I(x) = e^{-\int (-\beta) \dee t} = e^{\beta t}\)</span>.<br />So <span class="math">\(v = \frac{1}{e^{\beta t}} \int e^{\beta t} g \dee x = \frac{1}{e^{\beta t}} \left(\frac{g}{\beta} e^{\beta t} + c\right)\)</span>.<br />So <span class="math">\(v = \frac{1}{e^{\beta t}} \left(\frac{g}{\beta} e^{\beta t} + c\right) = \frac{g}{\beta} + ce^{-\beta t}\)</span>.<br />Now we need to find <span class="math">\(c\)</span>. Since <span class="math">\(v(t) = v(0) = v_0 = \frac{g}{\beta} + ce^{-\beta 0}\)</span>, <span class="math">\(c = v_0 - \frac{g}{\beta}\)</span>.<br />So <span class="math">\(v = \frac{g}{\beta} + \left(v_0 - \frac{g}{\beta}\right)e^{-\beta t}\)</span>.<br />We can check our answer by substituting <span class="math">\(v\)</span> back into the original equation: <span class="math">\(\frac{\dee}{\dee t} \left(\frac{g}{\beta} + \left(v_0 - \frac{g}{\beta}\right)e^{-\beta t}\right) = g - \beta \left(\frac{g}{\beta} + \left(v_0 - \frac{g}{\beta}\right)e^{-\beta t}\right) = g - \left(g + (\beta v_0 - g)e^{-\beta t}\right) = (g - \beta v_0)e^{-\beta t}\)</span>, which is correct.</p>
</blockquote>
<p>Consider <span class="math">\(x^2 \frac{\dee y}{\dee x} + xy = 1\)</span> for <span class="math">\(y(x) = y(1) = 2, x &gt; 0\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(x^2 \frac{\dee y}{\dee x} + xy = 1\)</span> is equivalent to <span class="math">\(\frac{\dee y}{\dee x} + \frac{1}{x}y = \frac{1}{x^2}\)</span> or <span class="math">\(\frac{\dee y}{\dee x} = -\frac{1}{x}y + \frac{1}{x^2}\)</span>.<br />So <span class="math">\(I(x) = e^{-\int \left(-\frac{1}{x}\right) \dee x} = e^{\ln x} = x\)</span>.<br />So <span class="math">\(y = \frac{1}{x} \int x \frac{1}{x^2} \dee x = \frac{\ln x + c}{x}\)</span>.<br />Since <span class="math">\(y(x) = y(1) = 2\)</span>, <span class="math">\(2 = \frac{\ln 1 + c}{1}\)</span> and <span class="math">\(c = 2\)</span>.<br />So <span class="math">\(y = \frac{\ln x + 2}{x}\)</span>.</p>
</blockquote>
<h1 id="section-16">12/2/14</h1>
<p>Often when solving differential equations, it is not possible to get an explicit solution (where the variable is isolated on one side). Instead, it is often only possible to get an implicit solution, like <span class="math">\(2\ln y + y^2 = x\)</span>.</p>
<p>Midterm Review:</p>
<ul>
<li>Techniques of Integration
<ul>
<li>Review</li>
<li>Integration by Substitution</li>
<li>Integration by Parts</li>
<li>Trigonometric Substitution</li>
<li>Partial Fraction Decomposition</li>
</ul></li>
<li>Applications
<ul>
<li>Volumes of Solids
<ul>
<li>Method of Shells</li>
<li>Method of Disks</li>
</ul></li>
<li>Improper Integrals</li>
<li>Differential Equations
<ul>
<li>Qualitative Analysis</li>
<li>Separable Differential Equations</li>
<li>Linear Differential Equations
<ul>
<li>Integrating Factors</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="sequences-series-taylor-polynomials">Sequences, Series, Taylor Polynomials</h2>
<p>Given a function <span class="math">\(f(x)\)</span>, we can often find a polynomial <span class="math">\(P(x)\)</span> that has the same first <span class="math">\(N\)</span> derivatives at a point <span class="math">\(x = a\)</span>.</p>
<p>For example, <span class="math">\(f(x) = \sin x\)</span> and <span class="math">\(P(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!}\)</span> have the same first 7 derivatives at <span class="math">\(x = 0\)</span>. In other words, <span class="math">\(\frac{\dee^i f}{\dee x^i} = \frac{\dee^i P}{\dee x^i}\)</span> for <span class="math">\(1 \le i \le 7\)</span> at <span class="math">\(x = 0\)</span>.</p>
<p>Another example is <span class="math">\(f(x) = \frac{1}{1 - x}\)</span> and <span class="math">\(P(x) = 1 + x + x^2 + x^3 + \ldots + x^N\)</span>. The first <span class="math">\(N\)</span> derivates at <span class="math">\(x = 0\)</span> are always equal, and it works for any arbitrary <span class="math">\(N\)</span>.</p>
<p>In general, if <span class="math">\(P(x) = \sum_{n = 0}^N \frac{f^{(n)}(a)}{n!}(x - a)^n\)</span>, then <span class="math">\(f(x)\)</span> and <span class="math">\(P(x)\)</span> share the first <span class="math">\(N\)</span> derivative values at <span class="math">\(x = a\)</span>. The notation <span class="math">\(f^{(n)}(a)\)</span> represents <span class="math">\(\evalat{\frac{\dee^n}{\dee x^n} f(x)}_{x = a}\)</span>.</p>
<p>The most important use of this is approximation of very difficult functions. This allows us to use polynomials as tools to analyze many types of functions.</p>
<p>What kinds of functions does this work for?</p>
<p>In the limit <span class="math">\(N \to \infty\)</span>, does <span class="math">\(f(x) = P(x) = \lim_{N \to \infty} \sum_{n = 0}^N \frac{f^{(n)}(a)}{n!}(x - a)^n\)</span> for all <span class="math">\(x\)</span>? Does the limit even exist?</p>
<h2 id="sequences">Sequences</h2>
<p>A <strong>sequence</strong> is an ordered list of numbers. We denote it with <span class="math">\(a_0, a_1, \ldots, a_n\)</span>, or simply <span class="math">\(a_n = f(n)\)</span>. For example, <span class="math">\(a_n = 2n\)</span> is equivalent to <span class="math">\(0, 2, 4, 6, \ldots\)</span></p>
<p>A sequence <strong>converges</strong> if it has a limit as <span class="math">\(n \to \infty\)</span>.</p>
<p>Sequences are often easier to work with than functions. For example, the <span class="math">\(\epsilon-\delta\)</span> definition of limits is much simpler.</p>
<p>The definition of the limit of a sequence is: a sequence <span class="math">\(a_n\)</span> has a limit <span class="math">\(L\)</span> if and only if for any <span class="math">\(\epsilon &gt; 0\)</span>, we can find <span class="math">\(k \in \mb{Z}\)</span> such that <span class="math">\(\abs{a_n - L} &lt; \epsilon\)</span> whenever <span class="math">\(n &gt; k\)</span>.</p>
<p>Formally, the limit <span class="math">\(L\)</span> exists if and only if <span class="math">\(\forall \epsilon &gt; 0, \exists k \in \mb{Z}, n &gt; k \implies \abs{a_n - L} &lt; \epsilon\)</span>.</p>
<p>This is similar to the definition of limits at infinity. For example, the sequence <span class="math">\(0.3, 0.33, 0.333, 0.3333, \ldots\)</span> has the limit <span class="math">\(L = \frac{1}{3}\)</span>, but <span class="math">\(1, -1, 1, -1, \ldots\)</span> has no limit.</p>
<p>Use the definition of the limit to prove that the limit of <span class="math">\(a_n = \frac{n}{1 + n}\)</span> is 1:</p>
<blockquote>
<p>Let <span class="math">\(\epsilon \in \mb{R}\)</span>. Construct <span class="math">\(k = \frac{1}{\epsilon} - 1\)</span>.<br />Assume <span class="math">\(n &gt; k\)</span>. Then <span class="math">\(n &gt; \frac{1}{\epsilon} - 1\)</span> and <span class="math">\(\frac{1}{1 + n} &lt; \epsilon\)</span>, so <span class="math">\(\abs{\frac{n}{1 + n} - 1} &lt; \epsilon\)</span>.<br />So by definition, <span class="math">\(\lim_{n \to \infty} a_n = 1\)</span>.</p>
</blockquote>
<p>If <span class="math">\(a_n\)</span> and <span class="math">\(L\)</span> lie in the domain of a continuous function <span class="math">\(f\)</span> and <span class="math">\(a_n \to L\)</span> as <span class="math">\(n \to \infty\)</span>, then <span class="math">\(\lim_{n \to \infty} f(a_n) = f(L)\)</span>. In other words, the limit of a sequence is the same as the limit of its corresponding function at infinity.</p>
<p>Sequences are easy to deal with if they are explicit functions of the index <span class="math">\(n\)</span>, but a lot of sequences are defined recursively, like <span class="math">\(a_{n + 1} = a_n + \frac{1}{n!}, a_0 = 1\)</span>.</p>
<p>;wip: try <span class="math">\(a_n = 7^{\frac{1}{2} + \frac{1}{n}}\tan \frac{\pi n + 1}{4n}\)</span> limit at infinity - </p>
<h1 id="section-17">14/2/14</h1>
<p>It is in fact easy to determine if any sequence converges or diverges.</p>
<p>Sequences that are defined only in terms of the current index are easy to find the limit of. For example, <span class="math">\(a_n = \frac{n}{n + 1}\)</span> converges to 1 at infinity.</p>
<p>However, sequences defined recursively are not so straightforward. For example, <span class="math">\(a_{n + 1} = a_n + \frac{1}{n!}, a_0 = 1\)</span>. This is an <strong>implicitly defined sequence</strong>.</p>
<h3 id="monotone-convergence-theorem">Monotone Convergence Theorem</h3>
<p>If the terms of a sequence are <strong>bounded</strong>, and the sequence is <strong>monotone</strong>, then the sequence converges.</p>
<p>There are two possible cases:</p>
<ul>
<li>If the sequence has an upper bound <span class="math">\(a_n \le b\)</span> and is monotonially increasing, then it converges.</li>
<li>If the sequence has a lower bound <span class="math">\(a_n \ge b\)</span> and is monotonically decreasing, then it converges.</li>
</ul>
<p><strong>Boundedness</strong> means that every element in the sequence is between a lower and upper bound. Formally, a sequence <span class="math">\(a_n\)</span> is bounded if and only if <span class="math">\(\exists u, \exists v, \forall n, u \le a_n \le v\)</span>.</p>
<p>We often prove boundedness by comparing to a known sequence (like <span class="math">\(\frac{1}{n!} \le \frac{1}{2^{n - 1}}\)</span>) or by using induction.</p>
<p><strong>Monotonicity</strong> means that once we start going up, we never go down again, and once we start going down, we never go up again. Basically, <span class="math">\(a_0 \le a_1 \le a_2 \le \ldots\)</span>, or <span class="math">\(a_0 \ge a_1 \ge a_2 \ge \ldots\)</span>.</p>
<p>Formally, a sequence <span class="math">\(a_n\)</span> is monotone if and only if <span class="math">\((\forall u, \forall v, u &lt; v \implies a_u &lt; a_v) \vee (\forall u, \forall v, u &lt; v \implies a_u &gt; a_v)\)</span>.</p>
<p>Proof:</p>
<blockquote>
<p>It is intuitively obvious that if a value is always increasing, and cannot exceed a value, then it must converge to some value.<br />Without loss of generality, assume that <span class="math">\(a_n\)</span> is increasing and bounded by <span class="math">\(a_n \le b\)</span>.<br />Let <span class="math">\(p\)</span> be the smallest possible upper bound on <span class="math">\(a_n\)</span>.<br />As an aside, <span class="math">\(p\)</span> is the limit of the sequence - any number less than this is not an upper bound, and any number greater than this can be smaller while still being an upper bound.<br />Let <span class="math">\(\epsilon &gt; 0\)</span>.<br />Clearly, <span class="math">\(p - \epsilon &lt; p\)</span>, so <span class="math">\(\exists k, p - \epsilon &lt; a_k\)</span>, since any value less than the tight upper bound must be exceeded by some element in the sequence.<br />Assume <span class="math">\(n &gt; k\)</span>. Clearly, <span class="math">\(a_k \le a_n\)</span> (since the sequence is monotonically increasing).<br />Clearly, <span class="math">\(a_n \le p &lt; p + \epsilon\)</span>.<br />So <span class="math">\(p - \epsilon &lt; a_n &lt; p + \epsilon\)</span> and <span class="math">\(-\epsilon &lt; a_n - p &lt; \epsilon\)</span>.<br />So <span class="math">\(\abs{a_n - p} &lt; \epsilon\)</span>, and by the definition of the limit, <span class="math">\(p\)</span> is the limit and the sequence converges.</p>
</blockquote>
<p>Does <span class="math">\(a_0 = 1, a_{n + 1} = a_n + \frac{1}{n!}\)</span> converge?</p>
<blockquote>
<p>Clearly, <span class="math">\(\frac{1}{n!}\)</span> is always positive, so <span class="math">\(a_{n + 1} = a_n + \frac{1}{n!}\)</span> is monotonically increasing.<br />Clearly, <span class="math">\(n! \le 2^{n - 1}\)</span>, since <span class="math">\(1 \cdot \ldots \cdot k \le 2 \cdot \ldots \cdots 2 \text{ (} k - 1 \text{ times)}\)</span>.<br />So <span class="math">\(\frac{1}{n!} \le \frac{1}{2^{k - 1}}\)</span> and <span class="math">\(a_n \le 1 + 1 + \frac{1}{2} + \frac{1}{2^2} + \ldots + \frac{1}{2^{n - 1}}\)</span>.<br />Clearly, this is a monotonically increasing geometric progression, and so we can determine that <span class="math">\(1 + 1 + \frac{1}{2} + \frac{1}{2^2} + \ldots + \frac{1}{2^{n - 1}} = \frac{1 - \left(\frac{1}{2}\right)^n}{1 - \frac{1}{2}}\)</span>.<br />Clearly, <span class="math">\(\lim_{n \to \infty} \frac{1 - \left(\frac{1}{2}\right)^n}{1 - \frac{1}{2}} = \frac{1}{\frac{1}{2}} = 2\)</span>.<br />So <span class="math">\(a_n \le \frac{1}{2^{k - 1}} \le 2\)</span>, and by the convergence theorem, the sequence converges.<br />As an aside, it converges to <span class="math">\(e\)</span>.</p>
</blockquote>
<p>Does <span class="math">\(a_1 = 1, a_{n + 1} = \sqrt{3 + 2a_n}\)</span> converge?</p>
<blockquote>
<p>The first few elements of the sequence are <span class="math">\(1, 2.23606797749979, 2.73352079834772, 2.90981813807933, 2.96978724425819\)</span>.<br />Clearly, <span class="math">\(a_{n + 1} \ge a_n \iff \sqrt{3 + 2a_n} \ge a_n \iff a_n^2 - 2a_n - 3 \le 0\)</span>, or <span class="math">\(-1 \le a_n \le 3\)</span>.<br />So <span class="math">\(a_n\)</span> is monotonically increasing if <span class="math">\([-1, 3]\)</span>.<br />Assume <span class="math">\(a_n \le 3\)</span>. Then <span class="math">\(3 + 2a_n \le 9\)</span> and <span class="math">\(\sqrt{3 + 2a_n} \le 3\)</span>. So <span class="math">\(a_{n + 1} \le 3\)</span>.<br />So by induction, <span class="math">\(a_n\)</span> has an upper bound of 3.<br />So by the monotone convergence theorem, the sequence converges.<br />Also, note that if the limit exists, we can set <span class="math">\(n \to \infty\)</span> and so <span class="math">\(a_{n + 1} = a_n\)</span>.<br />So <span class="math">\(a_n^2 - 2a_n - 3 = 0\)</span> and <span class="math">\(a_n  = -1, 3\)</span>. -1 is a extraneous answer since the function is always positive, so <span class="math">\(\lim_{n \to \infty} a_n = 3\)</span>.</p>
</blockquote>
<h1 id="section-18">24/2/14</h1>
<p>The monotone convergence theorem only tells us whether the sequence converges, but not what the actual limit is.</p>
<p>We usually prove the monotonicity and boundedness of sequences by comparing them to sequences with known properties (like geometric series), or by using induction.</p>
<p>To use induction to prove monotonicity, we simply need to prove that <span class="math">\(a_{n + 1} \ge a_n\)</span> for any <span class="math">\(n\)</span>.</p>
<p>To use induction to prove boundedness, we first need to guess a <span class="math">\(k\)</span> that might be an upper or lower bound. Then, we verify that it works for the first element of the sequence, and then that <span class="math">\(a_n \le k \implies a_{n + 1} \le k\)</span>.</p>
<p>If we know that the limit exists, sometimes we can find the limit by setting <span class="math">\(n \to \infty\)</span>, which implies that <span class="math">\(a_{n + 1} = a_n\)</span> (since we are at the limit).</p>
<p>Then we can write <span class="math">\(a_{n + 1}\)</span> in terms of <span class="math">\(a_n\)</span>, and we get a function over <span class="math">\(a_n\)</span>, which we can often isolate and solve for, which gives us the limit <span class="math">\(L = a_n\)</span>. The previous example uses this technique.</p>
<p>This doesn't always work. For example, it work doesn't for <span class="math">\(a_0 = 1, a_{n + 1} = a_n + \frac{1}{n!}\)</span>. If we try to substitute it, we get <span class="math">\(a_n = a_n + \frac{1}{n!} = a_n + \frac{1}{\infty} = a_n\)</span>. This doesn't help us find the limit.</p>
<h2 id="series">Series</h2>
<p>A series is a sum of terms. We denote this as <span class="math">\(S_N = \sum_{n = 0}^N a_n, a_n \in \mb{R}\)</span>. Here, <span class="math">\(N \in \mb{Z}, N \ge 0\)</span>.</p>
<p>For now, <span class="math">\(a_n\)</span> is a constant, which can depend on <span class="math">\(n\)</span>. Eventually, we want to be able to build and analyze sequences of functions, which can depend on other variables like <span class="math">\(x\)</span>.</p>
<p>If <span class="math">\(N\)</span> is finite, then <span class="math">\(S_N\)</span> is known as a <strong>partial sum</strong>.</p>
<p>We analyze series by analyzing the sequence of the series values: <span class="math">\(\sum_{n = 0}^0 a_n, \sum_{n = 0}^1 a_n, \sum_{n = 0}^2 a_n, \ldots\)</span>.</p>
<p>So just as we take the limit of a sequence, we can take the limit of a series with <span class="math">\(\lim_{N \to \infty} \sum_{n = 0}^N a_n\)</span>. This is the relation between sequences and series.</p>
<p>A sequence <strong>converges</strong> if this limit exists. Otherwise, it <strong>diverges</strong>. A series converges if and only if the limit of its partial sum to infinity is a finite value.</p>
<p>For example, we previously saw the sequence <span class="math">\(a_0 = 1, a_{n + 1} = a_n + \frac{1}{n!}\)</span>, which is actually equivalent to the series <span class="math">\(S_N = \sum_{n = 0}^1 \frac{1}{n!}\)</span>. They are equivalent because <span class="math">\(a_n = S_N\)</span> when <span class="math">\(n = N\)</span>.</p>
<p>We also define <span class="math">\(\sum a_n = \sum_{n = k}^\infty a_n, k \in \mb{Z}\)</span> for convenience.</p>
<h1 id="section-19">26/2/14</h1>
<h3 id="geometric-series">Geometric Series</h3>
<p>The geometric series is <span class="math">\(S_N = \sum_{n = 0}^N x^n = 1 + x + x^2 + x^3 + \ldots + x^n\)</span>.</p>
<p>The geometric series is a rare example of a series that can be written in <strong>closed form</strong> - non-recursively and in a finite number of symbols. In other words, we can write the value of the partial sum of the series as a function of <span class="math">\(n\)</span>.</p>
<p>Which values of <span class="math">\(n\)</span> make the series converge?</p>
<p>First, we start with the identity of <span class="math">\(1 - x^{N + 1} = (1 - x)(1 + x + x^2 + x^3 + \ldots + x^N)\)</span>. This is true because <span class="math">\((1 - x)(1 + x + x^2 + x^3 + \ldots + x^N) = (1 + x + x^2 + x^3 + \ldots + x^N) - (x + x^2 + x^3 + \ldots + x^{N + 1}) = 1 + x - x + x^2 - x^2 + x^3 - x^3 + \ldots + x^N - x^N - x^{N + 1} = 1 - x^{N + 1}\)</span>.</p>
<p>So <span class="math">\(S_N = \sum_{n = 0}^N x^n = 1 + x + x^2 + x^3 + \ldots + x^N = \frac{1 - x^{N + 1}}{1 - x}\)</span>.</p>
<p>So the limit is <span class="math">\(\lim_{N \to \infty} \frac{1 - x^{N + 1}}{1 - x} = \frac{1}{1 - x} - \frac{x}{1 - x} \lim_{N \to \infty} x^N\)</span>.</p>
<p>If <span class="math">\(x = 1\)</span>, then <span class="math">\(\lim_{N \to \infty} \sum_{n = 0}^N 1^n = 1 + \ldots + 1 = \infty\)</span>, and the sequence diverges.</p>
<p>If <span class="math">\(x = -1\)</span>, then <span class="math">\(\lim_{N \to \infty} \sum_{n = 0}^N (-1)^n = 1 - 1 + 1 - 1 + \ldots + 1 - 1 = ?\)</span>. This sum either has the value 0 or 1, and oscillates infinitely as we go to infinity. Therefore, the sequence diverges.</p>
<p>Clearly, if <span class="math">\(x &gt; 1\)</span> or <span class="math">\(x &lt; -1\)</span>, the value goes to positive or negative infinity, and the sequence diverges.</p>
<p>Therefore, the geometric series converges only for <span class="math">\(-1 &lt; x &lt; 1\)</span> (<span class="math">\(\abs{x} &lt; 1\)</span>), since if this is the case, <span class="math">\(\lim_{N \to \infty} x^N = 0\)</span> and <span class="math">\(\lim_{N \to \infty} S_N = \frac{1}{1 - x}\)</span>.</p>
<p>Does <span class="math">\(\sum_{k = 1}^\infty 3^{2k}5^{1 - k}\)</span> converge?</p>
<blockquote>
<p>Clearly, <span class="math">\(\sum_{k = 1}^\infty 3^{2k}5^{1 - k} = \sum_{k = 1}^\infty 9^k5^{1 - k} = 5\sum_{k = 1}^\infty 9^k5^{-k} = 5\sum_{k = 1}^\infty \frac{9^k}{5^k} = 5\sum_{k = 1}^\infty \left(\frac{9}{5}\right)^k\)</span>.<br />Since <span class="math">\(\frac{9}{5} \ge 1\)</span>, the geometric sequence diverges as the limit of <span class="math">\(\left(\frac{9}{5}\right)^k\)</span> goes to infinity.</p>
</blockquote>
<p>Does <span class="math">\(3 - \frac{3}{2}x^2 + \frac{3}{4}x - \frac{3}{8}x^2\)</span> converge? ;wip: what was the original question again? this doesn't seem right</p>
<blockquote>
<p>Clearly, <span class="math">\(3 - \frac{3}{2}x^2 + \frac{3}{4}x - \frac{3}{8}x^2 = 3 \sum_{n = 0}^\infty \left(-\frac{x}{2}\right)^n\)</span>.<br />Clearly, in order to converge, <span class="math">\(-1 \le -\frac{x}{2} \le -1\)</span>, or <span class="math">\(-1 \le \frac{x}{2} \le 1\)</span>.<br />As an aside, it converges to <span class="math">\(\frac{3}{1 + \frac{x}{2}} = \frac{6}{2 + x}\)</span>.</p>
</blockquote>
<h1 id="section-20">28/2/14</h1>
<p>The value of the geometric series is <span class="math">\(S_N = \sum_{n = 0}^N x^n = 1 + x + x^2 + \ldots + x^N = \begin{cases} \frac{1 - x^N}{1 - x} &amp;\text{if } x \ne 1 \\ N + 1 &amp;\text{if } x = 1 \end{cases}\)</span></p>
<h3 id="convergence">Convergence</h3>
<p>One of the simplest tests for convergence is that if the terms of a series are not getting closer and closer to 0, the series can never converge. In other words, <span class="math">\(\lim_{n \to \infty} a_n = 0\)</span> is a requirement for convergence.</p>
<p>Formally, if <span class="math">\(\lim_{n \to \infty} \abs{a_n} \ne 0\)</span>, then the sequence does not converge.</p>
<p>This is known as the <strong>simple limit test</strong> for series.</p>
<p>Our convergence tests can decide whether a series converges or not, but do not provide information about what it converges to.</p>
<p>The sum of two convergent series is also convergent - <span class="math">\(\sum a_n + \sum b_n = \sum (a_n + b_n)\)</span> if <span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum b_n\)</span> are both convergent. However, the sum of two divergent series is not necessarily always divergent. For example, <span class="math">\(\sum_{n = 1}^\infty (-1)^n\)</span> and <span class="math">\(\sum_{n = 1}^\infty (-1)^{n + 1}\)</span> are both divergent, but <span class="math">\(\sum_{n = 1}^\infty {(-1)^n + (-1)^{n + 1}} = 0\)</span>.</p>
<h2 id="p-series">P-series</h2>
<p>A <strong>P-series</strong> is a series of the form <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^P}\)</span> where <span class="math">\(P \in \mb{R}\)</span>.</p>
<h3 id="convergence-1">Convergence</h3>
<p>We want to figure out which values of <span class="math">\(P\)</span> allow the series to converge.</p>
<p>Clearly, <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^P} = \sum_{n = 1}^\infty n^{-P}\)</span>.</p>
<p>Clearly, if <span class="math">\(P \le 0\)</span>, then <span class="math">\(\lim_{n \to \infty} n^{-P} \ne 0\)</span>. So by the simple limit test, the sequence does not converge.</p>
<p>If <span class="math">\(P &gt; 0\)</span>, then <span class="math">\(f(n) = \frac{1}{n^P}\)</span> is continuous, positive, and decreasing.</p>
<p>Clearly, <span class="math">\(\int_1^\infty \frac{1}{x^P} \dee x = \frac{1}{1 - P} \evalat{x^{1 - P}}_1^\infty\)</span> converges if and only if <span class="math">\(P &gt; 1\)</span>.</p>
<p>So by the integral test, <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^P}\)</span> converges if and only if <span class="math">\(P &gt; 1\)</span>.</p>
<p>So <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^P}\)</span> converges if and only if <span class="math">\(P &gt; 1\)</span>.</p>
<h3 id="considerations">Considerations</h3>
<p>The series <span class="math">\(\sum_1^\infty \frac{1}{n}\)</span> is called the <strong>harmonic series</strong>. It diverges (very slowly, like the logarithmic functions), and this can be proven since it is a special case of the P-series where <span class="math">\(P = 1\)</span>. This is a useful series because <span class="math">\(\lim_{n \to \infty} \frac{1}{n} = 0\)</span>, yet the series diverges, so this is an example of the simple convergence test not giving a conclusive result.</p>
<p>For example, a P-series where <span class="math">\(P = 2\)</span> is <span class="math">\(\frac{\pi^2}{6}\)</span>. ;wip: how?</p>
<p>As an aside, we have closed forms for P-series for all even <span class="math">\(P\)</span> - always in the form of <span class="math">\(\frac{m}{n}\pi^P\)</span>. However, we do not know anything at this time about odd <span class="math">\(P\)</span>.</p>
<p>For example, a P-series where <span class="math">\(P = 3\)</span> results in a value that has no known exact form, and is still an unsolved problem in methematics.</p>
<h2 id="integral-test">Integral Test</h2>
<p>This is based on the connection between an infinite series (like a Riemann sum) and integration.</p>
<p>Let <span class="math">\(\sum_{n = 0}^\infty a_n\)</span> be an infinite series. Then we can write <span class="math">\(a_n\)</span> be a function of <span class="math">\(n\)</span>, like <span class="math">\(f(n)\)</span>.</p>
<p>For example, for <span class="math">\(\sum_{n = 0}^\infty \frac{1}{n^2}\)</span>, <span class="math">\(f(n) = \frac{1}{n^2}\)</span>.</p>
<p>Now we can develop the <strong>integral test</strong>.</p>
<p>Given <span class="math">\(f(n) = a_n\)</span>, if <span class="math">\(f(n)\)</span> is <strong>continuous</strong>, <strong>positive</strong>, and <strong>decreasing</strong> for all <span class="math">\(n \ge 1\)</span>, then <span class="math">\(\int_1^\infty f(n) \dee n\)</span> converges if and only if <span class="math">\(\sum_{n = 1}^\infty a_n\)</span> converges.</p>
<h3 id="error-estimation">Error Estimation</h3>
<p>For series that satisfy the hypetheses of the integral test, we can estimate the error/remainder <span class="math">\(R_N = \sum_1^\infty a_n - \sum_1^N a_n\)</span> for any <span class="math">\(N\)</span>.</p>
<p>This is useful because we can't explicitly calculate <span class="math">\(\sum_1^\infty a_n\)</span>, but we can calculate <span class="math">\(\sum_1^N a_n\)</span>.</p>
<p>So given <span class="math">\(f(n) = a_n\)</span> being continuous, positive, and decreasing, the error is bounded by <span class="math">\(\int_{N + 1}^\infty f(x) \dee x \le R_N \le \int_N^\infty f(x) \dee x\)</span>.</p>
<p>In other words, the error is bounded between <span class="math">\(\int_{N + 1}^\infty f(x)\)</span> and <span class="math">\(\int_N^\infty f(x) \dee x\)</span>.</p>
<p>For example, for the series <span class="math">\(S_N = \sum_{n = 1}^N \frac{1}{n^2}\)</span>, <span class="math">\(S_{10} \approxeq 1.54977\)</span>. We know that since <span class="math">\(f(n) = \frac{1}{n^2}\)</span> is continuous, positive, and decreasing, and <span class="math">\(\int_1^\infty \frac{1}{n^2}\)</span>. ;wip</p>
<h1 id="section-21">3/3/14</h1>
<h2 id="comparison-test-series">Comparison Test (Series)</h2>
<p>There is a deep connection between infinite series and improper integrals.</p>
<p>Like the improper integral, we can also have a form of the comparison test, but it is easier to use than with integrals.</p>
<p>Given <span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum b_n\)</span>, two series, with <span class="math">\(0 \le a_n \le b_n\)</span>:</p>
<ul>
<li>If <span class="math">\(\sum a_n\)</span> diverges, then <span class="math">\(\sum b_n\)</span> also diverges.</li>
<li>If <span class="math">\(\sum b_n\)</span> converges, then <span class="math">\(\sum a_n\)</span> also converges.</li>
</ul>
<p>Here, <span class="math">\(\sum a_n\)</span> is the series we are interested in and <span class="math">\(\sum b_n\)</span> is the series we chose to compare it with.</p>
<h3 id="limit-comparison-test">Limit Comparison Test</h3>
<p>For series only - not integrals - we can rewrite this in a more useful form.</p>
<p>Let <span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum b_n\)</span> be two series, with <span class="math">\(a_n \ge 0, b_n \ge 0\)</span>.</p>
<p>Let <span class="math">\(\rho = \lim_{n \to \infty} \frac{a_n}{b_n}\)</span>.</p>
<p>If <span class="math">\(0 &lt; \rho &lt; \infty\)</span> (<span class="math">\(\rho\)</span> is positive and finite), then:</p>
<ul>
<li><span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum b_n\)</span> both diverge.</li>
<li><span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum b_n\)</span> both converge.</li>
</ul>
<p>This is easily proved via contradiction or similar.</p>
<p>Note that if <span class="math">\(\rho = 0\)</span> or <span class="math">\(\rho = \infty\)</span>, then we cannot say anything about whether they converge or not, and we need to pick a better comparison.</p>
<p>Prove that <span class="math">\(\sum_{n = 1}^\infty \frac{\abs{\sin n}}{\sqrt{n + n^3}}\)</span> converges:</p>
<blockquote>
<p>Clearly, <span class="math">\(\frac{\abs{\sin n}}{\sqrt{n + n^3}} \le \frac{1}{\sqrt{n + n^3}} &lt; \frac{1}{\sqrt{n^3}} = \frac{1}{n^\frac{3}{2}}\)</span>.<br />Since this is a P-series where <span class="math">\(P = \frac{3}{2}\)</span>, <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^\frac{3}{2}}\)</span> converges.<br />So by the comparison test, <span class="math">\(\sum_{n = 1}^\infty \frac{\abs{\sin n}}{\sqrt{n + n^3}}\)</span> converges.</p>
</blockquote>
<h1 id="section-22">5/3/14</h1>
<p>We can find useful comparisons to make by finding something bigger than the numerator, and smaller than the denominator, and trying that as a comparison.</p>
<p>For example, <span class="math">\(\sum_1^\infty \frac{\sqrt{n}}{n^2 + 2} &lt; \sum_1^\infty \frac{\sqrt{n}}{n^2} = \sum_1^\infty \frac{1}{n^\frac{3}{2}}\)</span>, which converges as it is a P-series with <span class="math">\(P = \frac{3}{2}\)</span>.</p>
<p>For example, <span class="math">\(\sum_1^\infty \frac{1}{2^nn} \le \sum_1^\infty \frac{1}{2^n} = \sum_1^\infty \left(\frac{1}{2}\right)^n\)</span>, which converges since it is a geometric series with <span class="math">\(x = \frac{1}{2}\)</span>.</p>
<p>Does <span class="math">\(\sum_1^\infty \frac{1}{n^{1 + \frac{1}{n}}}\)</span> exist?</p>
<blockquote>
<p>Clearly, <span class="math">\(\sum_1^\infty \frac{1}{n^{1 + \frac{1}{n}}} = \sum_1^\infty \frac{1}{n}\frac{1}{n^\frac{1}{n}} &lt; \sum_1^\infty \frac{1}{n}\)</span>.<br />Using the limit comparison test, <span class="math">\(\rho = \lim_{n \to \infty} \frac{\frac{1}{n}\frac{1}{n^\frac{1}{n}}}{\frac{1}{n}} = \lim_{n \to \infty} n^{-\frac{1}{n}} = e^{-\lim_{n \to \infty} \frac{1}{n}\ln n} \lH e^{-\lim_{n \to \infty} \frac{\frac{1}{n}}{1}} = e^{-0} = 1\)</span>.<br />Since <span class="math">\(0 &lt; \rho &lt; \infty\)</span>, and <span class="math">\(\sum_1^\infty \frac{1}{n}\)</span> diverges, then <span class="math">\(\sum_1^\infty \frac{1}{n^{1 + \frac{1}{n}}\)</span> also diverges.</p>
</blockquote>
<p>Proof of limit comparison test:</p>
<blockquote>
<p>Let <span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum b_n\)</span> be two series, with <span class="math">\(a_n \ge 0, b_n \ge 0\)</span>.<br />Let <span class="math">\(\rho = \lim_{n \to \infty} \frac{a_n}{b_n}\)</span>. Assume <span class="math">\(0 &lt; \rho &lt; \infty\)</span>.<br />Clearly, <span class="math">\(\exists m, M &gt; 0, 0 &lt; m &lt; \rho &lt; M &lt; \infty\)</span>.<br />Clearly, <span class="math">\(\lim_{n \to \infty} \frac{a_n}{b_n} \iff (\exists K, n &gt; K \implies m &lt; \frac{a_n}{b_n} &lt; M)\)</span>.<br />So <span class="math">\(mb_n &lt; a_n &lt; Mb_n\)</span> and <span class="math">\(\sum mb_n &lt; \sum a_n &lt; \sum Mb_n\)</span>, or <span class="math">\(m\sum b_n &lt; \sum a_n &lt; M\sum b_n\)</span>.<br />Suppose <span class="math">\(\sum b_n\)</span> converges. Then <span class="math">\(\sum a_n &lt; M\sum b_n\)</span> and by the comparison test, <span class="math">\(\sum a_n\)</span> converges.<br />Suppose <span class="math">\(\sum b_n\)</span> diverges. Then <span class="math">\(m\sum b_n &gt; \sum a_n\)</span> and by the comparison test, <span class="math">\(\sum a_n\)</span> diverges.<br />So <span class="math">\(\sum a_n\)</span> converges if and only if <span class="math">\(\sum b_n\)</span> converges.</p>
</blockquote>
<p>Also, we can prove that sequences diverge by proving that they are increasing or decreasing without bound, or assuming that the sequence does converge, and deriving a contradiction.</p>
<h1 id="section-23">7/3/14</h1>
<h2 id="alternating-series">Alternating Series</h2>
<p>These are series where the sign of the terms alternate.</p>
<p>These usually take the form of <span class="math">\(\sum a_n = \sum (-1)^n p_n, p_n &gt; 0\)</span>.</p>
<p>Alternating series are useful to study because they have several useful properties.</p>
<h3 id="error">Error</h3>
<p>The remainder/error after <span class="math">\(N\)</span> terms is easy to estimate. Clearly, <span class="math">\(\abs{R_N} = \abs{\sum^\infty (-1)^n p_n - \sum^N (-1)^n p_n}\)</span>. So <span class="math">\(\abs{R_N} \le p_{N + 1}\)</span>.</p>
<p>This is true because the terms of the series keep bouncing back and forth across the limit, so the remainder is always bounded by the value of the next term.</p>
<p>For example, <span class="math">\(\sum_1^\infty (-1)^{n + 1} \frac{1}{n} = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \ldots = \ln 2\)</span>. We can estimate the error with <span class="math">\(\abs{R_N} = \frac{1}{N + 1}\)</span>.</p>
<h3 id="convergence-2">Convergence</h3>
<p>For an alternating series, if <span class="math">\(\lim_{n \to \infty} p_n = 0\)</span>, and <span class="math">\(p_{n + 1} \le p_n\)</span>, then the series converges.</p>
<p>In other words, if the terms of the sum tend to 0, and they are monotonically decreasing, then the series converges. This is one of the simplest convergence tests, but it only works on alternating series.</p>
<p>Alternating series also have special nomenclature that can be applied to them.</p>
<p>Let <span class="math">\(\sum a_n = \sum (-1)^n p_n\)</span> be an alternating series.</p>
<p><span class="math">\(\sum a_n\)</span> is <strong>absolutely convergent</strong> if <span class="math">\(\sum a_n\)</span> and <span class="math">\(\sum \abs{a_n}\)</span> converge.</p>
<p>Absolute convergence means that the series is <strong>well behaved</strong> - it behaves like an ordinary number. We can add, subtract, multiply, and divide absolutely convergent series and the result is still sensible.</p>
<p><span class="math">\(\sum a_n\)</span> is <strong>conditionally convergent</strong> if <span class="math">\(\sum a_n\)</span> converges, but <span class="math">\(\sum \abs{a_n}\)</span> diverges.</p>
<p>Conditional convergence means the series might not be well behaved.</p>
<p>For example, consider <span class="math">\(1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \ldots\)</span>.</p>
<p>For an absolutely convergent series, re-arrangement does nothing. This is not true for conditionally convergent series. In fact, the above can have its terms rearranged such that it sums up to any value we want, and this was proved by Riemann.</p>
<p>For example, we will make it sum up to 1.5:</p>
<blockquote>
<p>First, we add up positive terms until we pass 1.5: <span class="math">\(1 + \frac{1}{3} + \frac{1}{5} \approxeq 1.53\)</span>.<br />Then we add negative terms until we fall below 1.5 again: <span class="math">\(1 + \frac{1}{3} + \frac{1}{5} - \frac{1}{2} \approxeq 1.03\)</span>.<br />Then we repeat: <span class="math">\(1 + \frac{1}{3} + \frac{1}{5} - \frac{1}{2} + \frac{1}{7} + \frac{1}{9} + \frac{1}{11} + \frac{1}{13} + \frac{1}{15} \approxeq 1.52\)</span>.<br />We can do this as many times as needed to get the desired value.</p>
</blockquote>
<p>Even though there are far more positive terms than negative terms, we can do this because we have an infinite number of terms that we can add up. This only works because the series is infinite.</p>
<h1 id="section-24">10/3/14</h1>
<h2 id="ratio-test">Ratio Test</h2>
<p>This is the most useful of the convergence tests.</p>
<p>Let <span class="math">\(\sum a_n\)</span> be a series. Let <span class="math">\(L = \lim_{n \to \infty} \abs{\frac{a_{n + 1}}{a_n}}\)</span>.</p>
<p>If <span class="math">\(L &lt; 1\)</span>, then <span class="math">\(\sum a_n\)</span> converges absolutely.</p>
<p>If <span class="math">\(L &gt; 1\)</span>, then <span class="math">\(\sum a_n\)</span> diverges.</p>
<p>Otherwise, if <span class="math">\(L = 1\)</span>, the test is inconclusive. This test is very effective for powers and factorials, and especially for power series and Taylor series.</p>
<p>Determine if <span class="math">\(\sum_{n = 0}^\infty \frac{(n + 4)!}{4!n!4^n}\)</span> converges:</p>
<blockquote>
<p>We will use the ratio test.<br />Let <span class="math">\(L = \lim_{n \to \infty} \abs{\frac{((n + 1) + 4)!}{4!(n + 1)!4^(n + 1)} \frac{4!n!4^n}{(n + 4)!}} = \lim_{n \to \infty} \frac{n + 5}{4!(n + 1)!4^(n + 1)} 4!n!4^n = \lim_{n \to \infty} \frac{n + 5}{4(n + 1)!} n! = \lim_{n \to \infty} \frac{n + 5}{4(n + 1)} \lH \lim_{n \to \infty} \frac{1}{4} = \frac{1}{4}\)</span>.<br />Since <span class="math">\(L &lt; 1\)</span>, <span class="math">\(\sum_{n = 0}^\infty \frac{(n + 4)!}{4!n!4^n}\)</span> converges absolutely.</p>
</blockquote>
<p>Proof:</p>
<blockquote>
<p>The idea is that if <span class="math">\(L &lt; 1\)</span>, then we can compare <span class="math">\(\sum a_n\)</span> to a convergent geometric series.<br />Assume <span class="math">\(L &lt; 1\)</span>. Then <span class="math">\(\exists r \in \mb{R}, L &lt; r &lt; 1\)</span>.<br />Note that <span class="math">\(\lim_{n \to \infty} \abs{\frac{a_{n + 1}}{a_n}}\)</span> means that <span class="math">\(\exists K &gt; 0, n \ge K \implies \abs{\frac{a_{n + 1}}{a_n}} &lt; L\)</span>.<br />So <span class="math">\(\exists 0 \le N \le K, n \ge N \implies \abs{\frac{a_{n + 1}}{a_n}} &lt; r\)</span>.<br />Assume <span class="math">\(n \ge N\)</span>. Then <span class="math">\(\abs{\frac{a_{n + 1}}{a_n}} &lt; r\)</span> and <span class="math">\(\abs{a_{n + 1}} &lt; r\abs{a_n}\)</span>.<br />So <span class="math">\(\forall k, \abs{a_{N + k}} &lt; \abs{a_N}r^k\)</span>. For example, <span class="math">\(\abs{a_{N + 3}} &lt; \abs{a_{N + 2}}r &lt; \abs{a_{N + 1}}r^2 &lt; \abs{a_N}r^3\)</span>.<br />So <span class="math">\(\sum_{k = 0}^\infty \abs{a_{N + k}} &lt; \sum_{k = 0}^\infty \abs{a_{N}}r^k\)</span>.<br />Clearly, <span class="math">\(\sum_{k = 0}^\infty \abs{a_{N}}r^k = \abs{a_{N}}\sum_{k = 0}^\infty r^k\)</span>, which converges since it is a geometric series with <span class="math">\(x &lt; 1\)</span>.<br />So by the comparison test, <span class="math">\(\sum a_n &lt; \abs{a_{N}}\sum_{k = 0}^\infty r^k\)</span>, so <span class="math">\(\sum a_n\)</span> converges.<br />A similar proof can be made for the case when <span class="math">\(L &gt; 1\)</span>.</p>
</blockquote>
<p>Another example is <span class="math">\(e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}\)</span>. Note that if we take the limit of the series, we get the same series back.</p>
<h3 id="root-test">Root Test</h3>
<p>Let <span class="math">\(\sum a_n\)</span> be a series. Let <span class="math">\(L = \lim_{n \to \infty} \sqrt[n]{\abs{a_n}}\)</span>.</p>
<p>If <span class="math">\(L &lt; 1\)</span>, then <span class="math">\(\sum a_n\)</span> converges absolutely.</p>
<p>If <span class="math">\(L &gt; 1\)</span>, then <span class="math">\(\sum a_n\)</span> diverges.</p>
<p>This can be proved in a manner similar to the ratio test.</p>
<h1 id="section-25">12/3/14</h1>
<h2 id="using-convergence-tests">Using Convergence Tests</h2>
<p>Let <span class="math">\(\sum a_n\)</span> be a series.</p>
<ol style="list-style-type: decimal">
<li>Simple Limit Test: If <span class="math">\(\lim_{n \to \infty} a_n \ne 0\)</span>, then <span class="math">\(\sum a_n\)</span> diverges.</li>
<li>Alternating Series Test: If the series is alternating and decreasing (<span class="math">\(\abs{a_{n + 1}} &lt; \abs{a_n}\)</span>), then <span class="math">\(\sum a_n\)</span> converges.</li>
<li>Ratio Test/Root Test: Let <span class="math">\(L = \lim_{n \to \infty} \abs{\frac{a_{n + 1}}{a_n}}\)</span> or <span class="math">\(L = \lim_{n \to \infty} \sqrt[n]{\abs{a_n}}\)</span>, whichever is easier to evaluate:
<ol style="list-style-type: decimal">
<li>If <span class="math">\(L &lt; 1\)</span>, then <span class="math">\(\sum a_n\)</span> converges.</li>
<li>If <span class="math">\(L &gt; 1\)</span>, then <span class="math">\(\sum a_n\)</span> diverges.</li>
</ol></li>
<li>If <span class="math">\(a_n\)</span> is an algebraic (polynomials and roots) function of <span class="math">\(n\)</span>, then try using the Comparison Test with a P-series, <span class="math">\(\sum \frac{1}{n^P}\)</span>.</li>
<li>If <span class="math">\(a_n\)</span> is closely related to a geometric series, then try using the Comparison Test with a geometric series, <span class="math">\(\sum x^n\)</span>.</li>
<li>If <span class="math">\(f(n) = a_n\)</span> is positive, decreasing, and integrable, then try the Integral Test.</li>
</ol>
<p>Prove whether the following converge or diverge:</p>
<ul>
<li><span class="math">\(\sum_{n = 1}^\infty \frac{n^2 + 7n}{\sqrt{n^5 + 4n^3 - 2}} \le \frac{1}{\sqrt{n}}\)</span>.</li>
<li><span class="math">\(\sum_{n = 1}^\infty \frac{n + 5}{5^n}\)</span></li>
<li><span class="math">\(\sum_{n = 1}^\infty n^2 e^{-n}\)</span></li>
<li><span class="math">\(\sum_{n = 1}^\infty \frac{1}{(\ln n)^{\ln n}}\)</span></li>
<li><span class="math">\(\sum_{n = 1}^\infty \frac{e^\frac{1}{n}}{n^2}\)</span></li>
</ul>
<p>;wip</p>
<h2 id="power-series">Power Series</h2>
<p>A power series is a series of the form <span class="math">\(\sum_{n = 0}^\infty a_n (x - x_0)^n\)</span>, where <span class="math">\(a_n \in \mb{R}\)</span>.</p>
<p>Here, <span class="math">\(x_0\)</span> is the <strong>center</strong> of the power series.</p>
<p>We want to figure out for which values of <span class="math">\(x\)</span> our series converges for. For this, we will usually use the ratio test.</p>
<p>For example, check if <span class="math">\(\sum_{n = 1}^\infty \frac{(-1)^n x^n}{3^n \sqrt{n}}\)</span> converges:</p>
<blockquote>
<p>Let <span class="math">\(L = \lim_{n \to \infty} \abs{\frac{(-1)^{n + 1} x^{n + 1}}{3^{n + 1} \sqrt{n + 1}} \frac{3^n \sqrt{n}}{(-1)^n x^n}} = \lim_{n \to \infty} \abs{\frac{-x}{3 \sqrt{n + 1}} \sqrt{n}} = \frac{\abs{x}}{3} \lim_{n \to \infty} \frac{1}{\sqrt{n + 1}} \sqrt{n} = \frac{\abs{x}}{3} \lim_{n \to \infty} \sqrt{\frac{n}{n + 1}} = \frac{\abs{x}}{3}\)</span>. ;wip: use l'hospital's rule or something to evaluate the limit properly Clearly, <span class="math">\(L &lt; 1\)</span> whenever <span class="math">\(-3 &lt; x &lt; 3\)</span>, so the series converges for any <span class="math">\(-3 &lt; x &lt; 3\)</span>.<br />Clearly, <span class="math">\(L &gt; 1\)</span> whenever <span class="math">\(x &lt; -3 \vee x &gt; 3\)</span>, so the series diverges for any <span class="math">\(x &lt; -3 \vee x &gt; 3\)</span>.<br />Now we need to consider <span class="math">\(L = 1\)</span>, where <span class="math">\(x = \pm 3\)</span>. Assume <span class="math">\(x = 3\)</span>.<br />Then <span class="math">\(\sum_{n = 1}^\infty \frac{(-1)^n x^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n 3^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n}{\sqrt{n}}\)</span>.<br />This is an alternating series, and since <span class="math">\(\lim_{n \to \infty} \frac{1}{\sqrt{n}} = 0\)</span> and <span class="math">\(\frac{1}{\sqrt{n + 1}} &lt; \frac{1}{\sqrt{n}}\)</span>, the series converges (conditionally) by the alternating series test.<br />Assume <span class="math">\(x = -3\)</span>.<br />Then <span class="math">\(\sum_{n = 1}^\infty \frac{(-1)^n x^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n (-3)^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{(-1)^n (-1)^n 3^n}{3^n \sqrt{n}} = \sum_{n = 1}^\infty \frac{1}{\sqrt{n}}\)</span>.<br />This is a P-series where <span class="math">\(P = \frac{1}{2}\)</span>, so the series diverges.<br />So the series converges absolutely if and only if <span class="math">\(x \in (-3, 3)\)</span>, and converges conditionally for <span class="math">\(x = 3\)</span>.</p>
</blockquote>
<h3 id="radius-of-convergence">Radius of Convergence</h3>
<p>The <strong>radius of convergence</strong> for a power series is the maximum magnitude of the values of <span class="math">\(\abs{x - x_0}\)</span> on the imaginary plane such that all numbers inside this radius of <span class="math">\(x_0\)</span> allow the power series to converge absolutely, and all numbers outside of this radius diverge.</p>
<p>The behaviour when <span class="math">\(\abs{x - x_0} = \rho\)</span> is not important, just that it is a bounding radius.</p>
<p>The values of <span class="math">\(x\)</span> that allow the series to converge are known as the <strong>interval of convergence</strong>. Unlike the radius of convergence, we also need to consider the endpoints of the interval for convergence.</p>
<p>This is a number <span class="math">\(\rho \in \mb{R}\)</span> such that:</p>
<ul>
<li><span class="math">\(\sum_{n = 0}^\infty c_n (x - x_0)^n\)</span> converges absolutely for all <span class="math">\(\abs{x - x_0} &lt; \rho\)</span></li>
<li><span class="math">\(\sum_{n = 0}^\infty c_n (x - x_0)^n\)</span> diverges for all <span class="math">\(\abs{x - x_0} &gt; \rho\)</span></li>
<li><span class="math">\(\sum_{n = 0}^\infty c_n (x - x_0)^n\)</span> may converge or diverge for <span class="math">\(\abs{x - x_0} = \rho\)</span></li>
</ul>
<p>In the above example, the radius of convergence is 3.</p>
<p>All geometric series are power series where <span class="math">\(a_n = 1\)</span> and <span class="math">\(x_0 = 0\)</span>.</p>
<p>The interval of convergence for a geometric series <span class="math">\(\sum_{n = 0}^\infty x^n\)</span> is <span class="math">\(\abs{x} &lt; 1\)</span>.</p>
<h1 id="section-26">14/3/14</h1>
<p>Within the radius of convergence, a power series behaves like an ordinary function. The idea is that if we are inside the radius of convergence, then we can treat the infinite series like a finite polynomial.</p>
<p>Let <span class="math">\(f(x) = \sum_{n = 0}^\infty a_n (x - x_0)^n, g(x) = \sum_{n = 0}^\infty b_n (x - x_0)^n\)</span>:</p>
<ul>
<li><span class="math">\(f(x) \pm g(x) = \sum_{n = 0}^\infty (a_n \pm b_n) (x - x_0)^n\)</span>.</li>
<li><span class="math">\(f(x) g(x) = \sum_{n = 0}^\infty c_n (x - x_0)^n\)</span> where <span class="math">\(c_n = a_0 b_n + a_1 b_{n - 1} + \ldots + a_{n - 1} b_1 + a_n b_0\)</span>.</li>
<li>If <span class="math">\(g(x) \ne 0\)</span>, then <span class="math">\(\frac{f(x)}{g(x)} = \sum_{n = 0}^\infty d_n (x - x_0)^n\)</span> ;wip: what is d_n?</li>
</ul>
<p>More importantly, we can differentiate and integrate the terms of the sum:</p>
<p>So <span class="math">\(\frac{\dee f}{\dee x} = \frac{\dee}{\dee x} (a_0 + a_1(x - x_0) + a_2 (x - x_0)^2 + \ldots) = 0 + a_1 + 2a_2 (x - x_0) + \ldots\)</span>. Note that the first term became 0, so we don't need to sum it.</p>
<p>So <span class="math">\(\frac{\dee f}{\dee x} = \sum_{n = 0}^\infty a_n n(x - x_0)^{n - 1}\)</span>.</p>
<p>So <span class="math">\(\int f(x) \dee x = \sum_{n = 0}^\infty \int a_n (x - x_0)^n \dee x = c + \sum_{n = 0}^\infty a_n \frac{(x - x_0)^{n + 1}}{n + 1}\)</span>.</p>
<p>Find the power series of <span class="math">\(\frac{1}{1 - x}\)</span> and use it to approximate <span class="math">\(\ln\)</span>:</p>
<blockquote>
<p>Clearly, this is the value of the geometric series, as we saw earlier: <span class="math">\(\frac{1}{1 - x} = \sum_{n = 0}^\infty x^n\)</span> for <span class="math">\(\abs{x} &lt; 1\)</span>.<br />Clearly, <span class="math">\(\int_0^t \frac{1}{1 - x} \dee x = -\ln \abs{1 - t} = \sum_{n = 0}^\infty \int_0^t x^n \dee x = \sum_{n = 0}^\infty \frac{t^{n + 1}}{n + 1}\)</span> for <span class="math">\(\abs{t} &lt; 1\)</span>.<br />So <span class="math">\(\ln \abs{1 - t} = -\sum_{n = 1}^\infty \frac{t^n}{n}\)</span> for <span class="math">\(\abs{t} &lt; 1\)</span>.<br />Note that this only works for <span class="math">\(\abs{t} &lt; 1\)</span>. However, there are tricks we can use to avoid this issue.<br />For example, we can't use this approximation to find <span class="math">\(\ln 3\)</span>, since for <span class="math">\(\ln \abs{1 - t}\)</span>, <span class="math">\(t = -2\)</span>, but note that <span class="math">\(\ln \frac{1}{3} = -\ln 3\)</span>, so <span class="math">\(\ln 3 = -\ln \frac{1}{3} = -\ln \abs{1 - \frac{2}{3}} = \sum_{n = 1}^\infty \frac{1}{n} \frac{2}{3}^n\)</span>.<br />We want a general form for all values in the domain of <span class="math">\(\ln x\)</span>, so <span class="math">\(x &gt; 0\)</span>.<br />Clearly, <span class="math">\(\ln \abs{1 - (-t)} - \ln \abs{1 - t} = \ln \abs{\frac{1 + t}{1 - t}} = -\sum_{n = 1}^\infty \frac{(-t)^n}{n} + \sum_{n = 1}^\infty \frac{t^n}{n} = \sum_{n = 1}^\infty (1 - (-1)^n)\frac{t^n}{n} = 2t + \frac{2}{3}t^3 + \frac{2}{5}t^5 + \ldots = \sum_{n = 1}^\infty \frac{2}{2n - 1}t^{2n - 1}\)</span>.<br />Let <span class="math">\(x = \abs{\frac{1 + t}{1 - t}}\)</span>. Then <span class="math">\(t = \abs{\frac{x - 1}{x + 1}} = \frac{x - 1}{x + 1}\)</span>, since <span class="math">\(x &gt; 0\)</span>.<br />So <span class="math">\(\abs{t} &lt; 1 \iff -x &lt; x &lt; x + 2 \iff x &gt; 0\)</span>, so <span class="math">\(\abs{t} &lt; 1\)</span> for all <span class="math">\(x\)</span> in the domain, as required.<br />Then we can write <span class="math">\(\ln x = \ln \frac{1 + t}{1 - t} = \sum_{n = 1}^\infty \frac{2}{2n - 1}\left(\frac{x - 1}{x + 1}\right)^{2n - 1}\)</span>, for <span class="math">\(x &gt; 0\)</span>.</p>
</blockquote>
<p>This is actually how calculators evaluate these sorts of functions - by calculating the partial sums of a power series to a given error.</p>
<p>Find the power series for <span class="math">\(\frac{1}{1 + x^2}\)</span> and use it to approximate <span class="math">\(\arctan\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(u = -x^2\)</span>. Then <span class="math">\(\frac{1}{1 + x^2} = \frac{1}{1 - u} = \sum_{n = 0}^\infty u^n = \sum_{n = 0}^\infty (-1)^n x^{2n}\)</span> for <span class="math">\(\abs{u} &lt; 1\)</span>.<br />Clearly, <span class="math">\(\int_0^t \frac{1}{1 + x^2} \dee x = \arctan t = \sum_{n = 0}^\infty \int_0^t (-1)^n x^{2n} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1} t^{2n + 1}\)</span> for <span class="math">\(\abs{t} &lt; t\)</span>.<br />So <span class="math">\(\arctan t = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1} t^{2n + 1}\)</span> for <span class="math">\(-1 &lt; t &lt; 1\)</span>.</p>
</blockquote>
<h2 id="taylor-series">Taylor Series</h2>
<p>What power series is identical to a function <span class="math">\(f(x)\)</span> and all its derivatives at a point <span class="math">\(x = x_0\)</span>?</p>
<p>For <span class="math">\(\abs{x - x_0} &lt; \rho\)</span>, where <span class="math">\(\rho\)</span> is the radius of convergence, <span class="math">\(f(x) = \sum_{n = 0}^\infty \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n\)</span> where <span class="math">\(f^{(n)}(x_0) = \evalat{\frac{\dee^n f}{\dee x^n}}_{x = x_0}\)</span>, and <span class="math">\(f^{(0)}(x_0) = f(x_0)\)</span>. This is known as a <strong>Taylor series</strong>.</p>
<p>A <strong>Taylor polynomial</strong> is a partial sum of a Taylor series - all partial sums of Taylor series are simply polynomials. <span class="math">\(\sum_{n = 0}^k \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n\)</span> is known as a <span class="math">\(k\)</span>-degree Taylor polynomial.</p>
<p>Find the Taylor polynomial for <span class="math">\(e^x\)</span> and use it to estimate <span class="math">\(\int_0^1 e^{-x^2} \dee x\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(f(x) = e^x, x_0 = 0\)</span>. Then <span class="math">\(f^{(n)} = \evalat{\frac{\dee^n f}{\dee x^n}}_{x = x_0} = \evalat{e^x}_{x = x_0} = 1\)</span>.<br />Then <span class="math">\(f(x) = e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}, \abs{x - x_0} &lt; \rho\)</span>.<br />Let <span class="math">\(L = \lim_{n \to \infty} \abs{\frac{x^{n + 1}}{(n + 1)!} \frac{n!}{n^n}} = \lim_{n \to \infty} \abs{\frac{x}{n + 1}} = 0\)</span>.<br />Then by the ratio test, the series converges for all <span class="math">\(0 &lt; 1\)</span>, and the radius of covnergence is <span class="math">\(\rho = \infty\)</span>.<br />So <span class="math">\(\int_0^1 e^{-x^2} \dee x = \int_0^1 f(-x^2) \dee x = \sum_{n = 0}^\infty \int_0^1 \frac{(-x^2)^n}{n!} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{n!(2n + 1)}\)</span>.</p>
</blockquote>
<h1 id="section-27">17/3/14</h1>
<p>;wip: check to make sure assignment marks are on LEARN</p>
<p>The Taylor series has the same derivative and integral as the function for all possible values of <span class="math">\(x\)</span> within the radius of convergence.</p>
<p>The <span class="math">\(N\)</span>th partial sum of a Taylor series has the same zero to <span class="math">\(N\)</span>th derivatives.</p>
<p>Find the Taylor series for <span class="math">\(\sin x\)</span> and <span class="math">\(\cos x\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(f(x) = \sin x, x_0 = 0\)</span>. Then <span class="math">\(f^{(n)} = \evalat{\frac{\dee^n f}{\dee x^n}}_{x = x_0}\)</span>. Clearly, <span class="math">\(f^{(0)}(0) = 0, f^{(1)}(0) = 1, f^{(1)}(0) = 0, f^{(1)}(0) = -1, \ldots\)</span>.<br />Since all the even powers are 0, then we simply omit those terms.<br />So <span class="math">\(f(x) = \sin x = \sum_{n = 0}^\infty \frac{f^{(n)}(x_0)}{n!}x^n = x - \frac{x^3}{3} + \frac{x^5}{5!} - \frac{x^7}[7!} + \ldots = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}, \abs{x - x_0} &lt; \rho\)</span>.<br />Let <span class="math">\(L = \lim_{n \to \infty} \abs{\frac{(-1)^{n + 1} x^{2n + 3}}{(2n + 3)!} \frac{(2n + 1)!}{(-1)^n}} = \lim_{n \to \infty} \abs{\frac{x^2}{(2n + 3)(2n + 2)}} = 0\)</span>.<br />Then by the ratio test, the series converges for all <span class="math">\(0 &lt; 1\)</span>, and the radius of covnergence is <span class="math">\(\rho = \infty\)</span>.<br />So the Taylor series is <span class="math">\(\sin x = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}\)</span>.<br />We can find the Taylor series for <span class="math">\(\cos x\)</span> by taking derivatives of both sides: <span class="math">\(\frac{\dee}{\dee x} \sin x = \cos x = \frac{\dee}{\dee x} \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!} = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n)!}\)</span>.</p>
</blockquote>
<p>Taylor series allow us to do interesting analyses. For example, it is easy to see that <span class="math">\(\sin(-x) = -\sin x\)</span> from the fact that <span class="math">\(\sum_{n = 0}^\infty \frac{(-1)^n (-x)^{2n + 1}}{(2n + 1)!} = -\sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}\)</span>.</p>
<p>;wip: use the taylor series to show that <span class="math">\(e^{i \theta} = \cos \theta + \imag \sin \theta\)</span> - prove euler's identity</p>
<p>We want to find a simple formula to find <span class="math">\((1 + x)^P\)</span> for any natural number <span class="math">\(P\)</span>. This was found to be <span class="math">\(1 + Px + \frac{P(P - 1)x^2}{2!} + \frac{P(P - 1)(P - 2)}{3!} + \ldots + \frac{P \cdot (P - 1) \cdot \ldots \cdot (P - (n - 1))}{n!}x^n + \ldots\)</span>.</p>
<p>Clearly, for any whole number <span class="math">\(P\)</span> the series must terminate after <span class="math">\(P + 1\)</span> terms - when one of the factors <span class="math">\((P - k)\)</span> becomes 0. However, if <span class="math">\(P\)</span> is a fraction, then the series actually becomes infinite. As it turns out, this works for negative numbers too.</p>
<p>For example, <span class="math">\(\sqrt{1 - x} = (1 + x)^\frac{1}{2} = 1 - \frac{1}{2}x - \frac{1}{8}x^2 - \frac{1}{16}x^3 - \ldots\)</span>.</p>
<p>Some common Taylor series are:</p>
<ul>
<li>Geometric series: <span class="math">\(\sum_{n = 0}^\infty x^n = \frac{1}{1 - x}, \abs{x - x_0} &lt; \rho\)</span></li>
<li>Exponential series: <span class="math">\(\sum_{n = 0} \frac{x^n}{n!} = e^x, \abs{x - x_0} &lt; \rho\)</span></li>
<li>Trigonometric series: <span class="math">\(\sin x = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}\)</span></li>
<li>Binomial series: <span class="math">\(1 + Px + \frac{P(P - 1)}{2!}x^2 + \frac{P(P - 1)(P - 2)}{3!}x^3 + \ldots + \frac{P \cdot (P - 1) \cdot \ldots \cdot (P - (n - 1))}{n!}x^n + \ldots = (1 + x)^P\)</span></li>
</ul>
<h1 id="section-28">19/3/14</h1>
<h2 id="properties-of-taylor-series">Properties of Taylor Series</h2>
<p>So far we have derived power series by integrating geometric series, or by using the Taylor formula.</p>
<p>Is the Taylor series of a function unique? Are there multiple ways to write out the power series of a function?</p>
<p>First, we define the partial sum of a Taylor series for a function <span class="math">\(f(x)\)</span>, <span class="math">\(P_{N, x_0}(x) = \sum_{n = 0}^N \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n\)</span>.</p>
<p>Then the remainder - the difference between the function and the partial sum - is <span class="math">\(R_N(x) = f(x) - P_{N, x_0}(x) = \sum_{n = N + 1}^\infty \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n\)</span>.</p>
<p>For example, given <span class="math">\(f(x) = e^x\)</span>, <span class="math">\(P_{3, 0}(x) = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!}\)</span> and <span class="math">\(R_{3, 0} = e^x - 1 - x - \frac{x^2}{2!} - \frac{x^3}{3!}\)</span>.</p>
<h3 id="uniqueness-of-taylor-series">Uniqueness of Taylor Series</h3>
<p>If <span class="math">\(f^{(n)}(x)\)</span> exists for all <span class="math">\(n \in \mb{N}\)</span> for some interval <span class="math">\(\mb{I}\)</span> such that <span class="math">\(x_0 \in \mb{I}\)</span>, and <span class="math">\(\forall n \in \mb{N}, x \in \mb{I}, \abs{f^{(n)}(x)} &lt; \infty\)</span>, then <span class="math">\(\forall x \in \mb{I}, \lim_{N \to \infty} \abs{f(x) - P_{N, x_0}(x)} = 0\)</span>.</p>
<p>In other words, if the function has all derivatives on an interval containing <span class="math">\(x = x_0\)</span>, and all these derivatives are finite, then as we add more terms to the partial sum, the partial sum eventually converges to exactly the function.</p>
<p>As a result, <span class="math">\(P_{N, x_0}\)</span> is <strong>unique</strong>. Practically speaking, this means we can generate Taylor series using any method we want to, and the result will always be the one true Taylor series for a given <span class="math">\(f(x)\)</span> and <span class="math">\(x_0\)</span>.</p>
<p>Proof:</p>
<blockquote>
<p>;wip</p>
</blockquote>
<p>Derive the Taylor series for <span class="math">\(f(x) = e^{-x^2}\)</span> for <span class="math">\(x_0 = 0\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(f^{(0)}(0) = 1, f^{(1)}(0) = 0, \ldots\)</span>, and the derivatives keep getting more and more complicated as we keep differentiating. It is impractical to calculate <span class="math">\(f^{(n)}\)</span>.<br />Instead, we use a substitution: let <span class="math">\(u = -x^2\)</span>. Then <span class="math">\(e^u = 1 + u + \frac{u^2}{2!} + \frac{u^3}{3!} + \ldots\)</span>.<br />Then <span class="math">\(e^{-x^2} = 1 - x^2 + \frac{x^4}{2!} - \frac{x^6}{3!} + \ldots\)</span>.</p>
</blockquote>
<p>This is a faster way to derive series - by using <strong>substitutions</strong> to make the functions simpler, converting the simpler function into a series, and then substituting the variable back into the series.</p>
<p>Derive a Taylor series for <span class="math">\(f(x) = \sin x^3\)</span> at <span class="math">\(x_0 = 0\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(u = x^3\)</span>. Then <span class="math">\(\sin x^3 = \sin u = \sum_{n = 0}^\infty \frac{(-1)^n u^{2n + 1}}{(2n + 1)!} = \sum_{n = 0}^\infty \frac{(-1)^n x^{6n + 3}}{(2n + 1)!} = \sin x^3\)</span>.</p>
</blockquote>
<p>Derive the Taylor series for <span class="math">\(f(x) = \frac{1 + x}{1 - x}\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(f(x) = (1 + x)\frac{1}{1 - x} = (1 + x)\sum_{n = 0}^\infty x^n = \sum_{n = 0}^\infty x^n + \sum_{n = 1}^\infty x^n = 1 + \sum_{n = 1}^\infty x^n + \sum_{n = 1}^\infty x^n = 1 + 2\sum_{n = 1}^\infty x^n\)</span>.</p>
</blockquote>
<p>Derive the Taylor series for <span class="math">\(\arcsin x\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\arcsin x = \int_0^x \frac{1}{\sqrt{1 - t^2}} \dee t\)</span>.<br />Let <span class="math">\(u = -t^2\)</span>. Clearly, <span class="math">\(\frac{1}{\sqrt{1 - t^2}} = (1 + u)^{-\frac{1}{2}} = 1 - \frac{1}{2}u + \frac{3}{4}\frac{u^2}{2!} - \frac{15}{8}\frac{u^3}{3!} + \frac{105}{16} \frac{u^4}{4!} + \ldots\)</span>.<br />So <span class="math">\((1 + u)^{-\frac{1}{2}} = \frac{1}{\sqrt{1 - t^2}} = 1 + \frac{1}{2}t^2 + \frac{3}{2^2}\frac{t^4}{2!} + \frac{15}{2^3}\frac{t^6}{3!} + \frac{105}{2^4} \frac{t^8}{4!} + \ldots\)</span>.<br />So <span class="math">\(\int_0^x \frac{1}{\sqrt{1 - t^2}} \dee t = \arcsin x = \int_0^x 1 \dee t + \int_0^x \frac{1}{2}t^2 \dee t + \int_0^x \frac{3}{2^2}\frac{t^4}{2!} \dee t + \int_0^x \frac{15}{2^3}\frac{t^6}{3!} \dee t + \int_0^x \frac{105}{2^4} \frac{t^8}{4!} \dee t + \ldots = x + \frac{1}{3}\frac{1}{2}t^3 + \frac{1}{5}\frac{3}{2^2}\frac{t^5}{2!} + \frac{1}{7}\frac{15}{2^3}\frac{t^7}{3!} + \frac{1}{9}\frac{105}{2^4} \frac{t^9}{4!} + \ldots\)</span>.</p>
</blockquote>
<h1 id="section-29">21/3/14</h1>
<h2 id="truncation-error">Truncation Error</h2>
<p>We can actually estimate the error in <span class="math">\(P_{N, x_0}(x)\)</span>, even without knowing much about <span class="math">\(f(x)\)</span>.</p>
<h3 id="taylors-remainder-theorem">Taylor's Remainder Theorem</h3>
<p>If <span class="math">\(f^{(n + 1)}(x)\)</span> is continuous on an interval <span class="math">\(\mb{I}\)</span> such that <span class="math">\(x_0 \in \mb{I}\)</span>, then <span class="math">\(\forall x \in \mb{I}, \exists \min(x_0, x) &lt; c &lt; \max(x_0, x), f(x) - P_{N, x_0}(x) = R_N(x) = \frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}\)</span>.</p>
<p>In other words, there exists a value <span class="math">\(c\)</span> between <span class="math">\(x\)</span> and <span class="math">\(x_0\)</span> exclusive such that the error is <span class="math">\(\frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}\)</span> - the <span class="math">\(N + 1\)</span>th term evaluated with a certain value of the <span class="math">\(N + 1\)</span>th derivative.</p>
<p>This can be proved using the Intermediate Value Theorem, but it is a messy proof.</p>
<p>Clearly, if <span class="math">\(f(x) - P_{N, x_0}(x) = \frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}\)</span>, then <span class="math">\(\abs{f(x) - P_{N, x_0}(x)} = \abs{R_N(x)} = \abs{\frac{f^{(N + 1)}(c)}{(N + 1)!}(x - x_0)^{N + 1}} = \abs{f^{(N + 1)}(c)}\abs{\frac{(x - x_0)^{N + 1}}{(N + 1)!}} = \abs{f^{(N + 1)}(c)}\frac{\abs{x - x_0}^{N + 1}}{(N + 1)!}\)</span>.</p>
<p>Clearly, if <span class="math">\(\exists M \in \mb{R}, \forall x \in \mb{I}, \abs{f^{(N + 1)}(x)} \le M\)</span>, then <span class="math">\(\abs{f^{(N + 1)}(c)} \le M\)</span> and <span class="math">\(\abs{R_N(x)} \le M\frac{\abs{x - x_0}^{N + 1}}{(N + 1)!}\)</span>.</p>
<p>This is called the <strong>Taylor's inequality</strong>, and is a more practically useful form of the Taylor Remainder Theorem.</p>
<p>Basically, if <span class="math">\(f^{(n + 1)}(x)\)</span> is continuous on an interval <span class="math">\(\mb{I}\)</span> such that <span class="math">\(x_0 \in \mb{I}\)</span>, and <span class="math">\(\exists M \in \mb{R}, \forall x \in \mb{I}, \abs{f^{(N + 1)}(x)} \le M\)</span>, then <span class="math">\(\abs{R_{N, x_0}} \le M\frac{\abs{x - x_0}^{N + 1}}{(N + 1)!}\)</span>.</p>
<p>In other words, if we can bound <span class="math">\(f^{N + 1}(x)\)</span>, then we can bound the error.</p>
<p>Estimate the error in the Taylor polynomial for <span class="math">\(\sin x\)</span> about <span class="math">\(x_0 = 0\)</span> after <span class="math">\(N\)</span> terms:</p>
<blockquote>
<p>Clearly, the error is <span class="math">\(\abs{R_N(x)} = \abs{\sin x - \sum_{n = 0}^N \frac{(-1)^n x^{2n + 1}}{(2n + 1)!}}\)</span>.<br />We want to find an <span class="math">\(M\)</span> such that <span class="math">\(\abs{f^{(((2N + 1) + 1))}(x)} \le M\)</span>. Note that we simply added 1 to the derivative depth, not to <span class="math">\(N\)</span> itself (<span class="math">\(N\)</span> here actually means <span class="math">\(2N + 1\)</span>).<br />Clearly, <span class="math">\(f^{(((2N + 1) + 1))}(x)\)</span> is either <span class="math">\(\pm \sin x\)</span> or <span class="math">\(\pm \cos x\)</span>, and so <span class="math">\(\abs{f^{(2N + 2)}(x)} \le 1\)</span>.<br />Then by the Taylor Remainder Theorem, <span class="math">\(\abs{R_N(x)} \le \frac{\abs{x - x_0}^{N + 1}}{(N + 1)!} = \frac{\abs{x}^{N + 1}}{(N + 1)!}\)</span>.</p>
</blockquote>
<p>We almost always want to minimise the error. To do this, we should keep <span class="math">\(x\)</span> as close to <span class="math">\(x_0\)</span> as possible (<span class="math">\(x - x_0\)</span> can be made smaller), or use more terms in the partial sum (<span class="math">\((N + 1)\)</span> can be made larger). Also, we always want the smallest possible <span class="math">\(M\)</span>, so we want to pick the tightest possible bound for <span class="math">\(f^{(N + 1)}(x)\)</span>.</p>
<p>Estimate the error in the Taylor polynomial for <span class="math">\(e^x\)</span> about <span class="math">\(x_0 = 0\)</span> after <span class="math">\(N\)</span> terms for <span class="math">\(x \in [-1, 1]\)</span>, and determine the number of terms before the error is less than 0.000005:</p>
<blockquote>
<p>Clearly, the error is <span class="math">\(\abs{R_N(x)} = \abs{e^x - \sum_{n = 0}^N \frac{x^n}{n!}}\)</span>.<br />We want to find <span class="math">\(M\)</span> such that <span class="math">\(\abs{f^{(N + 1)}(x)} \le M\)</span>.<br />Clearly, <span class="math">\(f^{(N + 1)}(x) = e^x\)</span>, and the largest possible value occurs at <span class="math">\(x = 1\)</span>, so <span class="math">\(\abs{f^{(N + 1)}(x)} \le e^1\)</span>, so <span class="math">\(M \ge e\)</span>.<br />Then by the Taylor Remainder Theorem, <span class="math">\(\abs{R_N(x)} \le e\frac{\abs{x}^{N + 1}}{(N + 1)!}\)</span>. We can use any <span class="math">\(M \ge e\)</span> we want to simplify our calculations, but larger <span class="math">\(M\)</span> means less useful error bounds.<br />We want <span class="math">\(\abs{R_N(x)} \le e\frac{\abs{x}^{N + 1}}{(N + 1)!} \le t(N) \le 0.000005\)</span>, where <span class="math">\(t(N)\)</span> is a function of <span class="math">\(N\)</span> only, without <span class="math">\(x\)</span>.<br />Since <span class="math">\(\abs{x}^{N + 1} \le 1\)</span>, <span class="math">\(\frac{e}{(N + 1)!} \le \frac{e\abs{\pm 1}^{N + 1}}{(N + 1)!} \le 0.000005\)</span>, or <span class="math">\((N + 1)! \le 200000e\)</span>.<br />Clearly, <span class="math">\(400000 = 200000 \cdot 2 \le 200000e \le 200000 \cdot 3 = 600000\)</span>.<br />Since <span class="math">\(9! \le 200000\)</span> and <span class="math">\(10! &gt; 600000\)</span>, <span class="math">\(N + 1 \ge 10 \iff (N + 1)! &gt; 200000e\)</span> and <span class="math">\(N \ge 9\)</span>.<br />So the error is less than 0.000005 when <span class="math">\(N \ge 9\)</span>.</p>
</blockquote>
<h1 id="section-30">24/3/14</h1>
<p>A <strong>Maclaurin series</strong> is a Taylor series where <span class="math">\(x_0 = 0\)</span> - a Taylor series centered around 0.</p>
<p>Clearly, <span class="math">\(\sum_{n = 0}^\infty \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n = \frac{f^{(0)}(x_0)}{0!}(x - x_0)^0 + \ldots + \frac{f^{(N)}(x_0)}{N!}(x - x_0)^N + R_N(x)\)</span> for some finite <span class="math">\(N\)</span>.</p>
<p>Let <span class="math">\(\mb{I} = [a, b]\)</span> such that <span class="math">\(x_0 \in \mb{I}\)</span>, within the interval of convergence. Clearly, Taylor series are always continuous.</p>
<p>By the Taylor remainder theorem, <span class="math">\(\abs{R_{N, x_0}} = \frac{f^{(N + 1)}(c)}{(N + 1)!}\abs{x - x_0}^{N + 1}\)</span> for some <span class="math">\(c\)</span>. Clearly, <span class="math">\(\frac{f^{(N + 1)}(c)}{(N + 1)!}\abs{x - x_0}^{N + 1}\)</span> is a scalar multiple of <span class="math">\(\frac{f^{(N + 1)}(x)}{(N + 1)!}\abs{x - x_0}^{N + 1}\)</span>.</p>
<p>So <span class="math">\(R_N(x) = O(1) \frac{f^{(N + 1)}(x)}{(N + 1)!}\abs{x - x_0}^{N + 1}\)</span>. In other words, we can write the remainder as a scalar multiple of the next term.</p>
<p>So we can actually write the series as <span class="math">\(\frac{f^{(0)}(x_0)}{0!}(x - x_0)^0 + \ldots + \frac{f^{(N)}(x_0)}{N!}(x - x_0)^N + O(1) \frac{f^{(N + 1)}(x_0)}{(N + 1)!}(x - x_0)^{N + 1}\)</span>.</p>
<p>For example, <span class="math">\(\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + O(1)\frac{x^9}{9!}\)</span>.</p>
<h2 id="operations-on-taylor-series">Operations on Taylor Series</h2>
<p>The reason we use Taylor series to represent functions is in order to more easily evaluate limits, integrals, and infinite series. It is also useful for approximating the functions with actual numbers, all while being able to get the error bounds in our evaluation.</p>
<h3 id="limits">Limits</h3>
<p>If we take a limit as <span class="math">\(x \to x_0\)</span>, then the coefficients of a Taylor series already has l'Hospital's rule built in.</p>
<p>Consider <span class="math">\(\lim_{x \to 0} \frac{\sin x}{x}\)</span>:</p>
<blockquote>
<p>We could find this geometrically, using l'Hospital's rule, or using infinite series.<br />Clearly, <span class="math">\(\lim_{x \to 0} \frac{\sin x}{x} = \lim_{x \to 0} \frac{x - \frac{x^3}{3!} + \frac{x^5}{5!} + M\frac{x^7}{7!}}{x} = \lim_{x \to 0} 1 - \frac{x^2}{3!} + \frac{x^4}{5!} + M\frac{x^6}{7!} = 1 - 0 + 0 + M0 = 1\)</span>.</p>
</blockquote>
<p>Evaluate <span class="math">\(\lim_{x \to 0} \frac{e^{\sin x} - 1}{x}\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(u = \sin x\)</span>. Clearly, <span class="math">\(\lim_{x \to 0} \frac{e^{\sin x} - 1}{x} = \lim_{x \to 0} \frac{e^u - 1}{x} = \lim_{x \to 0} \frac{(1 + u + \frac{u^2}{2!} + \ldots) - 1}{x} = \lim_{x \to 0} \frac{\sin x + \frac{\sin^2 x}{2!} + \ldots}{x} = \lim_{x \to 0} \frac{\sin x}{x}\left(1 + \frac{\sin x}{2!} + \ldots\right) = \lim_{x \to 0} \frac{\sin x}{x} \lim_{x \to 0} \left(1 + \frac{\sin x}{2!} + \ldots\right) = 1\)</span>.</p>
</blockquote>
<p>However, it is usually faster and easier to just use l'Hospital's rule.</p>
<h1 id="section-31">26/3/14</h1>
<p>The Taylor inequality basicaly states that the remainder of a Taylor polynomial is a multiple of the next term if the derivative is bounded.</p>
<h3 id="estimating-definite-integrals">Estimating Definite Integrals</h3>
<p><span class="math">\(e^{-x^2}\)</span> is a Guassian function, which have the general form of <span class="math">\(e^{-\frac{(x - a)^2}{2\sigma^2}}\)</span>. This is also an error function. It is heavily used in statistics as a probability distribution, and looks like a bell curve. <span class="math">\(\sigma\)</span> represents the standard deviation of the distribution.</p>
<p>This is also associated with scientific literature claims of &quot;six-sigma&quot; accuracy or similar.</p>
<p>The interesting thing about this function is that it has no antiderivative.</p>
<p>Evaluate <span class="math">\(\int_0^1 e^{-x^2} \dee x\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(u = -x^2\)</span>. Clearly, <span class="math">\(e^{-x^2} = \sum_{n = 0}^\infty \frac{(-x^2)^n}{n!} = \sum_{n = 0}^\infty \frac{(-1)^nx^{2n}}{n!}\)</span>.<br />So <span class="math">\(\int_0^1 e^{-x^2} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{n!}\int_0^1 x^{2n} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{n!}\evalat{\frac{x^{2n + 1}}{2n + 1}}_0^1 = \sum_{n = 0}^\infty \frac{(-1)^n}{n!(2n + 1)}\)</span>.</p>
</blockquote>
<p>Estimate <span class="math">\(\int_0^1 x^x \dee x\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\int_0^1 x^x \dee x = \int_0^1 e^{x \ln x} \dee x = \sum_{n = 0}^\infty \frac{1}{n!} \int_0^1 x^n \ln^n x \dee x\)</span>.<br />Clearly, <span class="math">\(\int_0^1 x^n \ln^n x \dee x = \frac{(-1)^{n + 1}n!}{n^n}\)</span>. ;wip: what? how? even WolframAlpha can't evaluate this one So <span class="math">\(\int_0^1 x^x \dee x = \sum_{n = 0}^\infty \frac{(-1)^{n + 1}}{n^n}\)</span>.</p>
</blockquote>
<p>Estimate <span class="math">\(\int_0^1 \frac{\sin \ln x}{\ln x} \dee x\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(u = \ln x\)</span>. Then <span class="math">\(\frac{\sin \ln x}{\ln x} = \frac{1}{u}\sin u = \sum_{n = 0}^\infty \frac{1}{u}\frac{(-1)^n}{(2n + 1)!} u^{2n + 1} = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} \frac{u^{2n + 1}}{u} = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} \ln^{2n} x\)</span>.<br />So <span class="math">\(\int_0^1 \frac{\sin \ln x}{\ln x} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} \int_0^1 \ln^{2n} x \dee x\)</span>.<br />By taking a few values of <span class="math">\(n\)</span> and integrating by parts, we find that <span class="math">\(\int_0^1 \ln^{2n} x \dee x = (2n)!\)</span>.<br />So <span class="math">\(\int_0^1 \frac{\sin \ln x}{\ln x} \dee x = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1)!} (2n)! = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1}\)</span>.<br />Recall that <span class="math">\(\arctan x = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1} x^{2n + 1}\)</span>. So <span class="math">\(\arctan 1 = \sum_{n = 0}^\infty \frac{(-1)^n}{2n + 1}\)</span>.<br />So <span class="math">\(\int_0^1 \frac{\sin \ln x}{\ln x} \dee x = \arctan 1 = \frac{\pi}{4}\)</span>.</p>
</blockquote>
<h1 id="section-32">27/3/14</h1>
<h3 id="evaluating-infinite-series">Evaluating Infinite Series</h3>
<p>We often want a closed form of a series.</p>
<p>Evaluate <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^2}\)</span>:</p>
<blockquote>
<p>All we know right now is that this converges and is between 1 and 2. Euler found several ways to find the exact value of this series.<br />Clearly, <span class="math">\(\frac{\sin x}{x} = \frac{1}{x} \sum_{n = 0}^\infty \frac{(-1)^n x^{2n + 1}}{(2n + 1)!} = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n + 1)!}\)</span>.<br />Clearly, <span class="math">\(\frac{\sin x}{x} = 1\)</span> if <span class="math">\(x = 0\)</span>, and <span class="math">\(\frac{\sin x}{x} = \sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n + 1)!}\)</span> if <span class="math">\(x \ne 0\)</span>.<br />Clearly, any finite polynomial <span class="math">\(P(x)\)</span> such that <span class="math">\(P(0) = 1\)</span> and roots <span class="math">\(r_1, \ldots, r_n\)</span> can be written as <span class="math">\((1 - \frac{x}{r_1}) \cdots (1 - \frac{x}{r_n})\)</span>.<br />Assume this is also true for infinite polynomials as well. ;wip: this assumption is not always true Clearly, the roots of <span class="math">\(\frac{\sin x}{x}\)</span> are <span class="math">\(x = \pm \pi, \pm 2\pi, \ldots\)</span>.<br />So <span class="math">\(\frac{\sin x}{x} = \left(\left(1 - \frac{x}{\pi}\right)\left(1 + \frac{x}{\pi}\right)\right)\left(\left(1 - \frac{x}{2\pi}\right)\left(1 + \frac{x}{2\pi}\right)\right) \cdots = \left(1 - \frac{x^2}{\pi^2}\right)\left(1 - \frac{x^2}{2^2\pi^2}\right) \cdots\)</span>.<br />So <span class="math">\(\sum_{n = 0}^\infty \frac{(-1)^n x^{2n}}{(2n + 1)!} = \left(1 - \frac{x^2}{\pi^2}\right)\left(1 - \frac{x^2}{2^2\pi^2}\right) \cdots\)</span>.<br />Clearly, <span class="math">\(\left(1 - \frac{x^2}{\pi^2}\right)\left(1 - \frac{x^2}{2^2\pi^2}\right) \cdots = 1 - \frac{x^2}{\pi^2}\eft(\frac{1}{1^2} + \frac{1}{1^2} + \ldots\right) + x^4(\ldots) - x^6(\ldots) + \ldots\)</span>.<br />Clearly, the coefficients of <span class="math">\(x^2\)</span> must match. So <span class="math">\(-\frac{1}{3!} = -\frac{1}{\pi}^6 \sum_{n = 1}^\infty \frac{1}{n^2}\)</span>.<br />So <span class="math">\(\sum_{n = 1}^\infty \frac{1}{n^2} = \frac{\pi^2}{6}\)</span>.<br />In fact, we can also equate the coefficients of <span class="math">\(x^4\)</span>, <span class="math">\(x^6\)</span>, and etc. to obtain things like <span class="math">\(\sum_{n = 1}^\infty \frac{1}{26} = \frac{1315862 \pi^{26}}{11094481976030578125}\)</span>.<br />;wip: talk about odd powers and how to derive the even powers directly</p>
</blockquote>
<h2 id="parametric-curves">Parametric Curves</h2>
<p>We now consider functions with a single output and a vector output. For example, the position of a particle with respect to time, <span class="math">\(\vec{r}(t) = \begin{bmatrix} x(t) \\ y(t) \\ z(t) \end{bmatrix}\)</span>. This has many applications in physics.</p>
<p>The function <span class="math">\(\vec{r}(t)\)</span> defines a curve in the dimension of the vector. Here, <span class="math">\(t\)</span> is the <strong>parameter</strong> of the function.</p>
<p>These functions are also called <strong>parametric curves</strong>.</p>
<p>We do calculus on these functions by working with each component separately. As a result, calculus on parametric curves are no more difficult than calculus on normal functions.</p>
<p>For example, <span class="math">\(\vec{r}(t) = \begin{bmatrix} t \\ \abs{t} \end{bmatrix}\)</span> simply looks like the absolute value function on <span class="math">\(\begin{bmatrix} x \\ y \end{bmatrix} = \vec{r}(t)\)</span>.</p>
<p>However, the additional information is the direction along the curve - the velocity, in our case.</p>
<h1 id="section-33">31/3/14</h1>
<p>Parametric curves allow us to describe curves that would be very difficult or impossible to represent as s imple functions of <span class="math">\(x\)</span>. This is much more general than curves on a plane.</p>
<p>Parametric curves also have a direction vector along the curve. The direction always goes from a low <span class="math">\(t\)</span> to a high <span class="math">\(t\)</span>. This contrasts with curves on a plane, which does not have a direction along the curve.</p>
<p>For example, <span class="math">\(\vec{r}(t) = (t^2, t), t \in [0, 1]\)</span>. Since <span class="math">\(x = t^2\)</span> and <span class="math">\(y = t\)</span>, <span class="math">\(y = \sqrt{x} = t\)</span>, which is a form that allows us to plot the function easily.</p>
<p>Parametric curves are hard to plot because we are not used to them. However, parametric curves of the form <span class="math">\(\vec{r}(t) = (t, f(t))\)</span> can simply be plotted using <span class="math">\(y = f(t)\)</span>. Likewise, parametric curves of the form <span class="math">\(\vec{r}(t) = (f(t), t)\)</span> can simply be plotted using <span class="math">\(x = f(t)\)</span>, or <span class="math">\(y = f^{-1}(t)\)</span>. Also, the direction vector is rightwards, because as <span class="math">\(t\)</span> increases, the corresponding coordinate <span class="math">\(\vec{r}(t)\)</span> moves rightward.</p>
<p>Consider <span class="math">\(\vec{r}(t) = (a \cos t, a \sin t), t \in [0, 2\pi]\)</span>. Since <span class="math">\(x = a \cos t, y = a \sin t\)</span>, <span class="math">\(x^2 + y^2 = a^2(\sin^2 t + \cos^2 t) = a^2\)</span>. So this is a circle of radius <span class="math">\(a\)</span>. The circle starts at <span class="math">\((a, 0)\)</span>, and travels counterclockwise until it reaches the starting point again.</p>
<p>Given a value of <span class="math">\(t\)</span> for <span class="math">\(\vec{r}(t) = (f(t), g(t))\)</span> and <span class="math">\(y = f(x)\)</span>, we can plot it in an inverval of <span class="math">\(t \in [a, b]\)</span> by plotting for <span class="math">\(x \in [f(a), f(b)]\)</span>.</p>
<p>The parameterization of a curve is not unique, just like normal curves. Every parametric curve has infinite different ways of being represented mathematically, but when drawn on a plane each curve has only one shape.</p>
<p>For example, consider <span class="math">\(\vec{r}(t) = (a \cos t, b \sin t)\)</span>. This is an ellipse where <span class="math">\(a &gt; b\)</span> stretches it horiontally and <span class="math">\(b &gt; a\)</span> stretches it vertically. We can rewrite it as <span class="math">\(\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1\)</span> to plot it on a Cartesian plane.</p>
<p>We plot parametric curves by solving for <span class="math">\(t\)</span> in <span class="math">\(x = x(t)\)</span>, so <span class="math">\(t = x^{-1}(x)\)</span>, then subsituting into <span class="math">\(y(t)\)</span> to get <span class="math">\(y = y(x^{-1}(x))\)</span>, which is a non-parametric function we can plot more easily.</p>
<p>Alternatively, we would have to plot both <span class="math">\(y = y(t)\)</span> and <span class="math">\(x = x(t)\)</span>, and use these graphs to plot the points on <span class="math">\(\vec{r}(t) = (x(t), y(t))\)</span>.</p>
<h3 id="hyperbolic-functions">Hyperbolic Functions</h3>
<p>The functions <span class="math">\(\vec{r} = (a \cos t, b \sin t)\)</span> are called <strong>circular/elliptical trigonometric fucntions</strong>.</p>
<p>The hyperbolic trigonometric funnctions are called hyperbolic for a reason. Consider <span class="math">\(\vec{r}(t) = (a \cosh t, b \sinh t)\)</span>.</p>
<p>In fact, this creates a <strong>hyperbola</strong>, which looks like a parabola and another instance of that parabola flipped about the x-axis, or the same thing sideways. They are always symmetrical about the x-axis and y-axis.</p>
<p>A hyperbola is a curve defined by <span class="math">\(\frac{x^2}{a^2} - \frac{y^2}{b^2} = 1\)</span>. We can derive this form by using the identity <span class="math">\(\cosh^2 t - \sinh^2 t = 1\)</span>.</p>
<h1 id="section-34">2/4/14</h1>
<p>;wip: final exam MC 4061 thursday April 10 4pm</p>
<p>We can sketch this by rearranging the formula to get <span class="math">\(y = \pm \sqrt{\frac{b^2}{a^2}x^2 - b^2}\)</span>.</p>
<p>When <span class="math">\(x\)</span> or <span class="math">\(y\)</span> gets large, <span class="math">\(y \approxeq \pm \frac{b}{a}x\)</span> - the function has lines for asymptotes.</p>
<p>At <span class="math">\(x = 0\)</span>, <span class="math">\(y = \pm \sqrt{-b^2}\)</span>, which is imaginary, so there is no y-intercept.</p>
<p>At <span class="math">\(y = 0\)</span>, <span class="math">\(x = \pm a\)</span>, which are the x-intercepts.</p>
<p>Imagine a wheel of radius <span class="math">\(a\)</span> rolling along a level surface. If we observe from the reference frame of the surface, then a point on the edge of the wheel would create a bumpy curve. This curve is called a <strong>cycloid curve</strong>.</p>
<p>The cycloid curve can easily be parametrically defined by <span class="math">\(\vec{r}(t) = (at - a \sin t, a - a \cos t)\)</span>. The <span class="math">\(at\)</span> term moves the curve horizontally, and the <span class="math">\(a\)</span> term moves above the x-axis.</p>
<p>This function is very difficult to write in terms of <span class="math">\(y(x)\)</span>.</p>
<p>;wip: figure out how to convert parametrics to implicit functions</p>
<p>Parametric curves are not limited to <span class="math">\(\mb{R}^2\)</span>. If we extend them into <span class="math">\(\mb{R}^n\)</span>, then we can have <span class="math">\(n\)</span> dimensional curves.</p>
<h3 id="calculus-on-parametric-curves">Calculus on Parametric Curves</h3>
<p>To perform calculus on vector valued functions, we simply note that the vector valued function is a vector of single variable functions: <span class="math">\(\vec{r}(t) = (x(t), y(t))\)</span>, and we can apply the operations to the single variable functions.</p>
<p>For example, <span class="math">\(\lim_{t \to a} \vec{r}(t) = \vec{L} \iff \lim_{t \to a} x(t) = L_1 \wedge \lim_{t \to a} y(t) = L_2\)</span>.</p>
<p>In the same way, <span class="math">\(\frac{\dee \vec{r}}{\dee t} = (\frac{\dee x}{\dee t}, \frac{\dee y][\dee t})\)</span>. This is also known as the <strong>tangent vector</strong>.</p>
<p>This is the reason that the velocity of the object is tangent to its motion - it is the tangent vector of position.</p>
<p>Consider <span class="math">\(\magn{\frac{\dee \vec{r}}{\dee t}}\)</span>. This is the speed if <span class="math">\(\vec{r}(t)\)</span> is the position. This allows us to find the length of a curve (also known as distance or arclength) given its parametric curve.</p>
<p>The length of a curve from <span class="math">\(t = a\)</span> to <span class="math">\(t = b\)</span> is <span class="math">\(\int_a^b \magn{\frac{\dee \vec{r}}{\dee t}} \dee t\)</span>.</p>
<p>For example, find the circumference of the circle <span class="math">\(\vec{r}(t) = (a \cos t, a \sin t)\)</span> for <span class="math">\(t \in [0, 4\pi]\)</span>:</p>
<blockquote>
<p>Clearly, the length is <span class="math">\(\int_a^b \magn{\frac{\dee \vec{r}}{\dee t}} \dee t = \int_0^{4 \pi} \sqrt{\left(\frac{\dee}{\dee t} a \cos t\right)^2 + \left(\frac{\dee}{\dee t} a \sin t\right)^2} \dee t\)</span> ;wip</p>
</blockquote>
<p>For example, <span class="math">\(\vec{r}(t) = (a \cos t, a \sin t, t)\)</span> is a spiral upwards.</p>
<h1 id="section-35">4/4/14</h1>
<p>Find the arc length of <span class="math">\(\vec{r}(t) = (a \cos t, a \sin t, t)\)</span> for <span class="math">\(t \in [0, 4 \pi]\)</span>:</p>
<blockquote>
<p>This is a spiral going upwards.<br />Clearly, <span class="math">\(\frac{\dee \vec{r}}{\dee t} = (-a \sin t, a \cos t, 1)\)</span>.<br />Clearly, the arc length is <span class="math">\(\int_0^{4 \pi} \magn{\frac{\dee \vec{r}}{\dee t}} \dee t = \int_0^{4 \pi} \sqrt{a^2 \sin^2 t + a^2 \cos^2 t + 1^2} \dee t = \int_0^{4 \pi} \sqrt{a^2 + 1} \dee t\)</span>.<br />So the arc length is <span class="math">\(4 \pi \sqrt{a^2 + 1}\)</span>.</p>
</blockquote>
<p>Find the arc length of the cycloid function <span class="math">\(\vec{r}(t) = (at - a \sin t, a - a \cos t)\)</span> for <span class="math">\(t \in [0, 2 \pi]\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\frac{\dee \vec{r}}{\dee t} = (a - a \cos t, a \sin t)\)</span> and <span class="math">\(\magn{\frac{\dee \vec{r}}{\dee t}}\)</span>.<br />Clearly, <span class="math">\(\magn{\frac{\dee \vec{r}}{\dee t}} = \sqrt{a^2 - 2a^2 \cos t + a^2 \cos^2 t + a^2 \sin t} = \sqrt{2a^2 - 2a^2 \cos t} = a\sqrt{2 - 2 \cos t} = a\sqrt{4\left(\frac{1}{2} - \frac{1}{2} \cos t\right)} = 2a\sqrt{\frac{1}{2} - \frac{1}{2} \cos t}\)</span>.<br />Recall the half angle formula <span class="math">\(\sin^2 t = \frac{1}{2} - \frac{1}{2} \cos 2t\)</span>.<br />Clearly, <span class="math">\(2a\sqrt{\frac{1}{2} - \frac{1}{2} \cos t} = 2a\sqrt{\sin^2 \frac{t}{2}} = 2a\abs{\sin \frac{t}{2}}\)</span>.<br />Since we are working in a range where <span class="math">\(\frac{t}{2} \in [0, \pi]\)</span>, <span class="math">\(\abs{\sin \frac{t}{2}} = \sin \frac{t}{2}\)</span>.<br />Clearly, <span class="math">\(\int_0^{2\pi} \magn{\frac{\dee \vec{r}}{\dee t}} \dee t = 2a\int_0^{2\pi} \sin \frac{t}{2} \dee t = 2a\evalat{2\cos \frac{t}{2}}_0^{2\pi} = 8a\)</span>.<br />So the arc length is <span class="math">\(8a\)</span>.</p>
</blockquote>
<h3 id="slope">Slope</h3>
<p>The <strong>slope of a tangent vector</strong> is <span class="math">\(\frac{\dee y}{\dee x}\)</span>. We can find it using <span class="math">\(\frac{\dee y}{\dee x} = \frac{\frac{\dee y}{\dee t}}{\frac{\dee x}{\dee t}}\)</span>.</p>
<p>Find the slope of <span class="math">\(\vec{r}(t) = (\cos t, \sin t)\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(\frac{\dee y}{\dee x} = \frac{-\sin t}{\cos t} = -\tan t\)</span>.<br />This is where the <span class="math">\(\tan\)</span> function gets its name - it is the slope of the tangent of a circle at any given angle.</p>
</blockquote>
<p>Consider <span class="math">\(\frac{\dee^2 y}{\dee x^2}\)</span>. We might think that <span class="math">\(\frac{\dee^2 y}{\dee x^2} = \frac{\frac{\dee^2 y}{\dee t^2}}{\frac{\dee^2 x}{\dee t^2}}\)</span>, but this is incorrect.</p>
<p>In fact, <span class="math">\(\frac{\dee^2 y}{\dee x^2} = \frac{\dee}{\dee x} \frac{\dee y}{\dee x} = \frac{\frac{\dee}{\dee t} \frac{\dee y}{\dee x}}{\frac{\dee x}{\dee t}} = \frac{\frac{\dee}{\dee t} \frac{\dee y}{\dee x}}{\frac{\dee x}{\dee t}}\)</span>.</p>
<h3 id="area">Area</h3>
<p>The area under a curve of a function is given by <span class="math">\(y = F(x)\)</span> is <span class="math">\(A = \int_{x_1}^{x_2} F(x) \dee x\)</span>.</p>
<p>For parametric curves, we have <span class="math">\(x = x(t)\)</span> and <span class="math">\(y = y(t)\)</span>. Then there exists <span class="math">\(y = F(x)\)</span> - a function of <span class="math">\(x\)</span> equivalent to <span class="math">\(y\)</span>, and <span class="math">\(y(t) = F(x)\)</span>.</p>
<p>Then <span class="math">\(x_1 = x(t_1)\)</span> and <span class="math">\(x_2 = x(t_2)\)</span>, and <span class="math">\(\dee x = \frac{\dee x}{\dee t} \dee t\)</span>.</p>
<p>So <span class="math">\(A = \int_{t_1}^{t_2} F(x) \dee x = \int_{t_1}^{t_2} y(t) \dee x = \int_{t_1}^{t_2} y(t) \frac{\dee x}{\dee t} \dee t\)</span>.</p>
<p>This allows us to find the area under a curve.</p>
<p>;wip: I finally get <span class="math">\(u\)</span> substitution - it was inconsistent because sometimes u was a function of u, and sometimes x is a function of u.</p>
<p>;wip: is the limit test adding 1 to the exponent, or is it the next term when we have things like <span class="math">\(x^{2n}\)</span>? wikipedia says the latter but in class it was the former</p>
<p>Find the area under the cycloid curve <span class="math">\(\vec{r}(t) = (at - a \sin t, a - a \cos t)\)</span> for <span class="math">\(t \in [0, 2 \pi]\)</span>:</p>
<blockquote>
<p>Clearly, <span class="math">\(A = \int_0^{2 \pi} (a - a \cos t) \frac{\dee}{\dee t} (at - a \sin t) \dee t = \int_0^{2 \pi} (a - a \cos t)(a - a \cos t) \dee t = 2 \pi a^2 + \int_0^{2 \pi} -2a^2 \cos t \dee t + \int_0^{2 \pi} + a^2 \cos^2 t \dee t = 3 \pi a^2\)</span>.<br />So the cycloid curve has an area of <span class="math">\(3 \pi a^2\)</span> units.</p>
</blockquote>
<p>To find the value of an infinite series, we take a known series, then apply transformations to it until it is the function we need.</p>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2014 Anthony Zhang.
</div>
<script type="text/javascript">
MathJax.Hub.Config({
  jax: ["input/TeX","output/HTML-CSS"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  }
});
</script>
</body>
</html>